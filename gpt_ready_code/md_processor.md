"book_processor.py": "'import os\nimport re\nimport file_operations_utils\n# epub\ndef base_on_mulu_rename_mds(path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tmulu_name = "part0001.md"\n\tmulu_path = os.path.join(path, mulu_name)\n\tif not os.path.exists(mulu_path):\n\t\traise ValueError("no mulu file")\n\twith open(mulu_path, \'r\', encoding=\'utf-8\') as f:\n\t\tcontent = f.read()\n\treg_string1 = r"\\[(.+?)\\]\\(.+?(part)\\)"\n# zhi\ndef lower_header_level_in_md_files(path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfiles_md = [f for f in os.listdir(path) if f.endswith(\'.md\')]\n\treg_string_head = re.compile(r"(#{1,6}) (.+)")\n\t# what is compile\n\tfor file in files_md:\n\t\ttry:\n\t\t\twith open(os.path.join(path, file), "r", encoding="utf-8") as f:\n\t\t\t\tlines = f.readlines()\n\t\t\tprocessed_lines = []\n\t\t\tfor line in lines:\n\t\t\t\tmatch = reg_string_head.search(line)\n\t\t\t\tif match:\n\t\t\t\t\tstring_sharp = match.group(1)\n\t\t\t\t\thead_num = string_sharp.count("#")\n\t\t\t\t\tline = reg_string_head.sub(\n\t\t\t\t\t\t(head_num + 1) * "#" + r" \\2", line)\n\t\t\t\tprocessed_lines.append(line)\n\t\t\twith open(os.path.join(path, file), "w", encoding="utf-8") as f:\n\t\t\t\tf.writelines(processed_lines)\n\t\texcept Exception as e:\n\t\t\tprint(f"Failed to process file {file} due to {str(e)}")\ndef prepend_filename_as_header_if_chapter_present(directory=None):\n\treg_string1 = r"\\d{3}_(第.{1,2}章.+)"\n\treg_string2 = r"\\d{3}_(\\d{1,2} .+)\\.md"\n\tif directory is None:\n\t\tdirectory = os.getcwd()\n\treg_string = reg_string2\n\tfiles_md = [f for f in os.listdir(directory) if f.endswith(\'.md\')]\n\t# Iterate over all files in the directory\n\tfor filename in files_md:\n\t\t# If the filename contains \'Chapter\'\n\t\tmatch = re.search(reg_string, filename)\n\t\tif match:\n\t\t\tchapter_name = match.group(1)\n\t\t\tprint(chapter_name)\n\t\t\t# Open the file and read its contents\n\t\t\twith open(os.path.join(directory, filename), \'r\', encoding="utf-8") as f:\n\t\t\t\tcontent = f.readlines()\n\t\t\t# Prepend the filename as a level 2 header\n\t\t\tcontent.insert(0, f\'## {chapter_name}\\n\')\n\t\t\t# Write the modified content back to the file\n\t\t\twith open(os.path.join(directory, filename), \'w\', encoding="utf-8") as f:\n\t\t\t\tf.writelines(content)\ndef remove_md_copy_code(path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\treg_string_copy_code = [r"```\\n(.+)Copy code", r"```\\1\\n"]\n\treg_string_list = []\n\treg_string_list.append(reg_string_copy_code)\n\tfiles_md = [f for f in os.listdir(path) if f.endswith(\'.md\')]\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, path, files_md)\ndef perform_regex_replacement_on_index_file(directory_path=None):\n\t"""\n\tThis function checks for the existence of an index file in the given directory\n\tpath and performs a regex replacement on it.\n\tArgs:\n\t\tdirectory_path: Path to the directory to check. Defaults to the current working directory.\n\tRaises:\n\t\tFileNotFoundError: If the index file is not found in the directory.\n\t"""\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tindex_filename = "000_index.md"\n\tif index_filename not in os.listdir(directory_path):\n\t\traise FileNotFoundError("Index file not found")\n\tfile_paths = [os.path.join(directory_path, index_filename)]\n\tregex_patterns = [(r"- \\[(.+)\\]\\(.+\\)", r"\\1")]\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\tregex_patterns, directory_path, file_paths)\ndef perform_regex_replacement_on_zhi_mds(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_index_link = [\n\t\tr"-\\s+\\[.+\\]\\(https://www.zhihu.com/pub/reader/.+\\)\\n", r""]\n\treg_string_list.extend([reg_index_link])\n\treg_zhi_sao_ma = [\n\t\tr"扫码下载知乎APP 客户端\\n\\n!\\[\\]\\(.+sidebar-download-qrcode.wybWudky.png\\)\\n", r""]\n\treg_string_list.extend([reg_zhi_sao_ma])\n\treg_Back_matter_template = [r"---\\n\\n- created:.+\\n- source: .+", r""]\n\treg_string_list.extend([reg_Back_matter_template])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, directory_path, files_md)\ndef convert_zhi_footnote_to_obsidian(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\t# r"[\\[1\\]](https://www.zhihu.com/pub/reader/120057501/chapter/1302455544230445056#n1s) 在英语中，发散一词是diffuse。注意focused（专注）一词的词尾是-ed，而diffuse则不是。发散一词的意思是“薄薄地弥漫出去”。"\n\treg_string1 = [\n\t\tr\'<sup><a href="https://www\\.zhihu\\.com/pub/reader.+n\\d{1,2}" id="n\\d{1,2}s">\\[(\\d{1,2})\\]</a></sup>\', r"[^\\1]"]\n\t# r\'<sup><a href="https://www\\.zhihu\\.com/pub/reader.+n\\d{1,2}" id="n\\d{1,2}s">\\[\\d{1,2}\\]</a></sup>\'\n\treg_string_list.extend([reg_string1])\n\treg_string2 = [\n\t\tr\'\\[\\\\\\[(\\d{1,2})\\\\\\]\\]\\(https://www\\.zhihu\\.com/pub/.+\\) (.+)\', r"[^\\1]: (\\2)"]\n\treg_string_list.extend([reg_string2])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, directory_path, files_md)\ndef perform_regex_replacement_on_zhi_book_mds_name(path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfiles_md = [f for f in os.listdir(path) if f.endswith(\'.md\')]\n\treg_string_dir = [r"(.+) - .+ - 知乎书店", r"\\1"]\n\treg_string_md = [r"(.+) - .+ - 知乎书店(\\.md)", r"\\1\\2"]\n\treg_string_md2 = [r"{ (.+) }", r"{\\1}"]\n\treg_string_list = []\n\treg_string_list.append(reg_string_md)\n\tfile_operations_utils.perform_regex_rename_on_files(\n\t\treg_string_list, path, files_md)\n\tdirs = [directory for directory in os.listdir(\n\t\tpath) if os.path.isdir(directory)]\n\treg_string_list = []\n\treg_string_list.append(reg_string_dir)\n\tfile_operations_utils.perform_regex_rename_on_files(\n\t\treg_string_list, path, dirs)\ndef num2str_title(num):\n\treturn str(num).zfill(3)\ndef rename_files_base_on_index_markdown(path=None):\n\tcounter = 0\n\tif path is None:\n\t\tpath = os.getcwd()\n\twith open(os.path.join(path, "000_index.md"), \'r\', encoding=\'UTF-8\') as f:\n\t\tlines = f.readlines()\n\tfiles = os.listdir(path)\n\tfor i, line in enumerate(lines):\n\t\tline = line.strip().replace("%", "_")\n\t\tnote_name = line + \'.md\'\n\t\tif note_name in files:\n\t\t\tcounter += 1\n\t\t\tos.replace(os.path.join(path, note_name),\n\t\t\t\t\t   os.path.join(path, num2str_title(counter) + "_" + note_name))\n\t\telse:\n\t\t\tprint(files)\n\t\t\traise FileNotFoundError(f"{note_name} not in the files list")\ndef get_md_files(directory=\'.\'):\n\t"""Return a sorted list of markdown filenames in a given directory."""\n\tfiles = [f for f in os.listdir(directory) if f.endswith(\'.md\')]\n\t# Extract numeric prefix and sort based on it\n\tfiles.sort(key=lambda x: int(re.match(r\'(\\d{3})_\', x).group(\n\t\t1)) if re.match(r\'(\\d{3})_\', x) else float(\'inf\'))\n\treturn files\ndef check_md_files(files):\n\t# Check if files are in expected order\n\tfor i, filename in enumerate(files):\n\t\texpected_prefix = f"{i:03d}_"\n\t\tif not filename.startswith(expected_prefix):\n\t\t\tprint(\n\t\t\t\tf"Warning: {filename} does not match expected prefix {expected_prefix}")\ndef merge_files(filenames, output_filename):\n\t"""Merge the content of a list of files and write to a new file."""\n\twith open(output_filename, \'w\', encoding=\'utf-8\') as outfile:\n\t\tfor fname in filenames:\n\t\t\ttry:\n\t\t\t\twith open(fname, \'r\', encoding=\'utf-8\') as infile:\n\t\t\t\t\tcontent = infile.read()\n\t\t\t\t\toutfile.write(content)\n\t\t\t\t\toutfile.write(\'\\n\')  # add blank lines between files\n\t\t\texcept IOError:\n\t\t\t\tprint(f\'Error opening file {fname}, skipping.\')\ndef merge_all_md_files_into_one():\n\t"""Merge all markdown files in the current directory into one file."""\n\troot_path, root_dir = file_operations_utils.get_assets_root_path()\n\toutput_file = os.path.join(root_path, root_dir+".md")\n\tmd_files = get_md_files()\n\tcheck_md_files(md_files)\n\tmerge_files(md_files, output_file)\ndef Merge_all_md_files_into_one_file_base_on_num_index():\n\tfiles = [f for f in os.listdir() if f.endswith(\'.md\')]\n\tfiles.sort()\n\tprint(files)\n\troot_path, root_dir = file_operations_utils.get_assets_root_path()\n\twith open(os.path.join(root_path, root_dir+".md"), \'w\', encoding=\'utf-8\') as f:\n\t\tfor file in files:\n\t\t\twith open(file, \'r\', encoding=\'utf-8\') as f2:\n\t\t\t\tcontent = f2.read()\n\t\t\t\tf.write(content)\n\t\t\t\tf.write(\'\\n\\n\')\n'",
"file_operations_utils.py": "'import os\nimport re\nimport time\nimport pyperclip\nimport glob\nimport subprocess\ndef get_father_path(path):\n\treturn os.path.dirname(path)\ndef create_directory_assets_imgs():\n\tdirs = [\n\t\t"assets/imgs",\n\t\t"assets/vids"\n\t]\n\tfor directory in dirs:\n\t\tif not os.path.exists(directory):\n\t\t\tos.makedirs(directory)\n\t\t\tprint(f"Created directory: {directory}")\n\t\telse:\n\t\t\tprint(f"Directory already exists: {directory}")\ndef create_directory_assets_concept_structure():\n\tdirs = [\n\t\t"assets",\n\t\t"assets/imgs",\n\t\t"assets/lectures",\n\t\t"assets/papers",\n\t\t"lectures",\n\t\t"papers",\n\t]\n\tfor directory in dirs:\n\t\tif not os.path.exists(directory):\n\t\t\tos.makedirs(directory)\n\t\t\tprint(f"Created directory: {directory}")\n\t\telse:\n\t\t\tprint(f"Directory already exists: {directory}")\ndef open_folder_in_windows(folder_path):\n\t"""Open a folder in Windows File Explorer based on the folder path.\n\tArgs:\n\tfolder_path (str): The folder path to open.\n\tReturns:\n\tNone\n\t"""\n\tif os.path.exists(folder_path):\n\t\tos.startfile(folder_path)\n\telse:\n\t\tprint(f"Folder path {folder_path} does not exist.")\ndef open_b_assets_folder(cwd=None):\n\tif cwd is None:\n\t\tcwd = os.getcwd()\n\tprint(cwd)\n\tif cwd.find("OneDrive") == -1:\n\t\traise Exception("This script is only for use with OneDrive.")\n\tassets_path_front = "C:/BaiduSyncdisk/assets"\n\t# Split the path after \'KG\' and replace backslashes with forward slashes\n\tkg_path_back = cwd.split("\\\\KG")[1].replace("\\\\", "/")\n\t# Remove the leading forward slash from kg_path_back\n\tkg_path_back = kg_path_back.lstrip("/")\n\tassets_path = os.path.join(assets_path_front, kg_path_back)\n\tif assets_path.find("BaiduSyncdisk") == -1:\n\t\traise Exception("The assets path is not in BaiduSyncdisk.")\n\topen_folder_in_windows(assets_path)\ndef perform_regex_rename_on_files(reg_string_list, path=None, files=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tif files is None:\n\t\tfiles = os.listdir(path)\n\tfor file in files:\n\t\tfor reg_string in reg_string_list:\n\t\t\tmatch = re.search(reg_string[0], file)\n\t\t\tif match is not None:\n\t\t\t\tnew_file = re.sub(reg_string[0], reg_string[1], file)\n\t\t\t\ttry:\n\t\t\t\t\tos.rename(file, new_file)\n\t\t\t\t\tprint(f"Renamed \'{file}\' to \'{new_file}\'")\n\t\t\t\texcept OSError as e:\n\t\t\t\t\tprint(f"Error renaming \'{file}\' to \'{new_file}\': {e}")\ndef rename_files_in_directories(base_path=None):\n\trename_files_in_directories_orders(order=2)\ndef rename_files_in_directories_orders(base_path=None, order=0):\n\timport flags_utils\n\tflags = flags_utils.get_flag_default()\n\tTR_MODE = flags.get_flag("TR_MODE")\n\t"""\n\tRename all files in numbered directories within the base path.\n\tEach file is prefixed with the directory number, zero-padded to three digits.\n\t"""\n\t# Use the current working directory if no path is provided\n\tbase_path = base_path or os.getcwd()\n\t# Validate the base path\n\tif not os.path.isdir(base_path):\n\t\tprint(f"The provided path \'{base_path}\' is not a valid directory.")\n\t\treturn\n\tif order == 0:\n\t\t"""\n\t\t/index/*.mp4\n\t\t\tto\n\t\t\t/index_*.mp4\n\t\t"""\n\t\tfiles = os.listdir(base_path)\n\t\tfiles_mp4 = []\n\t\tfor f in files:\n\t\t\tif f.endswith(".mp4"):\n\t\t\t\tfiles_mp4.append(f)\n\t\tfor index in range(16):\n\t\t\tstart_str = f"{16 - index:03d}_"\n\t\t\tfor file_mp4 in files_mp4:\n\t\t\t\tif file_mp4.startswith(start_str):\n\t\t\t\t\tnew_file = f"{1+index:03d}{file_mp4[3:]}"\n\t\t\t\t\tos.rename(os.path.join(base_path, file_mp4),\n\t\t\t\t\t\t\t  os.path.join(base_path, new_file))\n\telif order == 1:\n\t\t"""\n\t/index/*.mp4\n\tto\n\t/16-index_*.mp4\n\t"""\n\t\tfor index in range(16):\n\t\t\tdir_path = os.path.join(base_path, f"{16 - index}")\n\t\t\t# Check if the directory exists\n\t\t\tif not os.path.isdir(dir_path):\n\t\t\t\tprint(f"Directory \'{dir_path}\' does not exist. Skipping.")\n\t\t\t\tcontinue\n\t\t\ttry:\n\t\t\t\tfor file in os.listdir(dir_path):\n\t\t\t\t\told_file_path = os.path.join(dir_path, file)\n\t\t\t\t\t# Zero-padded prefix\n\t\t\t\t\tnew_file_name = f"{16 - index:03d}_{file}"\n\t\t\t\t\tnew_file_path = os.path.join(base_path, new_file_name)\n\t\t\t\t\tos.rename(old_file_path, new_file_path)\n\t\t\t\t\tprint(f"Renamed \'{old_file_path}\' to \'{new_file_path}\'")\n\t\t\texcept OSError as e:\n\t\t\t\tprint(f"Error renaming files in \'{dir_path}\': {e}")\n\telif order == 2:\n\t\t"""\n\t\tcs50 note\n\t\t999_index\n\t\tWeek (\\d{1,3}) (.+)\n\t\t+\n\t\tLecture (\\d{1,3}) - CS50x 2023\\.md\n\t\t-->\n\t\tf"{lecture_number+1:03d}_{lecture[lecture_number]}.md"\n\t\t"""\n\t\twith open(os.path.join(base_path, "999_index.md"), "r") as f:\n\t\t\tindex_list = f.read().splitlines()\n\t\tlecture = dict()\n\t\tfor index in index_list:\n\t\t\treg = r"Week (\\d{1,3}) (.+)"\n\t\t\tmatch = re.match(reg, index)\n\t\t\tif match:\n\t\t\t\tweek_number = int(match.group(1))\n\t\t\t\tweek_name = match.group(2).strip()\n\t\t\t\tlecture[week_number] = week_name\n\t\t\t\tif TR_MODE:\n\t\t\t\t\tprint(f"Week {week_number} - {week_name}")\n\t\tfiles_md = [f for f in os.listdir(base_path) if f.endswith(".md")]\n\t\tfor file in files_md:\n\t\t\treg = r"Lecture (\\d{1,3}) - CS50x 2023\\.md"\n\t\t\tmatch = re.match(reg, file)\n\t\t\tif match:\n\t\t\t\tlecture_number = int(match.group(1))\n\t\t\t\tif TR_MODE:\n\t\t\t\t\tprint(f"Lecture {lecture_number}")\n\t\t\t\tnew_file_name = f"{lecture_number+1:03d}_{lecture[lecture_number]}.md"\n\t\t\t\tif TR_MODE:\n\t\t\t\t\tprint(f"Renaming {file} to {new_file_name}")\n\t\t\t\tos.rename(os.path.join(base_path, file),\n\t\t\t\t\t\t  os.path.join(base_path, new_file_name))\ndef rename_files_in_directories_1(base_path=None):\n\tfor index in range(16):\n\t\tdir_path = os.path.join(base_path, f"{16 - index}")\n\t\t# Check if the directory exists\n\t\tif not os.path.isdir(dir_path):\n\t\t\tprint(f"Directory \'{dir_path}\' does not exist. Skipping.")\n\t\t\tcontinue\n\t\ttry:\n\t\t\tfor file in os.listdir(dir_path):\n\t\t\t\told_file_path = os.path.join(dir_path, file)\n\t\t\t\t# Zero-padded prefix\n\t\t\t\tnew_file_name = f"{16 - index:03d}_{file}"\n\t\t\t\tnew_file_path = os.path.join(base_path, new_file_name)\n\t\t\t\tos.rename(old_file_path, new_file_path)\n\t\t\t\tprint(f"Renamed \'{old_file_path}\' to \'{new_file_path}\'")\n\t\texcept OSError as e:\n\t\t\tprint(f"Error renaming files in \'{dir_path}\': {e}")\ndef get_current_timestamp():\n\ttimestamp = int(time.time())\n\tprint(timestamp)\n\treturn timestamp\ndef add_timestamp_to_filenames():\n\tcurrent_dir = os.getcwd()\n\ttimestamp = int(time.time())\n\tprint("add_timestamp is : ", timestamp)\n\tfor filename in os.listdir(current_dir):\n\t\tif os.path.isfile(os.path.join(current_dir, filename)) and not filename.endswith(".py"):\n\t\t\tfilename_without_ext, ext = os.path.splitext(filename)\n\t\t\tnew_filename = f"{filename_without_ext}_{timestamp}{ext}"\n\t\t\tos.replace(os.path.join(current_dir, filename),\n\t\t\t\t\t   os.path.join(current_dir, new_filename))\ndef get_Topic_in_kg(TR_MODE=0):\n\tassets_sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tif TR_MODE:\n\t\tprint("assets_sub_topic1_to_sub_topicn_folder_list:",\n\t\t\t  assets_sub_topic1_to_sub_topicn_folder_list)\n\t\tprint("OneDrive KG root directory_path:",\n\t\t\t  OneDrive_KG_note_root_directory_path)\n\tTopic = os.path.basename(OneDrive_KG_note_root_directory_path)\n\tif TR_MODE:\n\t\tprint("Topic:", Topic)\n\tnum_topic = len(assets_sub_topic1_to_sub_topicn_folder_list)\n\treg_sub1 = [r\'\\d{3}_(.+)\', r\'\\1\']\n\tif num_topic < 1:\n\t\tsub_topic1 = None\n\telif num_topic >= 1:\n\t\tsub_topic1 = assets_sub_topic1_to_sub_topicn_folder_list[0]\n\t\tmatch = re.search(reg_sub1[0], sub_topic1)\n\t\tif match:\n\t\t\tsub_topic1 = re.sub(reg_sub1[0], reg_sub1[1], sub_topic1)\n\t\t\tif TR_MODE:\n\t\t\t\tprint("sub_topic1:", sub_topic1)\n\treturn Topic, sub_topic1\ndef perform_regex_replacement_on_files(reg_string_list, path=None, files=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tif files is None:\n\t\tfiles = os.listdir(path)\n\tfor file in files:\n\t\twith open(os.path.join(path, file), "r", encoding="utf-8") as f1:\n\t\t\tcontent = f1.read()\n\t\tfor regex in reg_string_list:\n\t\t\tcontent = re.sub(regex[0], regex[1], content)\n\t\twith open(os.path.join(path, file), "w", encoding="utf-8") as f:\n\t\t\tf.write(content)\ndef perform_regex_replacement_on_files_tree(reg_string_list, path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfor root, dirs, files in os.walk(path):\n\t\tfor file in files:\n\t\t\tfile_path = os.path.join(root, file)\n\t\t\twith open(file_path, "r", encoding="utf-8") as f1:\n\t\t\t\tcontent = f1.read()\n\t\t\tnew_content = content\n\t\t\tfor regex in reg_string_list:\n\t\t\t\tnew_content = re.sub(regex[0], regex[1], new_content)\n\t\t\tif new_content != content:\n\t\t\t\twith open(file_path, "w", encoding="utf-8") as f:\n\t\t\t\t\tf.write(new_content)\ndef get_bvids_origin_topic_path(Topic, TR_MODE=0):\n\t# bvids_origin_topic_path = get_bvids_origin_topic_path(BaiduSyncdisk_assets_root)\n\t# bvids_origin_topic_path = r"C:\\BaiduSyncdisk\\Multivariable_calculus_Khan_Academy_youtube"\n\t# bvids_origin_topic_path=r\'C:\\BaiduSyncdisk\\First Principles of Computer Vision Specialization\\Features and Boundaries\'\n\tbvids_origin_topic_path = r\'C:\\BaiduSyncdisk\\00_MOOC_b\'\n\t# bvids_origin_topic_path=r\'C:\\BaiduSyncdisk\\deep\'\n\t# bvids_origin_topic_path=r\'C:\\BaiduSyncdisk\\Introduction\'\n\tif Topic is None:\n\t\traise Exception("Topic is None")\n\tbvids_origin_topic_path = os.path.join(\n\t\tbvids_origin_topic_path, Topic)\n\tif TR_MODE:\n\t\tprint("bvids_origin_topic_path:", bvids_origin_topic_path)\n\t# if os.path.basename(bvids_origin_topic_path) != Topic:\n\t#\t print("bvids_origin_topic_path:", bvids_origin_topic_path)\n\t#\t print("Topic:", Topic)\n\t#\t raise Exception("Topic name not match")\n\treturn bvids_origin_topic_path\ndef get_kg_assets_root(current_dir=None):\n\t\'\'\'\n\t\'\'\'\n\tTR_MODE = 1\n\tif current_dir is None:\n\t\tcurrent_dir = os.getcwd()\n\tsub_topic1_to_sub_topicn_folder_list = []\n\twhile True:\n\t\tif \'assets\' in os.listdir(current_dir):\n\t\t\tsub_topic1_to_sub_topicn_folder_list.reverse()\n\t\t\treturn sub_topic1_to_sub_topicn_folder_list, current_dir\n\t\telse:\n\t\t\tsub_topic1_to_sub_topicn_folder_list.append(\n\t\t\t\tos.path.basename(current_dir))\n\t\t\tcurrent_dir = os.path.dirname(current_dir)\ndef create_file_subtitle_summary_gpt_md(path=None):\n\t# Create a file named subtitle.md and summary_gpt.md\n\tprint("create_file_subtitle_summary_gpt_md")\n\tif path is None:\n\t\tpath = os.getcwd()\n\ttime_stamp = int(time.time())\n\twith open(os.path.join(path, "subtitle_"+str(time_stamp)+".md"), "w") as f:\n\t\tpass\n\twith open(os.path.join(path, "summary_gpt_"+str(time_stamp)+".md"), "w") as f:\n\t\tpass\n\twith open(os.path.join(path, "timestamps_"+str(time_stamp)+".md"), "w") as f:\n\t\tpass\ndef get_note_assets_dir_path(sub_topic1_to_sub_topicn_folder_list, current_dir):\n\t# sub_topic1_to_sub_topicn_folder_list.append(os.path.basename(current_dir))\n\t# current_dir = os.path.dirname(current_dir)\n\twhile True:\n\t\tif \'assets\' in os.listdir(current_dir):\n\t\t\tsub_topic1_to_sub_topicn_folder_list.reverse()\n\t\t\tif sub_topic1_to_sub_topicn_folder_list != []:\n\t\t\t\tnote_assets_dir_path = os.path.join(current_dir, \'assets\')\n\t\t\t\tfor folder_name in sub_topic1_to_sub_topicn_folder_list:\n\t\t\t\t\tnote_assets_dir_path = os.path.join(\n\t\t\t\t\t\tnote_assets_dir_path, folder_name)\n\t\t\t\t\t# print(note_assets_dir_path)\n\t\t\t\t\t# if os.path.isdir(note_assets_dir_path):\n\t\t\t\t\tif not os.path.exists(note_assets_dir_path):\n\t\t\t\t\t\tos.makedirs(note_assets_dir_path)\n\t\t\t\treturn note_assets_dir_path\n\t\t\t\t# else:\n\t\t\t\t#\t raise Exception(\'not a directory \',note_assets_dir_path)\n\t\t\telse:\n\t\t\t\traise Exception("No folder name found")\n\t\t\tbreak\n\t\telse:\n\t\t\tsub_topic1_to_sub_topicn_folder_list.append(\n\t\t\t\tos.path.basename(current_dir))\n\t\t\tcurrent_dir = os.path.dirname(current_dir)\ndef initialize_notes_files_structure():\n\tTR_mode = 1\n\ttimestamp = int(time.time())\n\t# Get the current directory\n\tcurrent_directory = os.getcwd()\n\tif TR_mode:\n\t\tprint(f"Current directory: {current_directory}")\n\t# Get the parent directory\n\tparent_directory = os.path.dirname(current_directory)\n\tif TR_mode:\n\t\tprint(f"Parent directory: {parent_directory}")\n\t\t# Get the name of the current directory\n\tcurrent_directory_name = os.path.basename(current_directory)\n\tif TR_mode:\n\t\tprint(f"Current directory name: {current_directory_name}")\n\t# Get the name of the parent directory\n\tparent_directory_name = os.path.basename(parent_directory)\n\tif TR_mode:\n\t\tprint(f"Parent directory name: {parent_directory_name}")\n\tstart_file = "000_"+current_directory_name+"_"+parent_directory_name+".md"\n\tif TR_mode:\n\t\tprint(f"start_file: {start_file}")\n\t# Check if file exists, if not create it\n\tstart_file__directory = os.path.join(current_directory, start_file)\n\tif not os.path.exists(start_file__directory):\n\t\twith open(start_file__directory, \'w\') as f:\n\t\t\tf.write(\'\')  # creating an empty markdown file\n\tstring_list = current_directory_name.split("_")\n\tlen_string_list = len(string_list)\n\tif len_string_list < 1:\n\t\traise ValueError("len error")\n\telif len_string_list == 1:\n\t\tif len(string_list[0]) < 2:\n\t\t\traise ValueError("len error")\n\t\tfolder_b_assets = string_list[0][0] + \\\n\t\t\tstring_list[-1][-1]+"_"+str(timestamp)\n\telif len_string_list > 1:\n\t\tfolder_b_assets = string_list[0][0] + \\\n\t\t\tstring_list[-1][0]+"_"+str(timestamp)\n\tif TR_mode:\n\t\tprint("folder_b_assets: ", folder_b_assets)\n\tassets_directory = os.path.join(current_directory, "assets")\n\t# Check if \'assets\' directory exists, if not create it\n\tif not os.path.exists(assets_directory):\n\t\tos.mkdir(assets_directory)\n\t\tif TR_mode:\n\t\t\tprint(f"\'assets\' directory created in {current_directory}")\n\tb_assets_directory = os.path.join(assets_directory, folder_b_assets)\n\tif not os.path.exists(b_assets_directory):\n\t\tos.mkdir(b_assets_directory)\n\t\tif TR_mode:\n\t\t\tprint(\n\t\t\t\tf"b_assets_directory directory created in {b_assets_directory}")\n\tfile_git_ignore = os.path.join(b_assets_directory, ".gitignore")\n\tif not os.path.exists(file_git_ignore):\n\t\twith open(file_git_ignore, \'w\') as f:\n\t\t\tf.write(\'*.flv\\n*.mp4\\n*.srt\\n*.vtt\\n*.pdf\\n*.epub\\n*.pptx\\n\')\n\tfile_readme = os.path.join(b_assets_directory, "readme.md")\n\tif not os.path.exists(file_readme):\n\t\twith open(file_readme, \'w\') as f:\n\t\t\tf.write(current_directory_name+"\\n")\ndef rename_folders_4_mooc_b(path=None, zfill_num=3):\n\tif path is None:\n\t\tpath = os.getcwd()\n\timport flags_utils\n\tFlags = flags_utils.GlobalFlags()\n\tFlags.set_flag(\'TR_MODE\', 1)\n\tTR_MODE = Flags.get_flag(\'TR_MODE\')\n\t# files_mp4 = [f for f in os.listdir(\n\t#\t path) if f.endswith(".mp4")]\n\t# files_vtt = [f for f in os.listdir(\n\t#\t path) if f.endswith(".vtt")]\n\t# files_srt = [f for f in os.listdir(\n\t#\t path) if f.endswith(".srt")]\n\tfiles = os.listdir(path)\n\t# for file_mp4 in files_mp4:\n\t# r"How Ultrasonic Energy is Created _ Science of Energy Ep. 1 _ Ethicon-Bd2xISKVyFc.mp4"\n\tr"Monopolar Electrosurgery Technology and Principles - Science of Energy Ep. 5 - E.en.srt"\n\treg_string_vid1 = [\n\t\tr\'(.+) ｜ Fuzzy Logic.+Part (\\d{1,2})\\.mp4\', \'\']\n\treg_string_sub1 = [\n\t\tr"(.+) ｜ Fuzzy Logic.+Part (\\d{1,2})(\\.en|\\.eng|\\.zh|\\.cn|\\.zho|\\.chi|\\.zh-Hans|\\.zh-Hant|)-eEY6OEpapPo(\\.vtt|\\.srt)", r\'\\1\']\n\treg_string_vid2 = [\n\t\tr\'(.+) - Science of Energy Ep. (\\d{1,2}) -.+\\.mp4\', \'\']\n\treg_string_sub2 = [\n\t\tr"(.+) - Science of Energy Ep. (\\d{1,2}) -.+\\.en\\.srt", r\'\\1\']\n\treg_sring_vid = reg_string_vid1\n\treg_sring_sub = reg_string_sub1\n\tfor file in files:\n\t\tmatch = re.search(reg_sring_vid[0], file)\n\t\tif match:\n\t\t\tseries_num = match.group(2)\n\t\t\tseries_num = series_num.zfill(zfill_num)\n\t\t\treg_string_vid_replace = series_num+"_"+r"\\1"+".mp4"\n\t\t\tif TR_MODE:\n\t\t\t\tprint("reg_string_vid_replace is:", reg_string_vid_replace)\n\t\t\tfile_name = re.sub(reg_sring_vid[0], reg_string_vid_replace, file)\n\t\t\tif TR_MODE:\n\t\t\t\tprint(file_name)\n\t\t\tos.rename(os.path.join(path, file), os.path.join(\n\t\t\t\tpath, file_name))\n\t\tmatch = re.search(reg_sring_sub[0], file)\n\t\tif match:\n\t\t\tseries_num = match.group(2)\n\t\t\tseries_num = series_num.zfill(zfill_num)\n\t\t\treg_string_sub_replace = series_num+"_"+r"\\1"+r"\\3"+r"\\4"\n\t\t\tif TR_MODE:\n\t\t\t\tprint("reg_string_sub_replace is:\\n", reg_string_sub_replace)\n\t\t\tfile_name = re.sub(reg_sring_sub[0], reg_string_sub_replace, file)\n\t\t\tif TR_MODE:\n\t\t\t\tprint("file_name is :\\n", file_name)\n\t\t\tos.rename(os.path.join(path, file), os.path.join(\n\t\t\t\tpath, file_name))\ndef zfill_folder_files(path=None, zfill_num=3):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfiles = [f for f in os.listdir(\n\t\tpath) if os.path.isfile(os.path.join(path, f))]\n\tfor file in files:\n\t\tfile_name, file_ext = os.path.splitext(file)\n\t\tfile_name_zfilled = file_name.zfill(zfill_num)\n\t\tos.rename(os.path.join(path, file), os.path.join(\n\t\t\tpath, file_name_zfilled + file_ext))\n\tdirs = [f for f in os.listdir(\n\t\tpath) if os.path.isdir(os.path.join(path, f))]\n\tfor dir in dirs:\n\t\tdir_name, dir_ext = os.path.splitext(dir)\n\t\tdir_name_zfilled = dir_name.zfill(zfill_num)\n\t\tos.rename(os.path.join(path, dir), os.path.join(\n\t\t\tpath, dir_name_zfilled + dir_ext))\ndef get_kg_bassets_folder_keyword():\n\tTR_MODE = 1\n\tsub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tif TR_MODE:\n\t\tprint("Folder list:", sub_topic1_to_sub_topicn_folder_list)\n\t\tprint("OneDrive KG root directory_path:",\n\t\t\t  OneDrive_KG_note_root_directory_path)\n\tOneDrive_KG_assets_directory_path = os.path.join(\n\t\tOneDrive_KG_note_root_directory_path, "assets")\n\tif TR_MODE:\n\t\tprint("OneDrive KG assets directory_path:",\n\t\t\t  OneDrive_KG_assets_directory_path)\n\tdirs = [directory for directory in os.listdir(OneDrive_KG_assets_directory_path) if os.path.isdir(\n\t\tos.path.join(OneDrive_KG_assets_directory_path, directory))]\n\tif TR_MODE:\n\t\tprint("dirs:", dirs)\n\treg_string = [r".+_\\d{10}", r"\\1"]\n\tfor dir in dirs:\n\t\tmatch = re.search(reg_string[0], dir)\n\t\tif match:\n\t\t\tif TR_MODE:\n\t\t\t\tprint("match.group(0):", match.group(0))\n\t\t\tkeyword_path = os.path.join(OneDrive_KG_assets_directory_path, dir)\n\t\t\tif TR_MODE:\n\t\t\t\tprint("keyword_path:", keyword_path)\n\t\t\treturn match.group(0), keyword_path\ndef get_bassets_keyword_path(current_dir=None, key_word="mc_1683793602"):\n\t\'\'\'\n\tkg and bkg 中的 bassets path\n\t\'\'\'\n\tTR_MODE = 1\n\tif current_dir is None:\n\t\tcurrent_dir = os.getcwd()\n\tkeyword_sub_topic1_to_sub_topicn_folder_list = []\n\tkeyword_sub_topic1_to_sub_topicn_folder_list.append(\n\t\tos.path.basename(current_dir))\n\tcurrent_dir = os.path.dirname(current_dir)\n\twhile True:\n\t\tif \'assets\' in os.listdir(current_dir):\n\t\t\tkeyword_sub_topic1_to_sub_topicn_folder_list.reverse()\n\t\t\tkeyword_sub_topic1_to_sub_topicn_folder_list.insert(1, key_word)\n\t\t\treturn keyword_sub_topic1_to_sub_topicn_folder_list, current_dir\n\t\telse:\n\t\t\tkeyword_sub_topic1_to_sub_topicn_folder_list.append(\n\t\t\t\tos.path.basename(current_dir))\n\t\t\tcurrent_dir = os.path.dirname(current_dir)\ndef get_Topic_in_kg_assets(TR_MODE=0):\n\tassets_sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tif TR_MODE:\n\t\tprint("assets_sub_topic1_to_sub_topicn_folder_list:",\n\t\t\t  assets_sub_topic1_to_sub_topicn_folder_list)\n\t\tprint("OneDrive KG root directory_path:",\n\t\t\t  OneDrive_KG_note_root_directory_path)\n\tTopic = os.path.basename(OneDrive_KG_note_root_directory_path)\n\tif TR_MODE:\n\t\tprint("Topic:", Topic)\n\tnum_topic = len(assets_sub_topic1_to_sub_topicn_folder_list)\n\treg_sub1 = [r\'\\d{3}_(.+)\', r\'\\1\']\n\tif num_topic <= 1:\n\t\traise Exception("num_topic<=1")\n\telif num_topic == 2:\n\t\tsub_topic1 = None\n\telif num_topic >= 3:\n\t\tmatch = re.search(\n\t\t\treg_sub1[0], assets_sub_topic1_to_sub_topicn_folder_list[1])\n\t\tif match:\n\t\t\tsub_topic1 = re.sub(reg_sub1[0], reg_sub1[1],\n\t\t\t\t\t\t\t\tassets_sub_topic1_to_sub_topicn_folder_list[1])\n\t\t\tif TR_MODE:\n\t\t\t\tprint("sub_topic1:", sub_topic1)\n\t\telse:\n\t\t\traise Exception("sub_topic1 not found")\n\tcurrent_topic = assets_sub_topic1_to_sub_topicn_folder_list[-1]\n\tcurrent_topic = re.sub(reg_sub1[0], reg_sub1[1], current_topic)\n\treturn Topic, sub_topic1, current_topic\ndef get_b_KG_directory_path(path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tif path.find("OneDrive") == -1 or path.find("KG") == -1:\n\t\traise Exception("This script is only for use with OneDrive/KG.")\n\t# if path.find("assets") ==-1:\n\t#\t raise Exception("current path is not an assets path.")\n\t# reg_search=[r\'(.+\\\\OneDrive\\\\KG\\\\)(.+)\']\n\treg_search = [\n\t\t[r\'.+\\\\OneDrive\\\\KG\\\\(.+)\', r\'C:\\\\BaiduSyncdisk\\\\assets\\\\\\1\']]\n\ttest2 = r\'C:\\BaiduSyncdisk\\assets\\O\\O1\\O17\\O172\\Multivaribale_calculus_Khan_Academy\\assets\\bvids\\mc_1683793602\\001_\\005_\'\n\ttest = r\'C:\\Users\\shade\\OneDrive\\KG\\O\\O1\\O17\\O172\\Multivaribale_calculus_Khan_Academy\\assets\\001_Thinking about multivariable functions\\005_Transformations\\003_Transformations, part 3\'\n\t# print(path)\n\tmatch1 = re.search(reg_search[0][0], path)\n\tif match1:\n\t\tpath_b_assets = re.sub(reg_search[0][0], reg_search[0][1], path)\n\t\t# print(path_b_assets)\n\t\treturn path_b_assets\ndef get_OneDrive_KG_note_path(OneDrive_KG_root, sub_topic1_to_sub_topicn_folder_list):\n\tOneDrive_KG_note_path = OneDrive_KG_root\n\tfor i in range(2, len(sub_topic1_to_sub_topicn_folder_list)-1):\n\t\tOneDrive_KG_note_path = os.path.join(\n\t\t\tOneDrive_KG_note_path, sub_topic1_to_sub_topicn_folder_list[i])\n\tprint(OneDrive_KG_note_path)\n\treturn OneDrive_KG_note_path\ndef get_current_bvid_name(path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfile = os.path.basename(path)\n\treturn file+".mp4"\ndef get_bvids_destination_long(sub_topic1_to_sub_topicn_folder_list, BaiduSyncdisk_assets_root):\n\tpath_temp = BaiduSyncdisk_assets_root\n\tfor i in range(len(sub_topic1_to_sub_topicn_folder_list)-1):\n\t\tpath_temp = os.path.join(\n\t\t\tpath_temp, sub_topic1_to_sub_topicn_folder_list[i])\n\t\tif not os.path.exists(path_temp):\n\t\t\tos.makedirs(path_temp)\n\treturn path_temp\ndef get_assets_root_path(current_dir=None):\n\tif current_dir is None:\n\t\tcurrent_dir = os.getcwd()\n\twhile True:\n\t\tif \'assets\' in os.listdir(current_dir):\n\t\t\treturn current_dir, os.path.basename(current_dir)\n\t\telse:\n\t\t\tcurrent_dir = os.path.dirname(current_dir)\n\t\t\tif current_dir == \'\':\n\t\t\t\traise Exception(\'assets folder not found\')\ndef create_output_directory(root=None):\n\tif root is None:\n\t\troot = os.getcwd()\n\toutput_dir = os.path.join(root, \'output\')\n\tif not os.path.exists(output_dir):\n\t\tos.mkdir(output_dir)\n\t# print("Created output directory %s" % output_dir)\n\treturn output_dir\ndef create_new_file_name(file):\n\tif not file.endswith(\'.md\'):\n\t\tfilename_without_ext = os.path.splitext(file)[0]\n\t\tnew_file_name = filename_without_ext+\'.md\'\n\telse:\n\t\tnew_file_name = file\n\tprint(new_file_name)\n\treturn new_file_name\ndef create_excalidraw_file_based_on_content(content=None, path=None):\n\twrite_string = """\n---\nexcalidraw-plugin: parsed\ntags: [excalidraw]\n---\n==⚠  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠==\n%%\n# Drawing\n```json\n{"type":"excalidraw","version":2,"source":"https://github.com/zsviczian/obsidian-excalidraw-plugin/releases/tag/1.9.19","elements":[],"appState":{"gridSize":null,"viewBackgroundColor":"#ffffff"}}\n```\n%%\n"""\n\text = ".excalidraw" + ".md"\n\tcreate_file_based_on_content(\n\t\twrite_string, ext, content, path)\ndef create_drawio_file_based_on_content(content=None, path=None):\n\twrite_string = """\n<svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="0px" width="0px" viewBox="-10 -10 20 20" content="&lt;mxGraphModel dx=&quot;801&quot; dy=&quot;859&quot; grid=&quot;1&quot; gridSize=&quot;10&quot; guides=&quot;1&quot; tooltips=&quot;1&quot; connect=&quot;1&quot; arrows=&quot;1&quot; fold=&quot;1&quot; page=&quot;1&quot; pageScale=&quot;1&quot; pageWidth=&quot;827&quot; pageHeight=&quot;1169&quot; math=&quot;0&quot; shadow=&quot;0&quot;&gt;&lt;root&gt;&lt;mxCell id=&quot;0&quot;/&gt;&lt;mxCell id=&quot;1&quot; parent=&quot;0&quot;/&gt;&lt;/root&gt;&lt;/mxGraphModel&gt;"><style type="text/css"></style></svg>\n"""\n\text = ".drawio.svg"\n\tcreate_file_based_on_content(\n\t\twrite_string, ext, content, path)\ndef create_file_based_on_content(write_string="", ext="", content=None, path=None):\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\tif path is None:\n\t\tpath = os.getcwd()\n\tif len(content) > 100:\n\t\traise ValueError("Content length exceeds 100 characters")\n\tif len(content) < 1:\n\t\traise ValueError("Content length is less than 1 character")\n\tif content.count("\\n") > 2:\n\t\traise TypeError("Content contains more than 2 newline characters")\n\tcontent = content.replace(\'\\n\', \' \')\n\tcontent = content.replace(\'\\r\', \' \')\n\treg = [r"\\s{2,}", r\' \']\n\tcontent = re.sub(reg[0], reg[1], content)\n\ttimestamp = str(int(time.time()))\n\tnew_name = content.strip() + "_" + timestamp+ext\n\twith open(os.path.join(path, new_name), "w", encoding="utf-8") as file:\n\t\tfile.write(write_string)\ndef rename_index_folder_files(base_dir=None):\n\tif base_dir is None:\n\t\tbase_dir = os.getcwd()\n\t# Ensure the path is absolute\n\tbase_dir = os.path.abspath(base_dir)\n\t# Iterate through the subdirectories under the base directory\n\tfor subdir in os.listdir(base_dir):\n\t\tsubdir_path = os.path.join(base_dir, subdir)\n\t\tif os.path.isdir(subdir_path):\n\t\t\t# Ensure the subdirectory name is numeric before proceeding\n\t\t\tif subdir.isnumeric():\n\t\t\t\t# Format the subdirectory name with leading zeros\n\t\t\t\tformatted_subdir = f"{int(subdir):04d}"\n\t\t\t\t# Use glob to find all .mp4 files in the subdirectory\n\t\t\t\tmp4_files = glob.glob(os.path.join(subdir_path, "*.mp4"))\n\t\t\t\t# Rename each .mp4 file\n\t\t\t\tfor mp4_file in mp4_files:\n\t\t\t\t\tbasename = os.path.basename(mp4_file)\n\t\t\t\t\tnew_name = f"{formatted_subdir}_{basename}"\n\t\t\t\t\tnew_path = os.path.join(base_dir, new_name)\n\t\t\t\t\tos.rename(mp4_file, new_path)\ndef rename_bilibili_subs(path=None):\n\t\'\'\' 重命名下载的字幕，改成视频名\'\'\'\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfiles_mp4 = glob.glob(os.path.join(path, "*.mp4"))\n\tfiles_srt = glob.glob(os.path.join(path, "*.srt"))\n\tfor file_mp4 in files_mp4:\n\t\tbasename = os.path.basename(file_mp4)\n\t\tnew_name = f"{basename.split(\'.\')[0]}.srt"\n\t\tnew_path = os.path.join(path, new_name)\n\t\tfor file_srt in files_srt:\n\t\t\tmp4 = (basename.split(\'.\')[0]).split(\'_\')[1]\n\t\t\tif mp4 in file_srt:\n\t\t\t\tos.rename(file_srt, new_path)\n'",
"flags_utils.py": "'class GlobalFlags:\n\tdef __init__(self):\n\t\tself.flags = {\n\t\t\t\'flag_one_by_one\': False,\n\t\t\t\'verbose\': False,\n\t\t\t\'debug\': True,\n\t\t\t\'TR_MODE\': True,\n\t\t\t\'TR_MODE_debug\': True,\n\t\t}\n\tdef set_flag(self, name, value):\n\t\tif name in self.flags:\n\t\t\tself.flags[name] = value\n\t\telse:\n\t\t\traise KeyError(f"Flag \'{name}\' not found.")\n\tdef get_flag(self, name):\n\t\tprint(f"Getting flag \'{name}\'")\n\t\tprint(f"Flags: {self.flags}")\n\t\treturn self.flags.get(name, None)\n\tdef toggle_flag(self, name):\n\t\tif name in self.flags:\n\t\t\tself.flags[name] = not self.flags[name]\n\t\telse:\n\t\t\traise KeyError(f"Flag \'{name}\' not found.")\ndef get_flag_default():\n\tflags = GlobalFlags()\n\tflags.set_flag(\'TR_MODE\', True)\n\treturn flags\ndef get_flag_one_by_one(TR_MODE=0):\n\tflag_one_by_one = True\n\treturn flag_one_by_one\ndef get_flag_search_sub_topic1_in_bvids_origin_topic_path(TR_MODE=0):\n\tflag_search_sub_topic1 = False\n\treturn flag_search_sub_topic1\ndef main():\n\t# Usage\n\tflags = GlobalFlags()\n\tflags.set_flag(\'debug\', True)\n\tprint(flags.get_flag(\'debug\'))  # Output: True\n\tflags.toggle_flag(\'debug\')\n\tprint(flags.get_flag(\'debug\'))  # Output: False\nif __name__ == \'__main__\':\n\tmain()\n'",
"html_processor.py": "'import os\nimport re\nimport time\nimport urllib.parse\n# import aspose.words as aw\nimport subprocess\nfrom typing import Optional\nimport glob\ndef convert_html_to_md(input_directory=None, output_directory=None):\n\tif input_directory is None:\n\t\tinput_directory = os.getcwd()\n\tif output_directory is None:\n\t\toutput_directory = os.path.join(input_directory, "md")\n\ttry:\n\t\t# Create the output directory if it does not exist\n\t\tos.makedirs(output_directory, exist_ok=True)\n\t\t# List all files in the input directory\n\t\tfiles = [f for f in os.listdir(input_directory) if f.endswith(\'.html\')]\n\t\tfor file in files:\n\t\t\tinput_file = os.path.join(input_directory, file)\n\t\t\toutput_file = os.path.join(\n\t\t\t\toutput_directory, file.replace(\'.html\', \'.md\'))\n\t\t\t# Convert HTML to Markdown and extract images\n\t\t\tsubprocess.run([\'pandoc\', \'--extract-media=\' + output_directory,\n\t\t\t\t\t\t   input_file, \'-o\', output_file], check=True)\n\t\tprint(\n\t\t\tf\'Successfully converted HTML files to Markdown in {output_directory}\')\n\texcept subprocess.CalledProcessError as e:\n\t\tprint(f\'Failed to convert HTML to Markdown: {e}\')\n\texcept Exception as e:\n\t\tprint(f\'An error occurred: {e}\')\ndef change_html_title(path: Optional[str] = None) -> None:\n\t"""\n\tChange the title of all HTML files in the specified directory to match their filenames.\n\tParameters:\n\tpath (str): The directory to search for HTML files. Defaults to the current working directory.\n\tReturns:\n\tNone\n\t"""\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfiles = glob.glob(os.path.join(path, \'*.html\'))\n\tfor file in files:\n\t\tinput_file = os.path.join(path, file)\n\t\tinput_file = input_file.replace(\'\\\\\', \'/\')\n\t\tif os.path.exists(input_file) and os.path.isfile(input_file):\n\t\t\ttry:\n\t\t\t\twith open(input_file, \'r\', encoding="utf-8") as f:\n\t\t\t\t\tcontent = f.read()\n\t\t\t\treg_string = r\'<title>.*?</title>\'\n\t\t\t\tcontent = re.sub(\n\t\t\t\t\treg_string, f\'<title>{os.path.splitext(os.path.basename(file))[0]}</title>\', content)\n\t\t\t\twith open(input_file, \'w\', encoding="utf-8") as f:\n\t\t\t\t\tf.write(content)\n\t\t\texcept Exception as e:\n\t\t\t\tprint(f"An error occurred while processing {input_file}: {e}")\n\t\telse:\n\t\t\tprint(f"File {input_file} does not exist or is not accessible.")\ndef html2md(path=None, output_root="C://Output//", output_folder_name=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\ttimestamp = int(time.time())\n\tintput_path = path\n\tinput_floder_name = os.path.basename(intput_path)\n\t# replace_list_regex2=[[r\'Part \\d{2}-Module \\d{2}-Lesson (\\d{2})_(.+)\',r\'0\\1_\\2\'],]\n\tinput_floder_name = re.sub(\n\t\tr\'Part \\d{2}-Module \\d{2}-Lesson (\\d{2})_(.+)\', r\'0\\1_\\2\', input_floder_name)\n\t# Part 01-Module 01-Lesson 01_Welcome to the C++ Developer Nanodegree Program\n\tinput_floder_name = input_floder_name.replace(" ", "_")\n\toutput_path = os.path.join(\n\t\toutput_root, output_folder_name, input_floder_name)\n\tos.makedirs(output_path, exist_ok=True)\n\tlistfiles = os.listdir(intput_path)\n\tmp4_list = [\n\t\tfilename for filename in listfiles if filename.endswith(".mp4")]\n\t# print(listfiles)\n\tfor i in range(len(listfiles)):\n\t\tfilename = listfiles[i]  # get all file list\n\t\tif filename.endswith(".html"):\n\t\t\tinput_file = os.path.join(intput_path, filename)\n\t\t\tdoc = aw.Document(input_file)\n\t\t\toutput_file = os.path.join(\n\t\t\t\toutput_path, filename.replace(".html", ".md"))\n\t\t\t# print(output_path)\n\t\t\tdoc.save(output_file)\n\toutput_files_list = os.listdir(output_path)\n\treplace_list_regex = [[r\'!\\[\\]\\(.+\\.001\\.png\\)\', r\'\'],\n\t\t\t\t\t\t  [r\'(!\\[\\]|!\\[.+\\])(\\(.+)(\\.png|\\.jpg|\\.gif|\\.jpeg|\\.svg|\\.wbem)\\)\',\n\t\t\t\t\t\t\t  r\'\\1\\2\'+f\'_{timestamp}\'+r\'\\3)\'],\n\t\t\t\t\t\t  [r\'\\*\\*Evaluation Only\\. Created with Aspose\\.Words\\. Copyright 2003-2023 Aspose Pty Ltd\\.\\*\\*\', r\'\'],\n\t\t\t\t\t\t  [r\'\\*\\*Created with an evaluation copy of Aspose.Words. To discover the full versions of our APIs please visit: https://products.aspose.com/words/\\*\\*\', r\'\'],\n\t\t\t\t\t\t  [r\'\\[udacimak v1.4.1\\]\\(https://github.com/udacimak/udacimak#readme\\)\', r\'\'],\n\t\t\t\t\t\t  [r\'\\[.+\\]\\(.+\\.html\\)\', r\'\'],\n\t\t\t\t\t\t  [r\'\\n{3,}\', r\'\\n\\n\'],\n\t\t\t\t\t\t  [r\'`[ ]+`\', r\'\t\'],\n\t\t\t\t\t\t  ]\n\tfor i in range(len(output_files_list)):\n\t\tfilename = output_files_list[i]\n\t\tif filename.endswith(".001.png"):\n\t\t\tos.remove(os.path.join(output_path, filename))\n\t\t\tcontinue\n\t\tif filename.endswith(".md"):\n\t\t\tif filename == "index.md":\n\t\t\t\tos.remove(os.path.join(output_path, filename))\n\t\t\t\tcontinue\n\t\t\twith open(os.path.join(output_path, filename), \'r\', encoding=\'UTF-8\') as f:\n\t\t\t\tcontent = f.read()\n\t\t\twith open(os.path.join(output_path, filename), \'w\', encoding=\'UTF-8\') as f:\n\t\t\t\tfor replace_list in replace_list_regex:\n\t\t\t\t\tcontent = re.sub(replace_list[0], replace_list[1], content)\n\t\t\t\t# f.write(content)\n\t\t\t\tlines = content.splitlines()\n\t\t\t\tfor line in lines:\n\t\t\t\t\tif len(line) > 4:\n\t\t\t\t\t\tfor file_mp4 in mp4_list:\n\t\t\t\t\t\t\tword_list = line.split(" ")\n\t\t\t\t\t\t\tflag = 0\n\t\t\t\t\t\t\tflag_out = 0\n\t\t\t\t\t\t\tfor word in word_list:\n\t\t\t\t\t\t\t\tif file_mp4.find(word) > -1:\n\t\t\t\t\t\t\t\t\tflag = flag+1\n\t\t\t\t\t\t\t\telif file_mp4.find(word) == -1:\n\t\t\t\t\t\t\t\t\tflag_out = flag_out+1\n\t\t\t\t\t\t\tif flag:\n\t\t\t\t\t\t\t\tif flag_out:\n\t\t\t\t\t\t\t\t\t# print(line)\n\t\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tpath_mp4 = os.path.join(\n\t\t\t\t\t\t\t\t\t\tintput_path, file_mp4)\n\t\t\t\t\t\t\t\t\turl_path = urllib.parse.quote(\n\t\t\t\t\t\t\t\t\t\tos.path.abspath(path_mp4))\n\t\t\t\t\t\t\t\t\turl = "file:///" + \\\n\t\t\t\t\t\t\t\t\t\turl_path.replace("\\\\", "/")\n\t\t\t\t\t\t\t\t\tline = line+"\\n\\n" + \\\n\t\t\t\t\t\t\t\t\t\tf"[{file_mp4}]({url})\\n" + \\\n\t\t\t\t\t\t\t\t\t\tf"![{file_mp4}]({url})"\n\t\t\t\t\tf.write(line+"\\n")\n\tmd_note_process(output_path)\n\toutput_files_list = os.listdir(output_path)\n\toutput_path_md = output_path\n\toutput_path_img = os.path.join(\n\t\toutput_root, "imgs", output_folder_name, input_floder_name)\n\t# Create the output directory and its subdirectory if they don\'t exist\n\ttry:\n\t\tos.makedirs(output_path_img, exist_ok=True)\n\texcept FileNotFoundError as e:\n\t\tif e.winerror == 206:\n\t\t\t# Shorten the filename and try again\n\t\t\toutput_path_img = output_path_img = os.path.join(\n\t\t\t\toutput_path_md, "imgs")\n\t\t\tos.makedirs(output_path_img, exist_ok=True)\n\t\telse:\n\t\t\t# If it\'s not WinError 206, raise the original error\n\t\t\traise e\n\tfor i in range(len(output_files_list)):\n\t\tfilename = output_files_list[i]\n\t\tif filename.endswith(".md"):\n\t\t\ttry:\n\t\t\t\tos.replace(os.path.join(output_path, filename),\n\t\t\t\t\t\t   os.path.join(output_path_md, filename))\n\t\t\texcept FileExistsError:\n\t\t\t\tos.remove(os.path.join(output_path_md, filename))\n\t\t\t\tos.replace(os.path.join(output_path, filename),\n\t\t\t\t\t\t   os.path.join(output_path_md, filename))\n\t\tif filename.endswith(".png") or filename.endswith(".jpg") or filename.endswith(".jpeg") or filename.endswith(".gif"):\n\t\t\tfilename_ext = os.path.splitext(filename)[1]\n\t\t\tfilename_without_ext = os.path.splitext(filename)[0]\n\t\t\tfilename_img = filename_without_ext+f\'_{timestamp}\'+filename_ext\n\t\t\ttry:\n\t\t\t\tos.replace(os.path.join(output_path, filename),\n\t\t\t\t\t\t   os.path.join(output_path_img, filename_img))\n\t\t\texcept FileExistsError:\n\t\t\t\tos.remove(os.path.join(output_path_img, filename_img))\n\t\t\t\tos.replace(os.path.join(output_path, filename),\n\t\t\t\t\t\t   os.path.join(output_path_img, filename_img))\n\t\t\texcept FileNotFoundError as e:\n\t\t\t\tif e.winerror == 3:\n\t\t\t\t\toutput_path_img = output_path_img = os.path.join(\n\t\t\t\t\t\toutput_path_md, "imgs")\n\t\t\t\t\tos.makedirs(output_path_img, exist_ok=True)\n\t\t\t\t\tos.replace(os.path.join(output_path, filename),\n\t\t\t\t\t\t\t   os.path.join(output_path_img, filename_img))\n\t\t\t\telse:\n\t\t\t\t\t# If it\'s not WinError 206, raise the original error\n\t\t\t\t\traise e\ndef html2md2():\n\timport html2markdown\n\tfiles = [f for f in os.listdir() if os.path.isfile(f)]\n\tfor file in files:\n\t\tif file.endswith(".html"):\n\t\t\twith open(file, \'r\', encoding=\'utf-8\') as f:\n\t\t\t\thtml_string = f.read()\n\t\t\tmarkdown_text = html2markdown.convert(html_string)\n\t\t\twith open(file[:-4] + \'.md\', \'w\', encoding=\'utf-8\') as f:\n\t\t\t\tf.write(markdown_text)\ndef html2md_tree():\n\tfiles = [f for f in os.listdir() if os.path.isfile(f)]\n\tdirectories = [f for f in os.listdir() if os.path.isdir(f)]\n\toutput_folder_dict = dict()\n\tfor directory in directories:\n\t\tsearch_str = r\'Part (\\d{2})_(.+)\'\n\t\tmatch = re.search(search_str, directory)\n\t\tif match:\n\t\t\toutput_folder_dict[match.group(\n\t\t\t\t1)] = \'0\'+match.group(1)+"_"+match.group(2)\n\tfor directory in directories:\n\t\tsearch_str = r\'Part (\\d{2})-Module \\d{2}-Lesson (\\d{2})_(.+)\'\n\t\tmatch = re.search(search_str, directory)\n\t\tif match:\n\t\t\toutput_folder1 = "C:\\\\Output\\\\"\n\t\t\toutput_folder2 = output_folder_dict[match.group(1)]\n\t\t\t# output_folder=os.path.join(output_folder1,output_folder2)\n\t\t\tinput_path = os.path.join(os.getcwd(), directory)\n\t\t\thtml2md(input_path, output_folder1, output_folder2)\n'",
"main.py": "'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport argparse\ndef test():\n\tpass\ndef md_note_process(num=0, head_num=1):\n\timport md_helper\n\timport html_processor\n\toperations = {\n\t\t1: md_helper.remove_back_matter_and_copy_code,\n\t\t2: md_helper.process_md_head_to_hn,\n\t\t3: md_helper.retrieve_document_summary_info,\n\t\t4: md_helper.format_ocr_text,\n\t\t5: md_helper.create_file_based_on_content,\n\t\t6: md_helper.format_2_gpt_input,\n\t\t7: md_helper.mermaid_format,\n\t\t8: html_processor.convert_html_to_md,\n\t\t9: html_processor.change_html_title,\n\t\t10: md_helper.create_node_for_mermaid,\n\t}\n\tif num in operations:\n\t\tif (num == 2):\n\t\t\toperations[num](head_num)\n\t\telse:\n\t\t\toperations[num]()\n\telif num == 0:\n\t\tprint("Available operations:")\n\t\tfor num, func in operations.items():\n\t\t\tprint(f"{num}: {func.__name__}")\n\telse:\n\t\traise ValueError("Invalid operation number.")\ndef wiki_note_process(num=0):\n\timport wiki_processor\n\toperations = {\n\t\t1: wiki_processor.remove_wiki_edit_link,\n\t\t2: wiki_processor.remove_wiki_equation_svg,\n\t}\n\tif num in operations:\n\t\toperations[num]()\n\telif num == 0:\n\t\tprint("Available operations:")\n\t\tfor num, func in operations.items():\n\t\t\tprint(f"{num}: {func.__name__}")\n\telse:\n\t\traise ValueError("Invalid operation number.")\ndef book_processor(num=0):\n\timport book_processor\n\toperations = {\n\t\t1: book_processor.perform_regex_replacement_on_index_file,\n\t\t2: book_processor.perform_regex_replacement_on_zhi_book_mds_name,\n\t\t3: book_processor.rename_files_base_on_index_markdown,\n\t\t4: book_processor.prepend_filename_as_header_if_chapter_present,\n\t\t5: book_processor.lower_header_level_in_md_files,\n\t\t6: book_processor.remove_md_copy_code,\n\t\t7: book_processor.perform_regex_replacement_on_zhi_mds,\n\t\t8: book_processor.convert_zhi_footnote_to_obsidian,\n\t\t10: book_processor.merge_all_md_files_into_one,\n\t}\n\tif num in operations:\n\t\toperations[num]()\n\telif num == 0:\n\t\tprint("Available operations:")\n\t\tfor num, func in operations.items():\n\t\t\tprint(f"{num}: {func.__name__}")\n\telse:\n\t\traise ValueError(\n\t\t\t"Invalid operation number. Please choose a number between 0 and 4.")\ndef vid_note_process(num=0):\n\timport vid_note_processor\n\toperations = {\n\t\t1: vid_note_processor.initialize_vid_note_file_structure,\n\t\t2: vid_note_processor.generate_vid_note_with_timeline_from_text_summary,\n\t\t3: vid_note_processor.generate_vid_note_with_timeline_from_timestamps,\n\t\t4: vid_note_processor.convert_md_vid_link_to_html,\n\t\t5: vid_note_processor.convert_md_vid_link_to_html_tree,\n\t\t6: vid_note_processor.vtt_format_4_gpt,\n\t\t7: vid_note_processor.mul_initialize_vid_note_file_structure,\n\t}\n\tif num in operations:\n\t\toperations[num]()\n\telif num == 0:\n\t\tprint("Available operations:")\n\t\tfor num, func in operations.items():\n\t\t\tprint(f"{num}: {func.__name__}")\n\telse:\n\t\traise ValueError("Invalid operation number.")\ndef os_file_processor(num=0):\n\timport file_operations_utils\n\timport markmind\n\toperations = {\n\t\t1: file_operations_utils.initialize_notes_files_structure,\n\t\t2: file_operations_utils.add_timestamp_to_filenames,\n\t\t3: file_operations_utils.get_current_timestamp,\n\t\t4: file_operations_utils.open_b_assets_folder,\n\t\t5: file_operations_utils.rename_folders_4_mooc_b,\n\t\t6: file_operations_utils.create_drawio_file_based_on_content,\n\t\t7: file_operations_utils.create_excalidraw_file_based_on_content,\n\t\t8: file_operations_utils.rename_index_folder_files,\n\t\t9: file_operations_utils.rename_bilibili_subs,\n\t\t10: markmind.create_annotator,\n\t\t11: file_operations_utils.rename_files_in_directories,\n\t}\n\tif num in operations:\n\t\toperations[num]()\n\telif num == 0:\n\t\tprint("Available operations:")\n\t\tfor num, func in operations.items():\n\t\t\tprint(f"{num}: {func.__name__}")\n\telse:\n\t\traise ValueError("Invalid operation number.")\ndef get_prompts(num=0):\n\timport prompt_generator\n\toperations = {\n\t\t1: prompt_generator.video_summarization_expert_one,\n\t\t2: prompt_generator.get_prompt_explain_c_cpp,\n\t\t3: prompt_generator.chatbot_prompt_expert,\n\t\t4: prompt_generator.Translate_Chinese_sentence_into_function_name,\n\t\t5: prompt_generator.Expert_Prompt_Creator,\n\t\t6: prompt_generator.dot2mermaid,\n\t\t7: prompt_generator.code_improve,\n\t\t8: prompt_generator.format_code_current_dir,\n\t}\n\tif num in operations:\n\t\toperations[num]()\n\telif num == 0:\n\t\tprint("Available operations:")\n\t\tfor num, func in operations.items():\n\t\t\tprint(f"{num}: {func.__name__}")\n\telse:\n\t\traise ValueError("Invalid operation number.")\ndef main():\n\t# create a parser object\n\tparser = argparse.ArgumentParser()\n\t# add arguments for each function\n\tparser.add_argument(\'-t\', \'--timestamp\', type=str, default=r\'1676880280\',\n\t\t\t\t\t\thelp=\'input timestamp to pass to the function\')\n\tparser.add_argument(\'-u\', \'--str_url\', type=str, default=r\'test\',\n\t\t\t\t\t\thelp=\'input str_url to pass to the function\')\n\tparser.add_argument(\'-i\', \'--input_int\', type=int, default=r\'0\',\n\t\t\t\t\t\thelp=\'input input_int to pass to the function\')\n\tparser.add_argument(\'-hn\', \'--head_num\', type=int, default=r\'1\',\n\t\t\t\t\t\thelp=\'input head_num to pass to the function\')\n\tparser.add_argument(\'-mdx\', \'--mdx2md\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call mdx2md\')\n\tparser.add_argument(\'-oaf\', \'--open_b_assets_folder\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call open_b_assets_folder\')\n\tparser.add_argument(\'-md\', \'--md_note_process\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call md_note_process\')\n\tparser.add_argument(\'-wiki\', \'--wiki_note_process\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call wiki_note_process\')\n\tparser.add_argument(\'-vid\', \'--vid_note_process\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call vid_note_process\')\n\tparser.add_argument(\'-test\', \'--test\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call test\')\n\tparser.add_argument(\'-bp\', \'--book_processor\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call book_processor\')\n\tparser.add_argument(\'-ofp\', \'--os_file_processor\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call os_file_processor\')\n\tparser.add_argument(\'-gp\', \'--get_prompts\',\n\t\t\t\t\t\taction=\'store_true\', help=\'call get_prompts\')\n\t# parse the command-line arguments\n\targs = parser.parse_args()\n\t# call the appropriate function based on the arguments\n\tif args.md_note_process:\n\t\tmd_note_process(args.input_int, args.head_num)\n\telif args.wiki_note_process:\n\t\twiki_note_process(args.input_int)\n\telif args.vid_note_process:\n\t\tvid_note_process(args.input_int)\n\telif args.test:\n\t\ttest(args.input_int)\n\telif args.book_processor:\n\t\tbook_processor(args.input_int)\n\telif args.os_file_processor:\n\t\tos_file_processor(args.input_int)\n\telif args.get_prompts:\n\t\tget_prompts(args.input_int)\n\telse:\n\t\tprint("Invalid argument")\nif __name__ == "__main__":\n\tmain()\n'",
"markmind.py": "'import os\nimport logging\nimport file_operations_utils\nimport time\nimport urllib.parse\nimport re\n# Set up logging\nlogging.basicConfig(level=logging.DEBUG)\n# Constants\nTR_MODE = True\nASSETS_FOLDER_NAME = "assets"\ndef get_annotator_id(file_name):\n\tfile_name_temp = file_name.replace(" ", "_")\n\treturn file_name_temp + "_" + str(int(time.time())), file_name_temp\ndef get_annotate_image_target_path(path):\n\ttry:\n\t\treturn path.split("KG\\\\")[1]\n\texcept IndexError:\n\t\tlogging.error("Invalid path format")\n\t\treturn None\ndef create_annotator(path=None):\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfiles_annotator = [f for f in os.listdir(\n\t\tpath) if f.endswith(\'_annotator.md\')]\n\t# get bassets folder path\n\tbig_assets_path = file_operations_utils.get_b_KG_directory_path(path)\n\tif big_assets_path is None:\n\t\traise FileNotFoundError(\n\t\t\t"Could not find assets folder in current folder path")\n\tif TR_MODE:\n\t\tlogging.debug("big_assets_path: %s", big_assets_path)\n\tfor root, dirs, files in os.walk(big_assets_path):\n\t\tfor file in files:\n\t\t\tif file.endswith(".pdf"):\n\t\t\t\tfile_name = os.path.splitext(file)[0]\n\t\t\t\tannotator_id, file_name_temp = get_annotator_id(file_name)\n\t\t\t\tif TR_MODE:\n\t\t\t\t\tlogging.debug("annotator_id: %s", annotator_id)\n\t\t\t\tannotate_target_path = os.path.join(root, file)\n\t\t\t\t# annotate_target_path = urllib.parse.quote(\n\t\t\t\t#\t os.path.abspath(annotate_target_path))\n\t\t\t\tannotate_image_target_full_path = os.path.join(path, "imgs")\n\t\t\t\tannotate_image_target_path = get_annotate_image_target_path(\n\t\t\t\t\tannotate_image_target_full_path)\n\t\t\t\tcontent_annotator = f"""\n---\nid: {annotator_id}\nannotate-type: pdf\nannotate-target: file://{annotate_target_path}\nannotate-image-target: {annotate_image_target_path}\n---\n"""\n\t\t\t\tannotator_file_name = f"{annotator_id}_annotator.md"\n\t\t\t\tannotator_path = os.path.join(path, annotator_file_name)\n\t\t\t\treg_anno = file_name_temp+"_"+r"\\d{10}"+"_annotator.md"\n\t\t\t\tflag = False\n\t\t\t\tfor file_annotator in files_annotator:\n\t\t\t\t\tmatch = re.search(reg_anno, file_annotator)\n\t\t\t\t\tif match:\n\t\t\t\t\t\tflag = True\n\t\t\t\tif not flag:\n\t\t\t\t\twith open(annotator_path, "w", encoding="utf-8") as f:\n\t\t\t\t\t\tf.write(content_annotator)\n# def create_annotator(path=None):\n#\t if path is None:\n#\t\t path = os.getcwd()\n#\t TR_MODE = 1\n#\t # IS "\\OneDrive\\KG\\" contained by current folder path? if not, raise error\n#\t # get bassets folder path\n#\t big_assets_path = file_operations_utils.get_b_KG_directory_path(path)\n#\t if TR_MODE:\n#\t\t print("big_assets_path:", big_assets_path)\n#\t if big_assets_path is None:\n#\t\t raise Exception("Could not find assets folder in current folder path")\n#\t for root, dirs, files in os.walk(big_assets_path):\n#\t\t for file in files:\n#\t\t\t if file.endswith(".pdf"):\n#\t\t\t\t file_name = file.split(".")[0]\n#\t\t\t\t file_name_temp = file_name.replace(" ", "_")\n#\t\t\t\t annotator_id = file_name_temp+"_"+str(int(time.time()))\n#\t\t\t\t if TR_MODE:\n#\t\t\t\t\t print("annotator_id:", annotator_id)\n#\t\t\t\t annotate_target_path = os.path.join(root, file)\n#\t\t\t\t if TR_MODE:\n#\t\t\t\t\t print("annotate_target_path:", annotate_target_path)\n#\t\t\t\t annotate_image_target_full_path = os.path.join(path, "imgs")\n#\t\t\t\t if TR_MODE:\n#\t\t\t\t\t print("annotate_image_target_full_path:",\n#\t\t\t\t\t\t   annotate_image_target_full_path)\n#\t\t\t\t # annotate_image_target_path= annotate_image_target_full_path after \\OneDrive\\KG\\\n#\t\t\t\t annotate_image_target_path = annotate_image_target_full_path.split(\n#\t\t\t\t\t "KG\\\\")[1]\n#\t\t\t\t if TR_MODE:\n#\t\t\t\t\t print("annotate_image_target_path:",\n#\t\t\t\t\t\t   annotate_image_target_path)\n#\t\t\t\t content_annotator = f"""\n# ---\n# id: {annotator_id}\n# annotate-type: pdf\n# annotate-target: file://{annotate_target_path}\n# annotate-image-target: {annotate_image_target_path}\n# ---\n# """\n#\t\t\t\t annotator_file_name = annotator_id + "_annotator"+".md"\n#\t\t\t\t annotator_path = os.path.join(path, annotator_file_name)\n#\t\t\t\t with open(annotator_path, "w", encoding="utf-8") as f:\n#\t\t\t\t\t f.write(content_annotator)\n'",
"md_helper.py": "'from typing import Optional\nimport glob\nimport pyperclip\nimport os\nimport re\nimport subprocess\nimport time\nimport file_operations_utils\ndef text_replace(root_dir: str, replace_list: list):\n\tassets_root_path, assets_root_dir = file_operations_utils.get_assets_root_path()\n\toutput_dir = file_operations_utils.create_output_directory(\n\t\tassets_root_path)\n\tfor filename_with_ext in os.listdir(root_dir):\n\t\tif filename_with_ext.endswith(\'.md\'):\n\t\t\tsrc_path = os.path.join(root_dir, filename_with_ext)\n\t\t\tdest_path = os.path.join(output_dir, filename_with_ext)\n\t\t\twith open(src_path, \'r\', encoding=\'UTF-8\') as f_src, open(dest_path, \'w\', encoding=\'UTF-8\') as f_dest:\n\t\t\t\tfor line in f_src:\n\t\t\t\t\tfor replace_item in replace_list:\n\t\t\t\t\t\tline = line.replace(replace_item[0], replace_item[1])\n\t\t\t\t\tf_dest.write(line)\ndef mdx2md(timestamp: int = 1676880280):\n\tassets_root_path, assets_root_dir = file_operations_utils.get_assets_root_path()\n\toutput_dir = file_operations_utils.create_output_directory(\n\t\tassets_root_path)\n\tcwd = os.getcwd()\n\t# text_replace_list_mdx2md3 = [\n\t#\t\t\t\t\t\t\t  ]\n\t# replace_list = text_replace_list_mdx2md3\n\t# <Figure\n\tfor filename_with_ext in os.listdir(cwd):\n\t\tif filename_with_ext.endswith(\'.md\'):\n\t\t\tsrc_path = os.path.join(cwd, filename_with_ext)\n\t\t\tdest_path = os.path.join(output_dir, filename_with_ext)\n\t\t\t# with open(src_path, \'r\', encoding=\'UTF-8\') as f_src, open(dest_path, \'w\', encoding=\'UTF-8\') as f_dest:\n\t\t\t#\t for line in f_src:\n\t\t\t#\t\t for replace_item in replace_list:\n\t\t\t#\t\t\t line = line.replace(replace_item[0], replace_item[1])\n\t\t\t#\t\t f_dest.write(line)\n\t\t\twith open(src_path, \'r\', encoding=\'UTF-8\') as f_src:\n\t\t\t\tcontent = f_src.read()\n\t\t\t# Define the regex pattern and replacement string\n\t\t\treplace_list_regex = [\n\t\t\t\t\t\t\t\t [r"<PiCreature\\n{0,}\\s{0,}(.+)\\n{0,}\\s{0,}(.+)\\n{0,}\\s{0,}/>", r"\\1\\n\\2\\n"],\n\t\t\t\t# [r"show=\\"video\\"\\n", r""],\n\t\t\t\t#  [r"<!--", r""],\n\t\t\t\t#  [r"-->", r""],\n\t\t\t\t\t\t\t\t [r"<Question", r"---"],\n\t\t\t\t\t\t\t\t [r"<FreeResponse>", r"---"],\n\t\t\t\t[r"</FreeResponse>", r"---"],\n\t\t\t\t[r"</Question>", r"---"],\n\t\t\t\t[r\'\'\'<Figure[\\n ]{1,}image="(.+)(\\.svg|\\.png|\\.jpg)"[\\w ._="\'\\n_%]{0,}/>\'\'\',\n\t\t\t\t\t\t\t\t\t r\'![](\\1_\'+str(timestamp)+r\'\\2)\'],\n\t\t\t\t[r\'<Accordion\\stitle=".+">\\n\', r\'\'],\n\t\t\t\t[r\'</Accordion>\\n\', r\'\'],\n\t\t\t\t# [r\'emotion="\\w+"[ \\t]+\\n\', r\'\'],\n\t\t\t\t# [r\'flip=\\{(true|false)\\}\\n\', r\'\'],\n\t\t\t\t# [r\'(?s)<Question .+?</Question>\', r\'tttttttttttttttttttt\'],\n\t\t\t\t[r\'answer=\\{(\\d)\\}[ \\n\\t]{0,}>\',\n\t\t\t\t\t\t\t\t\t r\'\\n<details><summary>answer</summary><p>Choice= \\1</p></details>\\n\\n- **Explanation**\'],\n\t\t\t\t# [r\'\'\'<Question[\\n \\t]{0,}question="(.+)"[\\n \\t]{0,}choice1="(.+)"[\\n \\t]{0,}choice2="(.+)"[\\n \\t]{0,}choice3="(.+)"[\\n \\t]{0,}choice4="(.+)"[\\n \\t]answer=\\{(\\d)\\}[\\n \\t]{0,}>\'\'\',r\'- **Question**\\n\\t\\1\']\n\t\t\t\t[r\'[ \\t]{0,}question="(.+)"\',\n\t\t\t\t\t\t\t\t\t r\'- **Question**\\n\\t\\1\'],\n\t\t\t\t[r\'[ \\t]{0,}choice1="(.+)"\',\n\t\t\t\t\t\t\t\t\t r\'\t- **Choice 1=** \\1\'],\n\t\t\t\t[r\'[ \\t]{0,}choice2="(.+)"\',\n\t\t\t\t\t\t\t\t\t r\'\t- **Choice 2=** \\1\'],\n\t\t\t\t[r\'[ \\t]{0,}choice3="(.+)"\', r\'\t- **Choice 3=** \\1\'],\n\t\t\t\t[r\'[ \\t]{0,}choice4="(.+)"\', r\'\t- **Choice 4=** \\1\'],\n\t\t\t\t# [r\'video=".+\\.mp4"\', r\'\'],\n\t\t\t\t# [r\'show="video"\', r\'\'],\n\t\t\t\t[r\'([ \\t]{0,}\\n){3,}\', r\'\\1\\1\'],\n\t\t\t\t# [\'/>\', r\'\'],\n\t\t\t]\n\t\t\tfor i in range(len(replace_list_regex)):\n\t\t\t\tpattern = replace_list_regex[i][0]\n\t\t\t\treplacement = replace_list_regex[i][1]\n\t\t\t\t# Perform the regex replacement\n\t\t\t\tcontent = re.sub(pattern, replacement, content)\n\t\t\t# Write the modified content to the output Markdown file with UTF-8 encoding\n\t\t\twith open(dest_path, \'w\', encoding=\'utf-8\') as file:\n\t\t\t\tfile.write(content)\ndef remove_back_matter_and_copy_code(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_Back_matter_template = [r"---\\n\\n- created:.+\\n- source: .+", r""]\n\treg_string_list.extend([reg_Back_matter_template])\n\treg_string_copy_code = [r"```\\n(.+)Copy code", r"```\\1\\n"]\n\treg_string_list.extend([reg_string_copy_code])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, directory_path, files_md)\ndef Is_head_line(line):\n\tpattern = r"^(#{1,}) (.+|)"\n\tmatch = re.search(pattern, line)\n\tif match:\n\t\treturn True\n\telse:\n\t\treturn False\ndef get_highest_head_level(content):\n\tlines = content.split(\'\\n\')\n\tlowest_level = float(\'inf\')\n\tpattern = re.compile(r"^(#{1,}) ")\n\tfor line in lines:\n\t\tmatch = pattern.match(line)\n\t\tif match:\n\t\t\tlevel = len(match.group(1))\n\t\t\tif level < lowest_level:\n\t\t\t\tlowest_level = level\n\treturn lowest_level if lowest_level != float(\'inf\') else None\ndef downgrade_heads(content, downgrade_level):\n\tlines = content.split(\'\\n\')\n\tnew_lines = []\n\tfor line in lines:\n\t\tif Is_head_line(line):\n\t\t\thead_level = 0\n\t\t\tfor char in line:\n\t\t\t\tif char == \'#\':\n\t\t\t\t\thead_level += 1\n\t\t\t\telse:\n\t\t\t\t\tbreak\n\t\t\tif head_level > 0:\n\t\t\t\tnew_head_level = head_level + downgrade_level\n\t\t\t\tif new_head_level > 6:\n\t\t\t\t\tnew_head_level = 6\n\t\t\t\tnew_line = \'#\' * new_head_level + line[head_level:]\n\t\t\t\tnew_lines.append(new_line)\n\t\telse:\n\t\t\tnew_lines.append(line)\n\treturn \'\\n\'.join(new_lines)\ndef upgrade_heads(content, upgrade_level):\n\tlines = content.split(\'\\n\')\n\tnew_lines = []\n\tfor line in lines:\n\t\thead_level = 0\n\t\tfor char in line:\n\t\t\tif char == \'#\':\n\t\t\t\thead_level += 1\n\t\t\telse:\n\t\t\t\tbreak\n\t\tif head_level > 0:\n\t\t\tnew_head_level = head_level - upgrade_level\n\t\t\tif new_head_level < 1:\n\t\t\t\tnew_head_level = 1\n\t\t\tnew_line = \'#\' * new_head_level + line[head_level:]\n\t\t\tnew_lines.append(new_line)\n\t\telse:\n\t\t\tnew_lines.append(line)\n\treturn \'\\n\'.join(new_lines)\ndef degrade_markdown_by_head_number(head_number):\n\tcontent = pyperclip.paste()\n\tTR_MODE = 1\n\thighest_head_level = get_highest_head_level(content)\n\t# highest_head_level=3\n\tif TR_MODE:\n\t\tprint("highest_head_level: ", highest_head_level)\n\t\tprint("head_number: ", head_number)\n\tif highest_head_level < head_number:\n\t\tcontent = downgrade_heads(\n\t\t\tcontent, head_number-highest_head_level)\n\t\tpyperclip.copy(content)\ndef upgrade_markdown_by_head_number(head_number):\n\tcontent = pyperclip.paste()\n\tTR_MODE = 1\n\thighest_head_level = get_highest_head_level(content)\n\tif TR_MODE:\n\t\tprint("highest_head_level: ", highest_head_level)\n\t\tprint("head_number: ", head_number)\n\tif highest_head_level > head_number:\n\t\tcontent = upgrade_heads(\n\t\t\tcontent, highest_head_level-head_number)\n\t\tpyperclip.copy(content)\ndef process_md_head_to_hn(head_number, content=None):\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\tTR_MODE = 1\n\thighest_head_level = get_highest_head_level(content)\n\tif TR_MODE:\n\t\tprint("highest_head_level: ", highest_head_level)\n\t\tprint("head_number: ", head_number)\n\tif highest_head_level > head_number:\n\t\tcontent = upgrade_heads(\n\t\t\tcontent, highest_head_level-head_number)\n\t\tpyperclip.copy(content)\n\telif highest_head_level < head_number:\n\t\tcontent = downgrade_heads(\n\t\t\tcontent, head_number-highest_head_level)\n\t\tpyperclip.copy(content)\ndef format_2_gpt_input(content=None):\n\t"""\n\tThis function formats the input content by replacing one or more newline characters with a single newline character.\n\tIf no content is provided, it fetches the content from the clipboard, formats it, and then copies the formatted content back to the clipboard.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t"""\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\t# content = repr(content)\n\tprint(repr(content))\n\tcontent = content.replace("\\r\\n", "\\n")\n\tcontent = content.replace("\n", "\\n")\n\treg_repalce_list = []\n\treg_repalce_list.append([r"\\n{2,}", r"\\n"])\n\treg_repalce_list.append([r"[ ]{2,}", " "])\n\tfor reg_replace in reg_repalce_list:\n\t\tcontent = re.sub(reg_replace[0], reg_replace[1], content)\n\t# Printing the formatted content\n\tprint(repr(content))\n\t# Copying the formatted content back to the clipboard\n\tpyperclip.copy(repr(content))\ndef mermaid_format(content=None):\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\t# content = repr(content)\n\tprint(repr(content))\n\t# content = content.replace(" \\w{1,3}", "\\n")\n\tnum_str = r"22"\n\treg_repalce_list = []\n\treg_repalce_list.append(\n\t\t[r" (\\w{1,3})( |\\n|\\(|\\{|\\[)", r" \\1_"+num_str+r"\\2"])\n\t# reg_repalce_list.append([r" \\w{1,3}\\n", r" \\1\\n"+num_str])\n\tfor reg_replace in reg_repalce_list:\n\t\tcontent = re.sub(reg_replace[0], reg_replace[1], content)\n\tprint(repr(content))\n\t# Copying the formatted content back to the clipboard\n\tpyperclip.copy(content)\ndef retrieve_document_summary_info(content=None):\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\treg_string1 = [\n\t\tr\'(#{1,6}) (.+)\\n\\n<video src="file://.+" controls></video>\\n\\n- .+\', r"\\1# \\2"]\n\tmatch = re.search(reg_string1[0], content)\n\tif match:\n\t\tcontent = re.sub(reg_string1[0], reg_string1[1], content)\n\treg_string2 = [r\'\\n{3,}\', r\'\\n\\n\']\n\tcontent = re.sub(reg_string2[0], reg_string2[1], content)\n\tpyperclip.copy(content)\ndef format_ocr_text(content=None):\n\tTR_mode = False\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\tif TR_mode:\n\t\tprint(":", repr(content))\n\tcontent = content.replace(\'\\n\', \' \')\n\tcontent = content.replace(\'\\r\', \' \')\n\tif TR_mode:\n\t\tprint(repr(content))\n\twhile \'  \' in content:\n\t\tcontent = content.replace(\'  \', \' \')\n\tif TR_mode:\n\t\tprint(repr(content))\n\tpyperclip.copy(content)\ndef create_file_based_on_content(content=None, path=None):\n\t"""\n\tThis function creates a file based on the content provided.\n\tParameters:\n\tcontent (str): The content to be written to the file. If not provided, it will use the content from the clipboard.\n\tpath (str): The path where the file will be created. If not provided, it will use the current working directory.\n\tRaises:\n\tValueError: If the length of the content is less than 1 or greater than 100.\n\tTypeError: If the content contains more than 2 newline characters.\n\t"""\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\tif path is None:\n\t\tpath = os.getcwd()\n\tif len(content) > 100:\n\t\traise ValueError("Content length exceeds 100 characters")\n\tif len(content) < 1:\n\t\traise ValueError("Content length is less than 1 character")\n\tif content.count("\\n") > 2:\n\t\traise TypeError("Content contains more than 2 newline characters")\n\tcontent = content.replace(\'\\n\', \' \')\n\tcontent = content.replace(\'\\r\', \' \')\n\treg = [r"\\s{2,}", r\' \']\n\tcontent = re.sub(reg[0], reg[1], content)\n\ttimestamp = str(int(time.time()))\n\tnew_name = content.strip() + "_" + timestamp + ".md"\n\twith open(os.path.join(path, new_name), "w", encoding="utf-8") as file:\n\t\tfile.write("")\ndef create_node_for_mermaid(num=30):\n\tcontent = ""\n\tfor i in range(num):\n\t\tcontent += f"Node{i+1}[\\"\\"]\\n"\n\tpyperclip.copy(content)\ndef main():\n\tcontent = pyperclip.paste()\n\thighest_level = get_highest_head_level(content)\n\tprint(f"The highest head level is {highest_level}")\n\tdowngrade_level = int(\n\t\tinput("Enter the number by which you want to downgrade the headers: "))\n\tnew_content = downgrade_heads(content, downgrade_level)\n\tpyperclip.copy(new_content)\n\tprint("Content updated in clipboard.")\nif __name__ == "__main__":\n\tmain()\n'",
"prompt_generator.py": "'\nimport pyperclip\nimport re\nimport os\ndef get_prompt_explain_c_cpp(content=None):\n\tprompt_string1 = \'\'\'## Exploring Key C/C++ Concepts: A Guide to Understanding and Resources\nPlease provide a detailed explanation for the following C/C++ concepts that I\'ll specify. Can you also recommend some comprehensive books or resources to aid my understanding of these concepts\nconcepts is :\n```\n\'\'\'\n\tprompt_string2 = \'\'\'```\n\t\'\'\'\n\tcombine_strings_with_clipboard(\n\t\tprompt_string1, prompt_string2, content)\ndef chatbot_prompt_expert(content=None):\n\tprompt_string1 = \'\'\'## chatbot prompt expert\nAs an AI chatbot prompt expert, could you analyze and provide suggestions to improve the following prompt:\n\'[\n\'\'\'\n\tprompt_string2 = \'\'\'\n]\'\nPlease provide a final revised version.\n\'\'\'\n\tcombine_strings_with_clipboard(\n\t\tprompt_string1, prompt_string2, content)\ndef Translate_Chinese_sentence_into_function_name(content=None):\n\tprompt_string1 = \'\'\'\n\t## Translate Chinese sentence into function name\nTranslate the following Chinese sentence into English and create a snake_case function name based on the translated sentence:\n[\n\'\'\'\n\tprompt_string2 = \'\'\'\n]. Your function name should reflect the primary task described in the sentence. Please also provide a brief description of what the function will do\n\'\'\'\n\tcombine_strings_with_clipboard(\n\t\tprompt_string1, prompt_string2, content)\ndef combine_strings_with_clipboard(prompt_string1, prompt_string2, content=None):\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\tfinal_string = prompt_string1 + content + "\\n" + prompt_string2\n\tpyperclip.copy(final_string)\n\t# print(final_string)\n\treturn final_string\ndef Expert_Prompt_Creator():\n\tfinal_string = """\nI want you to become my Expert Prompt Creator. Your goal is to help me craft the best possible prompt for my needs. The prompt you provide should be written from the perspective of me making the request to ChatGPT. Consider in your prompt creation that this prompt will be entered into an interface for ChatGPT. The process is as follows:\n1. You will generate the following sections:\nPrompt:\n{provide the best possible prompt according to my request}\nCritique:\n{provide a concise paragraph on how to improve the prompt. Be very critical in your response}\nQuestions:\n{ask any questions pertaining to what additional information is needed from me to improve the prompt (max of 3). If the prompt needs more clarification or details in certain areas, ask questions to get more information to include in the prompt}\n2. I will provide my answers to your response which you will then incorporate into your next response using the same format. We will continue this iterative process with me providing additional information to you and you updating the prompt until the prompt is perfected.\nRemember, the prompt we are creating should be written from the perspective of me making a request to ChatGPT. Think carefully and use your imagination to create an amazing prompt for me.\nYou\'re first response should only be a greeting to the user and to ask what the prompt should be about.\n"""\n\tpyperclip.copy(final_string)\n\treturn final_string\ndef draw_flowchart():\n\t"""{\n  "instruction": "ChatGPT, could you assist me in designing two flowcharts based on the provided code?",\n  "codePlaceholder": "[YOUR CODE HERE]",\n  "description": "[YOUR CODE DESCRIPTION HERE]",\n  "syntax": "Mermaid",\n  "flowchartTypes": [\n\t"high-level overview",\n\t"detailed, including minor processes"\n  ],\n  "tone": "formal documentation"\n}\n"""\ndef dot2mermaid():\n\tprompt_string1 = """{ "instruction": "Dear ChatGPT, I need your assistance in converting the following Graphviz code into Mermaid syntax. I\'m trying to create a more visually appealing diagram while retaining the structure and relationships depicted in the original Graphviz diagram. Your expertise in this transformation would be highly valued. Here\'s the Graphviz code:",\n "graphviz_code": "["""\n\tprompt_string2 = """ ]",\n}"""\n\tcontent = format_code_2_gpt_input(copy_to_clipboard=False)\n\tfinal_string = prompt_string1 + content + prompt_string2\n\tpyperclip.copy(final_string)\ndef format_code_2_gpt_input(content=None, copy_to_clipboard=True):\n\t"""\n\tFormats the input content by replacing multiple newline characters with a single newline character and\n\tmultiple spaces with a single space. If no content is provided, it fetches the content from the clipboard,\n\tformats it, and then copies the formatted content back to the clipboard if copy_to_clipboard is True.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t:param copy_to_clipboard: A flag indicating whether to copy the formatted content back to the clipboard.\n\t:return: The formatted content as a string.\n\t"""\n\tif content is None:\n\t\ttry:\n\t\t\tcontent = pyperclip.paste()\n\t\texcept pyperclip.PyperclipException:\n\t\t\tprint("Unable to access the clipboard.")\n\t\t\treturn None\n\tcontent = content.replace("\\r\\n", "\\n").replace("\\\\\n", "\\n")\n\treplacements = [\n\t\t(r"\\n{2,}", "\\n"),\n\t\t(r"[ ]{2,}", " ")\n\t]\n\tfor pattern, replacement in replacements:\n\t\tcontent = re.sub(pattern, replacement, content)\n\tif copy_to_clipboard:\n\t\ttry:\n\t\t\tpyperclip.copy(repr(content))\n\t\texcept pyperclip.PyperclipException:\n\t\t\tprint("Unable to copy content to the clipboard.")\n\treturn repr(content)\ndef format_python_2_gpt_input(content=None, copy_to_clipboard=True):\n\t"""\n\tFormats the input content by replacing multiple newline characters with a single newline character and\n\tmultiple spaces with a single space. If no content is provided, it fetches the content from the clipboard,\n\tformats it, and then copies the formatted content back to the clipboard if copy_to_clipboard is True.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t:param copy_to_clipboard: A flag indicating whether to copy the formatted content back to the clipboard.\n\t:return: The formatted content as a string.\n\t"""\n\tif content is None:\n\t\ttry:\n\t\t\tcontent = pyperclip.paste()\n\t\texcept pyperclip.PyperclipException:\n\t\t\tprint("Unable to access the clipboard.")\n\t\t\treturn None\n\tcontent = content.replace("\\r\\n", "\\n").replace("\\\\\n", "\\n")\n\treplacements = [\n\t\t(r"\\n{2,}", "\\n"),\n\t\t(r"[ ]{4}", "\\t")\n\t]\n\tfor pattern, replacement in replacements:\n\t\tcontent = re.sub(pattern, replacement, content)\n\tif copy_to_clipboard:\n\t\ttry:\n\t\t\tpyperclip.copy(repr(content))\n\t\texcept pyperclip.PyperclipException:\n\t\t\tprint("Unable to copy content to the clipboard.")\n\treturn repr(content)\ndef format_c_cpp_2_gpt_input(content=None, copy_to_clipboard=True):\n\t"""\n\tFormats the input content by replacing multiple newline characters with a single newline character and\n\tmultiple spaces with a single space. If no content is provided, it fetches the content from the clipboard,\n\tformats it, and then copies the formatted content back to the clipboard if copy_to_clipboard is True.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t:param copy_to_clipboard: A flag indicating whether to copy the formatted content back to the clipboard.\n\t:return: The formatted content as a string.\n\t"""\n\tif content is None:\n\t\ttry:\n\t\t\tcontent = pyperclip.paste()\n\t\texcept pyperclip.PyperclipException:\n\t\t\tprint("Unable to access the clipboard.")\n\t\t\treturn None\n\tcontent = content.replace("\\r\\n", "\\n").replace("\\\\\n", "\\n")\n\treplacements = [\n\t\t(r"\\n{2,}", "\\n"),\n\t\t(r"[ ]{2,}", " ")\n\t]\n\tfor pattern, replacement in replacements:\n\t\tcontent = re.sub(pattern, replacement, content)\n\tif copy_to_clipboard:\n\t\ttry:\n\t\t\tpyperclip.copy(repr(content))\n\t\texcept pyperclip.PyperclipException:\n\t\t\tprint("Unable to copy content to the clipboard.")\n\treturn repr(content)\ndef code_improve():\n\tprompt_string1 = """{\n"language": "Python",\n"application_type": "desktop",\n"code_snippet": "[ """\n\tprompt_string2 = """ ]",\n"request": "I am developing a desktop application in Python and I need insights on how to improve my code. Here\'s a snippet of my code. Can you provide feedback on its efficiency, readability, and suggestions for enhancement?"\n}"""\n\tcontent = format_code_2_gpt_input(copy_to_clipboard=False)\n\tfinal_string = prompt_string1 + content + prompt_string2\n\tpyperclip.copy(final_string)\ndef video_summarization_expert_one(content=None):\n\tprompt_string1 = \'\'\'## video summarization expert one\nHello ChatGPT,\nI have an extensive video subtitle data that needs your expertise. My aim is to break down this data into as many thematic segments as possible, where each segment represents a unique topic or theme discussed in the video.\nFor each segment, I expect you to craft a detailed summary that includes:\n- Title: A descriptive title that encapsulates the main point of the segment.\n- Start Timestamp: The starting time of the segment within the video.\n- Summary: A brief and short summary text showing the main points or topics discussed in that segment.\nHere is the format I expect for each segment:\nTitle:\nStart Timestamp:\nSummary:\nKindly start analyzing the following subtitle data:\n[\n\'\'\'\n\tprompt_string2 = \'\'\'\n]\nI appreciate your assistance. Thank you!\n\'\'\'\n\tcontent = format_code_2_gpt_input(copy_to_clipboard=False)\n\tfinal_string = prompt_string1 + content + prompt_string2\n\tpyperclip.copy(final_string)\ndef read_file_skip_non_utf8_parts(file_path):\n\timport logging\n\t"""\n\tReads a file in binary mode and decodes it to UTF-8.\n\tSkips the parts of the file that are not UTF-8 encoded.\n\t:param file_path: Path to the file.\n\t:return: Decoded file content with non-UTF-8 parts skipped.\n\t"""\n\ttry:\n\t\twith open(file_path, \'rb\') as f:\n\t\t\tbyte_content = f.read()\n\t\t\treturn byte_content.decode(\'utf-8\', errors=\'ignore\')\n\texcept Exception as e:\n\t\tlogging.error(f"Error reading file {file_path}: {e}")\n\treturn None\ndef format_code_current_dir(current_dir=None):\n\tif current_dir is None:\n\t\tcurrent_dir = os.getcwd()\n\toutput_dir = os.path.join(current_dir, \'gpt_ready_code\')\n\tos.makedirs(output_dir, exist_ok=True)\n\t# with open(os.path.join(output_dir, \'.gitignore\'), \'w\', encoding="utf-8") as f:\n\t#\t f.write("*.md\\n")\n\tfor root, dirs, files in os.walk(current_dir):\n\t\tfor file in files:\n\t\t\tif file.endswith(\'.c\') or file.endswith(\'.cpp\') or file.endswith(\'.h\') or file.endswith(\'.hpp\') or file.endswith(\'.py\'):\n\t\t\t\t# Get file name\n\t\t\t\tfile_name = os.path.basename(file)\n\t\t\t\t# Get directory name\n\t\t\t\tdir_name = os.path.basename(root)\n\t\t\t\t# print(dir_name)\n\t\t\t\tif dir_name.startswith(\'.\'):\n\t\t\t\t\tcontinue\n\t\t\t\torigin_dir = os.path.join(root, file)\n\t\t\t\t# read file skip none utf-8\n\t\t\t\tcontent = read_file_skip_non_utf8_parts(origin_dir)\n\t\t\t\tcontent = format_python_2_gpt_input(\n\t\t\t\t\tcontent=content, copy_to_clipboard=False) if file.endswith(\'.py\') else format_c_cpp_2_gpt_input(content, copy_to_clipboard=False)\n\t\t\t\tfloder_sep = os.path.join(output_dir, dir_name)\n\t\t\t\tos.makedirs(floder_sep, exist_ok=True)\n\t\t\t\tfile_dir = os.path.join(floder_sep, f\'{file_name}.md\')\n\t\t\t\ttotal_dir = os.path.join(\n\t\t\t\t\toutput_dir, f\'{dir_name}.md\')\n\t\t\t\twith open(file_dir, \'w\', encoding="utf-8") as f1:\n\t\t\t\t\tf1.write(f"\\"{file_name}\\": \\"{content}\\",\\n")\n\t\t\t\tif os.path.exists(total_dir):\n\t\t\t\t\twith open(total_dir, \'r\', encoding="utf-8") as f1:\n\t\t\t\t\t\tcontent1 = f1.read()\n\t\t\t\telse:\n\t\t\t\t\tcontent1 = \'\'\n\t\t\t\twith open(total_dir, \'w\', encoding="utf-8") as f1:\n\t\t\t\t\tcontent = f1.write(\n\t\t\t\t\t\tcontent1+f"\\"{file_name}\\": \\"{content}\\",\\n")\n\treturn current_dir\n'",
"UI.py": "'import sys\nfrom PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QTabWidget, QPushButton, QTextEdit\nimport prompt_generator\nimport pyperclip\n# Your functions here (e.g., get_prompt_explain_c_cpp, video_summarization_expert_one, Translate_Chinese_sentence_into_function_name)\nclass MyApp(QWidget):\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.initUI()\n\tdef initUI(self):\n\t\tlayout = QVBoxLayout()\n\t\ttab_widget = QTabWidget()\n\t\tprompts_tab = QWidget()\n\t\tprompts_layout = QVBoxLayout()\n\t\tself.prompts_text_edit = QTextEdit()\n\t\tprompts_layout.addWidget(self.prompts_text_edit)\n\t\tbtn1 = QPushButton(\'video_summarization_expert_one\')\n\t\tbtn1.clicked.connect(lambda: prompt_generator.video_summarization_expert_one(\n\t\t\tself.prompts_text_edit.toPlainText()))\n\t\tprompts_layout.addWidget(btn1)\n\t\tbtn2 = QPushButton(\'Get Prompt Explain C/C++\')\n\t\tbtn2.clicked.connect(lambda: prompt_generator.get_prompt_explain_c_cpp(\n\t\t\tself.prompts_text_edit.toPlainText()))\n\t\tprompts_layout.addWidget(btn2)\n\t\tbtn3 = QPushButton(\'chatbot_prompt_expert\')\n\t\tbtn3.clicked.connect(lambda: prompt_generator.chatbot_prompt_expert(\n\t\t\tself.prompts_text_edit.toPlainText()))\n\t\tprompts_layout.addWidget(btn3)\n\t\tbtn4 = QPushButton(\'Translate Chinese Sentence into Function Name\')\n\t\tbtn4.clicked.connect(lambda: prompt_generator.Translate_Chinese_sentence_into_function_name(\n\t\t\tself.prompts_text_edit.toPlainText()))\n\t\tprompts_layout.addWidget(btn4)\n\t\tbtn5 = QPushButton(\'Expert_Prompt_Creator\')\n\t\tbtn5.clicked.connect(lambda: prompt_generator.Expert_Prompt_Creator(\n\t\t\tself.prompts_text_edit.toPlainText()))\n\t\tprompts_layout.addWidget(btn5)\n\t\tprompts_tab.setLayout(prompts_layout)\n\t\ttab_widget.addTab(prompts_tab, "Prompts")\n\t\tlayout.addWidget(tab_widget)\n\t\tself.setLayout(layout)\n\t\tself.setWindowTitle(\'Expert Prompt Creator\')\n\t\tself.show()\nif __name__ == \'__main__\':\n\tapp = QApplication(sys.argv)\n\tex = MyApp()\n\tsys.exit(app.exec_())\n'",
"vid_note_processor.py": "'import os\nimport re\nimport file_operations_utils\nimport pyperclip\nimport flags_utils\nimport shutil\nimport prompt_generator\nimport urllib.parse\ndef srt_format_4_gpt(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_srt = [f for f in os.listdir(directory_path) if f.endswith(\'.srt\')]\n\tfor file in files_srt:\n\t\twith open(os.path.join(directory_path, file), "r", encoding="utf-8") as f1:\n\t\t\tlines = f1.readlines()\n\t\tcontent = \'\'\n\t\tfor line in lines:\n\t\t\tline_temp = line.strip()\n\t\t\tcontent += line_temp\n\t\treg_srt_2_gpt1 = [\n\t\t\tr\'\\d{1,3}(\\d{2}:\\d{2}:\\d{2}),\\d{3} --> \\d{1,2}:\\d{2}:\\d{2},\\d{3}\', r\'\\n(\\1) \']\n\t\treg_srt_2_gpt = reg_srt_2_gpt1\n\t\tcontent = re.sub(reg_srt_2_gpt[0], reg_srt_2_gpt[1], content)\n\t\twith open(os.path.join(directory_path, file), "w", encoding="utf-8") as f1:\n\t\t\tf1.write(content)\n\tif files_srt != []:\n\t\tprint(files_srt)\n\t\tprompt_generator.video_summarization_expert_one(content)\ndef vtt_format_4_gpt(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_srt = [f for f in os.listdir(directory_path) if f.endswith(\'.vtt\')]\n\tfor file in files_srt:\n\t\twith open(os.path.join(directory_path, file), "r", encoding="utf-8") as f1:\n\t\t\tlines = f1.readlines()\n\t\tcontent = \'\'\n\t\tfor line in lines:\n\t\t\tcontent += line.strip()+" "\n\t\treg_vtt_2_gpt_list = []\n\t\treg_vtt_2_gpt_list.append([\n\t\t\tr\'(\\d{2}:\\d{2}:\\d{2}).\\d{3} --> \\d{1,2}:\\d{2}:\\d{2}.\\d{3}\', r\'\\n(\\1)\'])\n\t\treg_vtt_2_gpt_list.append([\n\t\t\tr\'WEBVTT Kind:.+ Language:.+\\n\', r\'\'])\n\t\treg_vtt_2_gpt_list.append([r\'&nbsp;\', r\' \'])\n\t\treg_vtt_2_gpt_list.append([r\' line:\\d{1,3}%\', r\' \'])\n\t\treg_vtt_2_gpt_list.append([r\'[ ]{1,}\', r\' \'])\n\t\tfor reg_vtt_2_gpt in reg_vtt_2_gpt_list:\n\t\t\tcontent = re.sub(reg_vtt_2_gpt[0], reg_vtt_2_gpt[1], content)\n\t\twith open(os.path.join(directory_path, file), "w", encoding="utf-8") as f1:\n\t\t\tf1.write(content)\n\tif files_srt != []:\n\t\tprint(files_srt)\n\t\tprompt_generator.video_summarization_expert_one(content)\ndef subtitles_format_for_gpt_input(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tvtt_format_4_gpt(directory_path)\n\tsrt_format_4_gpt(directory_path)\ndef get_list_key_word_vid(current_dir=None):\n\tif current_dir is None:\n\t\tcurrent_dir = os.getcwd()\n\tlist_key_word_vid = []\n\tfiles_mp4 = [file for file in os.listdir(\n\t\tcurrent_dir) if file.endswith(".mp4")]\n\tfiles_mp4.sort()\n\tfor file in files_mp4:\n\t\treg = r".*? - Lecture \\d{1,2} - (.*?)-.*?\\.mp4"\n\t\tmatch = re.search(reg, file)\n\t\tif match:\n\t\t\tlist_key_word_vid.append(match[1])\n\t\telse:\n\t\t\tprint("not matching")\n\treturn list_key_word_vid\ndef mul_initialize_vid_note_file_structure(current_dir=None, list_content=None):\n\tflags = flags_utils.GlobalFlags()\n\tflags.set_flag(\'TR_MODE\', True)\n\tTR_MODE = flags.get_flag(\'TR_MODE\')\n\tif current_dir is None:\n\t\tcurrent_dir = os.getcwd()\n\tTopic, sub_topic1 = file_operations_utils.get_Topic_in_kg(TR_MODE)\n\tif Topic is None:\n\t\traise ValueError("Topic is None")\n\tbvids_origin_topic_path = file_operations_utils.get_bvids_origin_topic_path(\n\t\tTopic, TR_MODE)\n\tif list_content is None:\n\t\tlist_content = get_list_key_word_vid(\n\t\t\tcurrent_dir=bvids_origin_topic_path)\n\tfor content in list_content:\n\t\tinitialize_vid_note_file_structure(current_dir, content)\ndef initialize_vid_note_file_structure(current_dir=None, content=None):\n\tflags = flags_utils.GlobalFlags()\n\tflags.set_flag(\'TR_MODE\', True)\n\tTR_MODE = flags.get_flag(\'TR_MODE\')\n\t# Get content from clipboard\n\tif content is None:\n\t\tcontent = pyperclip.paste()\n\tcontent = content.strip()\n\treg_content_to_current_topic = [r"\\d{1,3}_(.+)\\.mp4", r"\\1"]\n\tmatch = re.search(reg_content_to_current_topic[0], content)\n\tif match:\n\t\tcurrent_topic = re.sub(\n\t\t\treg_content_to_current_topic[0], reg_content_to_current_topic[1], content)\n\telse:\n\t\treg_content_to_current_topic = [r"(.+)\\.mp4", r"\\1"]\n\t\tmatch = re.search(reg_content_to_current_topic[0], content)\n\t\tif match:\n\t\t\tcurrent_topic = re.sub(\n\t\t\t\treg_content_to_current_topic[0], reg_content_to_current_topic[1], content)\n\t\telse:\n\t\t\tcurrent_topic = content\n\tif TR_MODE == 1:\n\t\tprint("current_topic: ", current_topic)\n\tif current_dir is None:\n\t\tcurrent_dir = os.getcwd()\n\t# Check for existing serial numbers (first three digits of filenames)\n\tserial_numbers = [f[:3] for f in os.listdir(current_dir) if os.path.isfile(\n\t\tos.path.join(current_dir, f)) and f[:3].isdigit()]\n\t# # Generate filename\n\t# if serial_numbers:\n\t#\t max_serial_number = max(serial_numbers)\n\t#\t note_file = str(int(max_serial_number) + 1).zfill(3) + \\\n\t#\t\t "_"+current_topic+".md"\n\t# else:\n\t#\t note_file = "001"+"_"+current_topic+".md"\n\tmax_serial_number = max(serial_numbers) if serial_numbers else "000"\n\tnote_file = f"{int(max_serial_number) + 1:03d}_{current_topic}.md"\n\tif TR_MODE == 1:\n\t\tprint("note_file: ", note_file)\n\t# Add the filename to the current_dir\n\tnote_file_path = os.path.join(current_dir, note_file)\n\tif not os.path.exists(note_file_path):\n\t\twith open(note_file_path, \'w\') as f:\n\t\t\tf.write("")\n\tsub_topic1_to_sub_topicn_folder_list = [note_file[:-3]]\n\t# sub_topic1_to_sub_topicn_folder_list.append(os.path.basename(current_dir))\n\tnote_assets_dir_path = file_operations_utils.get_note_assets_dir_path(\n\t\tsub_topic1_to_sub_topicn_folder_list, current_dir)\n\tif TR_MODE == 1:\n\t\tprint("note_assets_dir_path: ", note_assets_dir_path)\n\tfile_operations_utils.create_file_subtitle_summary_gpt_md(\n\t\tnote_assets_dir_path)\n\tTopic, sub_topic1 = file_operations_utils.get_Topic_in_kg(TR_MODE)\n\tif Topic is None:\n\t\traise ValueError("Topic is None")\n\tbvids_origin_topic_path = file_operations_utils.get_bvids_origin_topic_path(\n\t\tTopic, TR_MODE)\n\tflag_search_sub_topic1 = flags_utils.get_flag_search_sub_topic1_in_bvids_origin_topic_path()\n\tif flag_search_sub_topic1:\n\t\tdirs = [d for d in os.listdir(bvids_origin_topic_path) if os.path.isdir(\n\t\t\tos.path.join(bvids_origin_topic_path, d))]\n\t\tif TR_MODE:\n\t\t\tprint("dirs:", dirs)\n\t\treg_string = r"\\d{1,3}_"+sub_topic1\n\t\tflag_find_sub_topic = False\n\t\tfor dir in dirs:\n\t\t\tif re.match(reg_string, dir):\n\t\t\t\tbvids_origin_topic_path = os.path.join(\n\t\t\t\t\tbvids_origin_topic_path, dir)\n\t\t\t\tflag_find_sub_topic = True\n\t\t\t\tbreak\n\t\tif not flag_find_sub_topic:\n\t\t\traise Exception("sub topic not found")\n\t# if match copy to des\n\tfiles_subtitle = [f for f in os.listdir(\n\t\tbvids_origin_topic_path) if f.endswith(\'.srt\') or f.endswith(\'.vtt\')]\n\tif TR_MODE:\n\t\tprint("files_subtitle:", files_subtitle)\n\treg_sub_string_current_topic = [\n\t\tr\'(\\d{1,3}_|)\'+current_topic+r\'(\\.en|\\.eng|\\.zh|\\.cn|\\.zho|\\.chi|\\.zh-Hans|\\.zh-Hant|)(\\.srt|\\.vtt)\', r\'\']\n\tflag_one_by_one = flags_utils.get_flag_one_by_one()\n\tfor file_srt in files_subtitle:\n\t\tmatch = re.match(reg_sub_string_current_topic[0], file_srt)\n\t\tflag_find_match = False\n\t\tif match:\n\t\t\tflag_find_match = True\n\t\t\tif ((match.group(2) == ".en") or (match.group(2) == "")):\n\t\t\t\t# copy srt to note_assets_dir_path\n\t\t\t\tnew_srt_name = note_file[:-3]+match.group(2)+match.group(3)\n\t\t\t\tsrc_srt_file_path = os.path.join(\n\t\t\t\t\tbvids_origin_topic_path, file_srt)\n\t\t\t\tdes_srt_file_path = os.path.join(\n\t\t\t\t\tnote_assets_dir_path, new_srt_name)\n\t\t\t\tshutil.copy(src_srt_file_path, des_srt_file_path)\n\tif not flag_find_match:\n\t\tif flag_one_by_one:\n\t\t\tfile_srt = files_subtitle[0]\n\t\t\tsrc_srt_file_path = os.path.join(\n\t\t\t\tbvids_origin_topic_path, file_srt)\n\t\t\tdes_srt_file_path = os.path.join(\n\t\t\t\tnote_assets_dir_path, file_srt)\n\t\t\tshutil.copy(src_srt_file_path, des_srt_file_path)\n\tsubtitles_format_for_gpt_input(note_assets_dir_path)\n\t# todo generate prompt\ndef move_origin_vid_to_destination(TR_MODE=0):\n\tflag_one_by_one = flags_utils.get_flag_one_by_one()\n\tif TR_MODE:\n\t\tprint("flag_one_by_one:", flag_one_by_one)\n\tflag_search_sub_topic1 = flags_utils.get_flag_search_sub_topic1_in_bvids_origin_topic_path()\n\tkey_word, key_word_path = file_operations_utils.get_kg_bassets_folder_keyword()\n\tsub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = file_operations_utils.get_bassets_keyword_path(\n\t\tkey_word=key_word)\n\t# sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_bassets_keyword_path(key_word="NN_1687967434")\n\torigin_current_vid_file_name = ""\n\t# sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tTopic, sub_topic1, current_topic = file_operations_utils.get_Topic_in_kg_assets(\n\t\tTR_MODE)\n\tif TR_MODE:\n\t\tprint("Folder list:", sub_topic1_to_sub_topicn_folder_list)\n\t\tprint("OneDrive KG root directory_path:",\n\t\t\t  OneDrive_KG_note_root_directory_path)\n\tBaiduSyncdisk_KG_note_root_directory_path = file_operations_utils.get_b_KG_directory_path(\n\t\tOneDrive_KG_note_root_directory_path)\n\tif TR_MODE:\n\t\tprint("BaiduSyncdisk assets root _directory_path:",\n\t\t\t  BaiduSyncdisk_KG_note_root_directory_path)\n\tbvids_origin_topic_path = file_operations_utils.get_bvids_origin_topic_path(\n\t\tTopic, TR_MODE=TR_MODE)\n\tif flag_search_sub_topic1:\n\t\tdirs = [d for d in os.listdir(bvids_origin_topic_path) if os.path.isdir(\n\t\t\tos.path.join(bvids_origin_topic_path, d))]\n\t\tif TR_MODE:\n\t\t\tprint("dirs:", dirs)\n\t\treg_string = r"\\d{1,3}_"+sub_topic1\n\t\tflag_find_sub_topic = False\n\t\tfor dir in dirs:\n\t\t\tif re.match(reg_string, dir):\n\t\t\t\tbvids_origin_topic_path = os.path.join(\n\t\t\t\t\tbvids_origin_topic_path, dir)\n\t\t\t\tflag_find_sub_topic = True\n\t\t\t\tbreak\n\t\tif not flag_find_sub_topic:\n\t\t\traise Exception("sub topic not found")\n\tfiles = [f for f in os.listdir(bvids_origin_topic_path) if os.path.isfile(\n\t\tos.path.join(bvids_origin_topic_path, f)) and f.endswith(".mp4")]\n\tfiles.sort()\n\tif TR_MODE:\n\t\tprint("Files:", files)\n\tOneDrive_KG_current_note_directory_path = file_operations_utils.get_OneDrive_KG_note_path(\n\t\tOneDrive_KG_note_root_directory_path, sub_topic1_to_sub_topicn_folder_list)\n\tif TR_MODE:\n\t\tprint("OneDrive KG note directory_path:",\n\t\t\t  OneDrive_KG_current_note_directory_path)\n\tcurrent_bvid_name = file_operations_utils.get_current_bvid_name()\n\tif TR_MODE:\n\t\tprint("current_bvid_name:", current_bvid_name)\n\tserial_number = current_bvid_name[:3]\n\tif TR_MODE:\n\t\tprint("serial_number:", serial_number)\n\tbvids_destination_directory_path = file_operations_utils.get_bvids_destination_long(\n\t\tsub_topic1_to_sub_topicn_folder_list, BaiduSyncdisk_KG_note_root_directory_path)\n\tif TR_MODE:\n\t\tprint("bvids_destination_directory_path:",\n\t\t\t  bvids_destination_directory_path)\n\t# bvid_reg_string = r\'.+\\(P\\d{1,3}\\. \\d{1,3}\\.\\d{1,3}\\.\\d{1,3}(.+)\\)\\.mp4\'\n\tcurrent_bvid_destination_file_path = os.path.join(\n\t\tbvids_destination_directory_path, current_bvid_name)\n\tif flag_one_by_one:\n\t\tif not os.path.exists(current_bvid_destination_file_path):\n\t\t\tvid_name_origin = files[0]\n\t\t# origin_current_vid_file_name = "\\n"+re.sub(bvid_reg_string, r\'\\1\', vid_name_origin)\n\t\t\torigin_current_vid_file_name = vid_name_origin\n\t\t\tos.rename(os.path.join(bvids_origin_topic_path,\n\t\t\t\t\t  vid_name_origin), current_bvid_destination_file_path)\n\t\t\treg_vid_name_origin_serial = r"(\\d{2,6})_.+(\\.mp4|\\.flv|\\.whem)"\n\t\t\tmatch = re.search(reg_vid_name_origin_serial,\n\t\t\t\t\t\t\t  origin_current_vid_file_name)\n\t\t\tserial_number_origin = match.group(1)\n\t\t\tif match:\n\t\t\t\treg_string_sub = r"^" + \\\n\t\t\t\t\tserial_number_origin+"_"+".+?" + \\\n\t\t\t\t\tr"(\\.ch\\.cn|\\.en)(\\.srt|\\.vtt)$"\n\t\t\t\treg_string_sub2 = r"^" + \\\n\t\t\t\t\tserial_number_origin+"_"+".+?" + \\\n\t\t\t\t\tr"(\\.srt|\\.vtt)$"\n\t\t\telse:\n\t\t\t\traise Exception("Error: regex not match")\n\t\t\tfiles_sub = [f for f in os.listdir(bvids_origin_topic_path) if os.path.isfile(\n\t\t\t\tos.path.join(bvids_origin_topic_path, f)) and (f.endswith(".srt") or f.endswith(".vtt"))]\n\t\t\tfor file_sub in files_sub:\n\t\t\t\tmatch = re.search(reg_string_sub, file_sub)\n\t\t\t\tif match:\n\t\t\t\t\t# print(match)\n\t\t\t\t\tcurrent_bsrt_name = current_bvid_name[:-4] + \\\n\t\t\t\t\t\tmatch.group(1)+match.group(2)\n\t\t\t\t\tos.rename(os.path.join(\n\t\t\t\t\t\tbvids_origin_topic_path, file_sub), os.path.join(bvids_destination_directory_path, current_bsrt_name))\n\t\t\t\telse:\n\t\t\t\t\tmatch = re.search(reg_string_sub2, file_sub)\n\t\t\t\t\tif match:\n\t\t\t\t\t\tcurrent_bsrt_name = current_bvid_name[:-4] + \\\n\t\t\t\t\t\t\tmatch.group(1)\n\t\t\t\t\t\tos.rename(os.path.join(\n\t\t\t\t\t\t\tbvids_origin_topic_path, file_sub), os.path.join(bvids_destination_directory_path, current_bsrt_name))\n\treturn origin_current_vid_file_name, current_bvid_destination_file_path, OneDrive_KG_current_note_directory_path\ndef vid_path_2_md_vid_link(vid_path, current_bvid_name):\n\timport urllib\n\turl_path = urllib.parse.quote(os.path.abspath(vid_path))\n\turl = "file:///" + url_path.replace("\\\\", "/")\n\tmd_show_url = f"![{current_bvid_name}]({url})"\n\tmd_url = f"[{current_bvid_name}]({url})"\n\treturn md_show_url, md_url\ndef convert_chatgpt_summary_text_to_one_line_summary(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_string1 = [\n\t\tr\'(Section \\d{1,2}: |Title: |Title:\\n)(.+)\\n{1,2}(Start: |Start Timestamp: |Start Timestamp:\\n)(|\\()(\\d{1,2}:\\d{1,2})(|\\))\\n{1,2}Summary(: |:\\n)(.+)\', r"- \\2 (\\5) \\8"]\n\treg_string_list.append(reg_string1)\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, directory_path, files_md)\ndef check_video_file_path_conforms_to_pattern(str_url):\n\tr"![001_Derivatives of multivariable functions.mp4](file:///C%3A%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CMultivaribale_calculus_Khan_Academy%5Cassets%5Cbvids%5Cmc_1683793602%5C002%5C001%5C001_Derivatives%20of%20multivariable%20functions.mp4)"\n\turl_pattern_4_file_vid = r\'(!\\[.+\\..+\\]\\(file:///C:%5CBaiduSyncdisk%5Cassets(%5C.+){1,}\\.\\w+)(\\))\'\n\turl_pattern_4_file_vid2 = r\'(!\\[.+\\..+\\]\\(file:///C%3A%5CBaiduSyncdisk%5Cassets(%5C.+){1,}\\.\\w+)(\\))\'\n\tmatch1 = re.search(url_pattern_4_file_vid, str_url)\n\tif not match1:\n\t\tmatch1 = re.search(url_pattern_4_file_vid2, str_url)\n\t\tif not match1:\n\t\t\tprint("str_url: ", str_url)\n\t\t\traise Exception(\'No match found\')\n\treturn match1\ndef convert_min_sec_to_seconds(time_str):\n\ttime_line_pattern_str = r\'\\((\\d{1,2}:\\d{1,2})-(\\d{1,2}:\\d{1,2})\\)[ ]{1,}\'\n\ttime_stamp_pattern_str = r\'((\\d{1,2}):|)(\\d{1,2}):(\\d{1,2})\'\n\tmatch = re.search(time_line_pattern_str, time_str)\n\tif match:\n\t\ttime_line_start = match.group(1)\n\t\ttime_line_end = match.group(2)\n\t\ttime_line_start_seconds = int(time_line_start.split(\n\t\t\t\':\')[0])*60+int(time_line_start.split(\':\')[1])\n\t\treturn time_line_start_seconds\n\telse:\n\t\tmatch = re.search(time_stamp_pattern_str, time_str)\n\t\tif match:\n\t\t\tif match.group(2) != None:\n\t\t\t\t# print(match.group(1))\n\t\t\t\thour = int(match.group(2))\n\t\t\telse:\n\t\t\t\thour = 0\n\t\t\ttime_seconds = hour * 60*60 + \\\n\t\t\t\tint(match.group(3))*60 + int(match.group(4))\n\t\t\treturn time_seconds\n\t\telse:\n\t\t\treturn None\ndef get_list_time_head_textshort_text_4_file(file, key_word):\n\t# print("start to generate time line for video and head text:")\n\tnumber_list_head_time_text_pattern_str = r\'((\\d{1,2}\\.)|-)[ ]{1,}(.+) \\((\\d{1,2}):(\\d{1,2})\\) (.+)\'\n\tnumber_list_head_time_pattern_str = r\'(\\d{1,2}):(\\d{1,2}) - (.+)\'\n\tnumber_list_head_time_pattern_str2 = r\'(\\d{1,2}):(\\d{1,2}) (.+)\'\n\ttime_text_pattern_str = r\'\\((\\d{1,2}):(\\d{1,2})\\)[ ]{0,}([^\\n]+)[\\n]{0,}\'\n\tpattern_dict = dict()\n\tpattern_dict["timestamps"] = number_list_head_time_pattern_str\n\tpattern_dict["summary_gpt"] = number_list_head_time_text_pattern_str\n\tpattern_dict["subtitle"] = time_text_pattern_str\n\tlist_time_head_textshort_text = []\n\twith open(os.path.join(os.getcwd(), file), \'r\', encoding=\'UTF-8\') as f:\n\t\tlines = f.readlines()\n\tfor line in lines:\n\t\ttime_line_start_seconds = convert_min_sec_to_seconds(line)\n\t\tif time_line_start_seconds != None:\n\t\t\tif key_word in pattern_dict:\n\t\t\t\tpattern_str = pattern_dict[key_word]\n\t\t\t\tmatch = re.search(pattern_str, line)\n\t\t\t\tif match:\n\t\t\t\t\tif key_word == "timestamps":\n\t\t\t\t\t\tlist_time_head_textshort_text.append(\n\t\t\t\t\t\t\t[time_line_start_seconds, match.group(3), None, None])\n\t\t\t\t\telif key_word == "summary_gpt":\n\t\t\t\t\t\t# for i in range(len(match.groups())):\n\t\t\t\t\t\t#\t print(i,match.group(i))\n\t\t\t\t\t\tlist_time_head_textshort_text.append(\n\t\t\t\t\t\t\t[time_line_start_seconds, match.group(3), match.group(6), None])\n\t\t\t\t\telif key_word == "subtitle":\n\t\t\t\t\t\tlist_time_head_textshort_text.append(\n\t\t\t\t\t\t\t[time_line_start_seconds, None, None, match.group(3)])\n\t\t\t\telse:\n\t\t\t\t\tif key_word == "timestamps":\n\t\t\t\t\t\tmatch2 = re.search(\n\t\t\t\t\t\t\tnumber_list_head_time_pattern_str2, line)\n\t\t\t\t\t\tif match2:\n\t\t\t\t\t\t\tlist_time_head_textshort_text.append(\n\t\t\t\t\t\t\t\t[time_line_start_seconds, match2.group(3), None, None])\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tprint("no match for line:", line)\n\t\t\t\t\t\t\tprint(key_word)\n\t\t\t\t\telse:\n\t\t\t\t\t\tprint("no match for line:", line)\n\t\t\t\t\t\tprint(key_word)\n\t\t\telse:\n\t\t\t\traise Exception("key_word not in pattern_dict")\n\t# print("List of time, heading, short text, text:")\n\t# print(list_time_head_textshort_text)\n\treturn list_time_head_textshort_text\ndef list_time_head_textshort_text_to_vid_timeline_md(timeline_data, file, match):\n\t# print(timeline_data)\n\tassets_root_path, assets_root_dir = file_operations_utils.get_assets_root_path()\n\toutput_dir = file_operations_utils.create_output_directory(\n\t\tassets_root_path)\n\tnew_file_name = file_operations_utils.create_new_file_name(file)\n\tflag_write_line_by_line = True\n\tif not flag_write_line_by_line:\n\t\tcontent = ""\n\twith open(os.path.join(output_dir, new_file_name), \'w\', encoding=\'UTF-8\') as f:\n\t\tfor i, (start_time, heading, short_text, text) in enumerate(timeline_data):\n\t\t\tstart_time_sec = int(start_time)\n\t\t\tif i == len(timeline_data) - 1:\n\t\t\t\tend_time_sec = start_time_sec + 999\n\t\t\telse:\n\t\t\t\tend_time_sec = int(timeline_data[i + 1][0])\n\t\t\tif heading:\n\t\t\t\tif flag_write_line_by_line:\n\t\t\t\t\tf.write(f"## {heading}\\n\\n")\n\t\t\t\telse:\n\t\t\t\t\tcontent += f"## {heading}\\n\\n"\n\t\t\t\ti_temp = i\n\t\t\t\tflag_find_next_head = False\n\t\t\t\twhile i_temp < len(timeline_data) - 1:\n\t\t\t\t\ti_temp += 1\n\t\t\t\t\tif timeline_data[i_temp][1]:\n\t\t\t\t\t\tend_time_sec2 = int(timeline_data[i_temp][0])\n\t\t\t\t\t\tvid_line = f"{match.group(1)}#t={start_time_sec},{end_time_sec2}{match.group(3)}"\n\t\t\t\t\t\tif flag_write_line_by_line:\n\t\t\t\t\t\t\tf.write(f"{vid_line}\\n\\n")\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tcontent += f"{vid_line}\\n\\n"\n\t\t\t\t\t\tflag_find_next_head = True\n\t\t\t\t\t\tbreak\n\t\t\t\tif not flag_find_next_head:\n\t\t\t\t\tvid_line = f"{match.group(1)}#t={start_time_sec}{match.group(3)}"\n\t\t\t\t\tif flag_write_line_by_line:\n\t\t\t\t\t\tf.write(f"{vid_line}\\n\\n")\n\t\t\t\t\telse:\n\t\t\t\t\t\tcontent += f"{vid_line}\\n\\n"\n\t\t\tif short_text:\n\t\t\t\tif flag_write_line_by_line:\n\t\t\t\t\tf.write(f"- {short_text}\\n\\n")\n\t\t\t\telse:\n\t\t\t\t\tcontent += f"- {short_text}\\n\\n"\n\t\t\tif heading:\n\t\t\t\tif flag_write_line_by_line:\n\t\t\t\t\tf.write(f"---\\n\\n\\n\\n")\n\t\t\t\telse:\n\t\t\t\t\tcontent += f"---\\n\\n\\n\\n"\n\t\t\tif text:\n\t\t\t\tvid_line = f"{match.group(1)}#t={start_time_sec},{end_time_sec}{match.group(3)}"\n\t\t\t\tif flag_write_line_by_line:\n\t\t\t\t\tf.write(f"{vid_line}\\n\\n")\n\t\t\t\t\tf.write(f"{text}\\n\\n")\n\t\t\t\telse:\n\t\t\t\t\tcontent += f"{vid_line}\\n\\n"\n\t\t\t\t\tcontent += f"{text}\\n\\n"\n\t\t\tif flag_write_line_by_line:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tf.write(content)\n\t\t\t\tcontent = ""\n\treturn output_dir, new_file_name\ndef convert_md_vid_link_to_html(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_string2 = [r\'(!\\[\\]|!\\[.+\\])\\((file:///.+(\\.mp4|\\.mp4#t=.+))\\)\',\n\t\t\t\t   r\'<video src="\\2" controls></video>\']\n\treg_string_list.extend([reg_string2])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, directory_path, files_md)\ndef convert_md_vid_link_to_html_tree(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\treg_string_list = []\n\treg_string2 = [r\'(!\\[\\]|!\\[.+\\])\\((file:///.+(\\.mp4|\\.mp4#t=.+))\\)\',\n\t\t\t\t   r\'<video src="\\2" controls></video>\']\n\treg_string_list.extend([reg_string2])\n\tfile_operations_utils.perform_regex_replacement_on_files_tree(\n\t\treg_string_list, directory_path)\ndef convert_gpt_summary_to_markdown_vid_timeline(str_url, TR_MODE, path=None):\n\t# str_url=r\'![009_area-and-slope.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C009_area-and-slope.mp4)\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\tif path is None:\n\t\tpath = os.getcwd()\n\tfile_list = os.listdir(path)\n\tassets_root_path, assets_root_dir = file_operations_utils.get_assets_root_path()\n\tif TR_MODE:\n\t\tprint("assets_root_path is : ", assets_root_path)\n\toutput_dir = file_operations_utils.create_output_directory(\n\t\tassets_root_path)\n\tif TR_MODE:\n\t\tprint("output_dir is : ", output_dir)\n\tfor file in file_list:\n\t\tif file.endswith(".md"):\n\t\t\tif file.find("summary_gpt") != -1:\n\t\t\t\tcwd_floder_name = os.path.basename(path)\n\t\t\t\tfile_summary = file\n\t\t\t\tkey_word = "summary_gpt"\n\t\t\t\tlist_time_head_textshort = get_list_time_head_textshort_text_4_file(\n\t\t\t\t\tfile, key_word)\n\t\t\t\t# list_time_head_textshort_text_to_vid_timeline_md(list_time_head_textshort_text,file,match1)\n\tif TR_MODE:\n\t\tprint("list_time_head_textshort is :", list_time_head_textshort)\n\tlist_time_head_textshort_text_to_vid_timeline_md(\n\t\tlist_time_head_textshort, file_summary, match1)\n\tconvert_md_vid_link_to_html(output_dir)\n\treturn output_dir, file_summary\ndef get_note_vid_name():\n\tfile = os.path.basename(os.getcwd())\n\treturn file+r\'_vid\'+".md"\ndef merge_all_content_into_md_note_file(note_name, file_summary_path, origin_current_vid_file_name, current_vid_md_link_content, OneDrive_KG_current_note_directory_path):\n\twith open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "r", encoding="utf-8") as f:\n\t\tcurrent_note_origin_content = f.read()\n\twith open(file_summary_path, "r", encoding="utf-8") as f:\n\t\tcurrent_vid_summary = f.read()\n\twith open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "w", encoding="utf-8") as f:\n\t\tf.write(current_note_origin_content+origin_current_vid_file_name +\n\t\t\t\tcurrent_vid_md_link_content+current_vid_summary)\ndef generate_vid_note_with_timeline_from_text_summary():\n\tTR_MODE = 1\n\torigin_current_vid_file_name, current_bvid_destination_file_path, OneDrive_KG_current_note_directory_path = move_origin_vid_to_destination(\n\t\tTR_MODE)\n\tcurrent_bvid_name = file_operations_utils.get_current_bvid_name()\n\tif TR_MODE:\n\t\tprint("current_bvid_name:", current_bvid_name)\n\tmd_show_url, md_url = vid_path_2_md_vid_link(\n\t\tcurrent_bvid_destination_file_path, current_bvid_name)\n\tcurrent_vid_md_link_content = \'\\n\\n\'+md_url+\'\\n\'+md_show_url+\'\\n\\n\'\n\tif TR_MODE:\n\t\tprint("md_show_url:", md_show_url)\n\t\tprint("md_url:", md_url)\n\tconvert_chatgpt_summary_text_to_one_line_summary()\n\t# output_dir, file_summary = convert_subtitle_and_summary_to_markdown_vid_timeline(\n\t#\t md_show_url)\n\toutput_dir, file_summary = convert_gpt_summary_to_markdown_vid_timeline(\n\t\tmd_show_url, TR_MODE)\n\tfile_summary_path = os.path.join(output_dir, file_summary)\n\tnote_name = get_note_vid_name()\n\tif TR_MODE:\n\t\tprint("note_name:", note_name)\n\tif not os.path.exists(os.path.join(OneDrive_KG_current_note_directory_path, note_name)):\n\t\t# print(os.path.join(OneDrive_KG_current_note_directory_path, note_name),"is note exists")\n\t\t# raise Exception("note not found")\n\t\twith open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "w", encoding="utf-8") as f:\n\t\t\tpass\n\tmerge_all_content_into_md_note_file(note_name, file_summary_path, origin_current_vid_file_name,\n\t\t\t\t\t\t\t\t\t\tcurrent_vid_md_link_content, OneDrive_KG_current_note_directory_path)\n\tconvert_md_vid_link_to_html(OneDrive_KG_current_note_directory_path)\ndef timestamps_3blue1brown_2_timeline(str_url):\n\t# process url\n\t# str_url=r\'![007_limits.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C007_limits.mp4)\'\n\t# \'(!\\[.+\\..+\\]\\(file:///C:%5CBaiduSyncdisk%5Cassets(%5C.+){1,}\\.\\w+)(\\))\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\t# timestamps file\n\tfile_list = os.listdir(os.getcwd())\n\tfor file in file_list:\n\t\tif file.endswith(".md") or file.endswith(".txt"):\n\t\t\tif file.find("timestamps") != -1:\n\t\t\t\tkey_word = "timestamps"\n\t\t\t\tlist_time_head_textshort_text = get_list_time_head_textshort_text_4_file(\n\t\t\t\t\tfile, key_word)\n\t\t\t\toutput_dir, file_name = list_time_head_textshort_text_to_vid_timeline_md(\n\t\t\t\t\tlist_time_head_textshort_text, file, match1)\n\t\t\t\treturn output_dir, file_name\ndef generate_vid_note_with_timeline_from_timestamps():\n\tTR_MODE = 1\n\torigin_current_vid_file_name, current_bvid_destination_file_path, OneDrive_KG_current_note_directory_path = move_origin_vid_to_destination(\n\t\tTR_MODE)\n\tcurrent_bvid_name = file_operations_utils.get_current_bvid_name(\n\t\tcurrent_bvid_destination_file_path)\n\tmd_show_url, md_url = vid_path_2_md_vid_link(\n\t\tcurrent_bvid_destination_file_path, current_bvid_name)\n\tcurrent_vid_md_link_content = \'\\n\\n\'+md_url+\'\\n\'+md_show_url+\'\\n\\n\'\n\tif TR_MODE:\n\t\tprint("md_show_url:", md_show_url)\n\t\tprint("md_url:", md_url)\n\toutput_dir, file_summary = timestamps_3blue1brown_2_timeline(md_show_url)\n\tfile_summary_path = os.path.join(output_dir, file_summary)\n\tnote_name = get_note_vid_name()\n\tif TR_MODE:\n\t\tprint("note_name:", note_name)\n\tif not os.path.exists(os.path.join(OneDrive_KG_current_note_directory_path, note_name)):\n\t\t# print(os.path.join(OneDrive_KG_current_note_directory_path, note_name),"is note exists")\n\t\t# raise Exception("note not found")\n\t\twith open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "w", encoding="utf-8") as f:\n\t\t\tpass\n\tmerge_all_content_into_md_note_file(note_name, file_summary_path, origin_current_vid_file_name,\n\t\t\t\t\t\t\t\t\t\tcurrent_vid_md_link_content, OneDrive_KG_current_note_directory_path)\n\tconvert_md_vid_link_to_html(OneDrive_KG_current_note_directory_path)\ndef merge_list_time_head_textshort_text(list_time_text, list_time_head_textshort):\n\t# print("list_time_head_textshort is :")\n\t# print(list_time_head_textshort)\n\t# print("list_time_text is :")\n\t# print(list_time_text)\n\tfor i in range(len(list_time_head_textshort)):\n\t\t# print(list_time_head_textshort[i][0])\n\t\tfor j in range(len(list_time_text)):\n\t\t\tif list_time_head_textshort[i][0] == list_time_text[j][0]:\n\t\t\t\ttime_text = list_time_text.pop(j)\n\t\t\t\tprint(time_text)\n\t\t\t\tlist_time_head_textshort[i][3] = time_text[3]\n\t\t\t\t# list_time_head_textshort.append([list_time_head_textshort[i][0],list_time_head_textshort[i][1],list_time_head_textshort[i][2],time_text[3]])\n\t\t\t\tbreak\n\t# print("first merge list_time_head_textshort_text is :")\n\t# print(list_time_head_textshort)\n\tlist_time_head_textshort_text = list_time_head_textshort\n\tif len(list_time_text) > 0:\n\t\t# print("remain:",list_time_text)\n\t\tlist_pop = []\n\t\tfor i in range(len(list_time_text)):\n\t\t\tfor j in range(len(list_time_head_textshort_text)):\n\t\t\t\ttime_text = int(list_time_text[i][0])\n\t\t\t\ttime_shorttext = int(list_time_head_textshort_text[j][0])\n\t\t\t\tif j != len(list_time_head_textshort_text)-1:\n\t\t\t\t\ttime_shorttext_next = int(\n\t\t\t\t\t\tlist_time_head_textshort_text[j+1][0])\n\t\t\t\t\tif time_text > time_shorttext and time_text < time_shorttext_next:\n\t\t\t\t\t\tlist_time_head_textshort_text.insert(\n\t\t\t\t\t\t\tj+1, [list_time_text[i][0], None, None, list_time_text[i][3]])\n\t\t\t\t\t\tlist_pop.append(list_time_text[i])\n\t\t\t\t\t\tbreak\n\t\t\t\telse:\n\t\t\t\t\tif time_text > time_shorttext:\n\t\t\t\t\t\tlist_time_head_textshort_text.append(\n\t\t\t\t\t\t\t[list_time_text[i][0], None, None, list_time_text[i][3]])\n\t\t\t\t\t\tlist_pop.append(list_time_text[i])\n\t\t\t\t\t\tbreak\n\t\tfor elment in list_pop:\n\t\t\tindex = list_time_text.index(elment)\n\t\t\tlist_time_text.pop(index)\n\tif len(list_time_text) > 0:\n\t\tprint("remain:", list_time_text)\n\treturn list_time_head_textshort_text\ndef get_bvid_reg_string(sub_topic1_to_sub_topicn_folder_list, TR_MODE=0):\n\t# sub_topic=sub_topic1_to_sub_topicn_folder_list[-2].split("_")[-2]+" "+sub_topic1_to_sub_topicn_folder_list[-2].split("_")[-1]\n\t# sub_topic=sub_topic1_to_sub_topicn_folder_list[-2].split("_")[-1]\n\treg_sub = [r\'\\d{3}_(.+)\', r\'\\1\']\n\tmatch = re.search(reg_sub[0], sub_topic1_to_sub_topicn_folder_list[-2])\n\tif match:\n\t\tsub_topic1 = re.sub(reg_sub[0], reg_sub[1],\n\t\t\t\t\t\t\tsub_topic1_to_sub_topicn_folder_list[-2])\n\t\tsub_topic1.replace("_", " ")\n\telse:\n\t\traise Exception("sub_topic1 not found")\n\tif TR_MODE:\n\t\tprint("Sub topic1:", sub_topic1)\n\tcurrent_topic = sub_topic1_to_sub_topicn_folder_list[-1].split("_")[-1]\n\tif TR_MODE:\n\t\tprint("Current topic:", current_topic)\n\tbvid_reg_string = current_topic+r\'(( - )|(- - ))\'+sub_topic1+r\'\\.mp4\'\n\tif TR_MODE:\n\t\tprint("bvid_reg_string:", bvid_reg_string)\n\tbvid_srt_reg_string = current_topic + \\\n\t\tr\'(( - )|(- - ))\'+sub_topic1+r\'(\\.en|\\.en.+)\'+r\'\\.srt\'\n\treturn bvid_reg_string, bvid_srt_reg_string\ndef get_bvids_destination_short(sub_topic1_to_sub_topicn_folder_list, BaiduSyncdisk_assets_root):\n\tpath_temp = BaiduSyncdisk_assets_root\n\tfor i in range(len(sub_topic1_to_sub_topicn_folder_list)-1):\n\t\tfolder_temp = sub_topic1_to_sub_topicn_folder_list[i].split(\'_\')[0]\n\t\tif folder_temp != "FPCV":\n\t\t\tpath_temp = os.path.join(path_temp, folder_temp)\n\t\telse:\n\t\t\tpath_temp = os.path.join(\n\t\t\t\tpath_temp, sub_topic1_to_sub_topicn_folder_list[i])\n\t\tif not os.path.exists(path_temp):\n\t\t\tos.makedirs(path_temp)\n\treturn path_temp\ndef get_bvids_origin_topic_path(BaiduSyncdisk_assets_root):\n\treturn os.path.join(BaiduSyncdisk_assets_root, "assets", "bvids", "mc_1683793602")\ndef get_note_name():\n\tfile = os.path.basename(os.getcwd())\n\treturn file+".md"\ndef get_note_vid_tra_name():\n\tfile = os.path.basename(os.getcwd())\n\treturn file+r\'_vid_tra\'+".md"\ndef copy_timestamps_and_index_2_root(directory=None):\n\t"""\n\tCopies files with \'timestamps\' in their name and \'.mdx\' extension to the root directory\n\twith an updated name. Also copies files with \'index\' in their name and \'.mdx\' extension\n\tto the root directory with an updated name.\n\t"""\n\tif directory is None:\n\t\tdirectory = os.getcwd()\n\tcurrent_folder_name = os.path.basename(directory)\n\tfilelist = os.listdir(directory)\n\tfor file in filelist:\n\t\tfile_name, file_extension = os.path.splitext(file)\n\t\tif "timestamps" in file_name and file_extension == \'.md\':\n\t\t\tnew_file_name1 = f"timestamps_{current_folder_name}.md"\n\t\t\tdest_path1 = os.path.join(directory, \'../..\', new_file_name1)\n\t\t\tif not os.path.exists(dest_path1):\n\t\t\t\tshutil.copy(file, dest_path1)\n\t\tif file_extension == \'.mdx\':\n\t\t\tif "index" in file_name:\n\t\t\t\tnew_file_name = f"{current_folder_name}.md"\n\t\t\t\tdest_path = os.path.join(directory, \'../..\', new_file_name)\n\t\t\t\tif not os.path.exists(dest_path):\n\t\t\t\t\tshutil.copy(file, dest_path)\ndef convert_subtitle_and_summary_to_markdown_vid_timeline(str_url):\n\t# str_url=r\'![009_area-and-slope.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C009_area-and-slope.mp4)\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\tcwd = os.getcwd()\n\tfile_list = os.listdir(cwd)\n\tassets_root_path, assets_root_dir = get_assets_root_path()\n\toutput_dir = create_output_directory(assets_root_path)\n\tfor file in file_list:\n\t\tif file.endswith(".md"):\n\t\t\tif file.find("subtitle") != -1:\n\t\t\t\tkey_word = "subtitle"\n\t\t\t\tlist_time_text = get_list_time_head_textshort_text_4_file(\n\t\t\t\t\tfile, key_word)\n\t\t\t\t# list_time_head_textshort_text_to_vid_timeline_md(list_time_head_textshort_text,file,match1)\n\t\t\tif file.find("summary_gpt") != -1:\n\t\t\t\tcwd_floder_name = os.path.basename(cwd)\n\t\t\t\tfile_summary = file\n\t\t\t\tkey_word = "summary_gpt"\n\t\t\t\tlist_time_head_textshort = get_list_time_head_textshort_text_4_file(\n\t\t\t\t\tfile, key_word)\n\t\t\t\t# list_time_head_textshort_text_to_vid_timeline_md(list_time_head_textshort_text,file,match1)\n\tlist_time_head_textshort_text = merge_list_time_head_textshort_text(\n\t\tlist_time_text, list_time_head_textshort)\n\tprint("final is:")\n\tprint(list_time_head_textshort_text)\n\tlist_time_head_textshort_text_to_vid_timeline_md(\n\t\tlist_time_head_textshort_text, file_summary, match1)\n\tconvert_md_vid_link_to_html(output_dir)\n\treturn output_dir, file_summary\ndef convert_subtitle_chatgpt_summary_to_markdown_vid_timeline(str_url):\n\t# str_url=r\'![009_area-and-slope.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C009_area-and-slope.mp4)\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\tcwd = os.getcwd()\n\tfile_list = os.listdir(cwd)\n\tassets_root_path, assets_root_dir = get_assets_root_path()\n\tcreate_output_directory(assets_root_path)\n\tfor file in file_list:\n\t\tif file.endswith(".md"):\n\t\t\tif file.find("summary_gpt") != -1:\n\t\t\t\tkey_word = "summary_gpt"\n\t\t\t\tlist_time_head_textshort_text = get_list_time_head_textshort_text_4_file(\n\t\t\t\t\tfile, key_word)\n\t\t\t\tlist_time_head_textshort_text_to_vid_timeline_md(\n\t\t\t\t\tlist_time_head_textshort_text, file, match1)\n'",
"wiki_processor.py": "'import os\nimport file_operations_utils\ndef remove_wiki_edit_link(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_wiki_edit_link = [\n\t\tr\'\\\\\\[\\[edit\\]\\(https://en\\.wikipedia\\.org/w/index\\.php\\?title=.+ "Edit section: (.+)"\\)\\\\\\]\', r""]\n\treg_string_list.extend([reg_wiki_edit_link])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, directory_path, files_md)\ndef remove_wiki_equation_svg(directory_path=None):\n\tif directory_path is None:\n\t\tdirectory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_wiki_equation_svg = [r\'!\\[([^\\]]+)\\]\\([A-Za-z0-9]+\\.svg\\)\', r"$\\1$"]\n\treg_string_list.extend([reg_wiki_equation_svg])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n\t\treg_string_list, directory_path, files_md)\n'",
