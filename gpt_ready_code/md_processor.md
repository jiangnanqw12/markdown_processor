"book_processor.py": "'import os\nimport re\nimport file_operations_utils\n# epub\ndef base_on_mulu_rename_mds(path=None):\n\tif path is None:\n path = os.getcwd()\n\tmulu_name = "part0001.md"\n\tmulu_path = os.path.join(path, mulu_name)\n\tif not os.path.exists(mulu_path):\n raise ValueError("no mulu file")\n\twith open(mulu_path, \'r\', encoding=\'utf-8\') as f:\n content = f.read()\n\treg_string1 = r"\\[(.+?)\\]\\(.+?(part)\\)"\n# zhi\ndef lower_header_level_in_md_files(path=None):\n\tif path is None:\n path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(path) if f.endswith(\'.md\')]\n\treg_string_head = re.compile(r"(#{1,6}) (.+)")\n\t# what is compile\n\tfor file in files_md:\n try:\n with open(os.path.join(path, file), "r", encoding="utf-8") as f:\n lines = f.readlines()\n processed_lines = []\n for line in lines:\n match = reg_string_head.search(line)\n if match:\n string_sharp = match.group(1)\n head_num = string_sharp.count("#")\n line = reg_string_head.sub(\n (head_num + 1) * "#" + r" \\2", line)\n processed_lines.append(line)\n with open(os.path.join(path, file), "w", encoding="utf-8") as f:\n f.writelines(processed_lines)\n except Exception as e:\n print(f"Failed to process file {file} due to {str(e)}")\ndef prepend_filename_as_header_if_chapter_present(directory=None):\n\treg_string1 = r"\\d{3}_(第.{1,2}章.+)"\n\treg_string2 = r"\\d{3}_(\\d{1,2} .+)\\.md"\n\tif directory is None:\n directory = os.getcwd()\n\treg_string = reg_string2\n\tfiles_md = [f for f in os.listdir(directory) if f.endswith(\'.md\')]\n\t# Iterate over all files in the directory\n\tfor filename in files_md:\n # If the filename contains \'Chapter\'\n match = re.search(reg_string, filename)\n if match:\n chapter_name = match.group(1)\n print(chapter_name)\n # Open the file and read its contents\n with open(os.path.join(directory, filename), \'r\', encoding="utf-8") as f:\n content = f.readlines()\n # Prepend the filename as a level 2 header\n content.insert(0, f\'## {chapter_name}\\n\')\n # Write the modified content back to the file\n with open(os.path.join(directory, filename), \'w\', encoding="utf-8") as f:\n f.writelines(content)\ndef remove_md_copy_code(path=None):\n\tif path is None:\n path = os.getcwd()\n\treg_string_copy_code = [r"```\\n(.+)Copy code", r"```\\1\\n"]\n\treg_string_list = []\n\treg_string_list.append(reg_string_copy_code)\n\tfiles_md = [f for f in os.listdir(path) if f.endswith(\'.md\')]\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, path, files_md)\ndef perform_regex_replacement_on_index_file(directory_path=None):\n\t"""\n\tThis function checks for the existence of an index file in the given directory\n\tpath and performs a regex replacement on it.\n\tArgs:\n directory_path: Path to the directory to check. Defaults to the current working directory.\n\tRaises:\n FileNotFoundError: If the index file is not found in the directory.\n\t"""\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tindex_filename = "000_index.md"\n\tif index_filename not in os.listdir(directory_path):\n raise FileNotFoundError("Index file not found")\n\tfile_paths = [os.path.join(directory_path, index_filename)]\n\tregex_patterns = [(r"- \\[(.+)\\]\\(.+\\)", r"\\1")]\n\tfile_operations_utils.perform_regex_replacement_on_files(\n regex_patterns, directory_path, file_paths)\ndef perform_regex_replacement_on_zhi_mds(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_index_link = [\n r"-\\s+\\[.+\\]\\(https://www.zhihu.com/pub/reader/.+\\)\\n", r""]\n\treg_string_list.extend([reg_index_link])\n\treg_zhi_sao_ma = [\n r"扫码下载知乎APP 客户端\\n\\n!\\[\\]\\(.+sidebar-download-qrcode.wybWudky.png\\)\\n", r""]\n\treg_string_list.extend([reg_zhi_sao_ma])\n\treg_Back_matter_template = [r"---\\n\\n- created:.+\\n- source: .+", r""]\n\treg_string_list.extend([reg_Back_matter_template])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, directory_path, files_md)\ndef convert_zhi_footnote_to_obsidian(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\t# r"[\\[1\\]](https://www.zhihu.com/pub/reader/120057501/chapter/1302455544230445056#n1s) 在英语中，发散一词是diffuse。注意focused（专注）一词的词尾是-ed，而diffuse则不是。发散一词的意思是“薄薄地弥漫出去”。"\n\treg_string1 = [\n r\'<sup><a href="https://www\\.zhihu\\.com/pub/reader.+n\\d{1,2}" id="n\\d{1,2}s">\\[(\\d{1,2})\\]</a></sup>\', r"[^\\1]"]\n\t# r\'<sup><a href="https://www\\.zhihu\\.com/pub/reader.+n\\d{1,2}" id="n\\d{1,2}s">\\[\\d{1,2}\\]</a></sup>\'\n\treg_string_list.extend([reg_string1])\n\treg_string2 = [\n r\'\\[\\\\\\[(\\d{1,2})\\\\\\]\\]\\(https://www\\.zhihu\\.com/pub/.+\\) (.+)\', r"[^\\1]: (\\2)"]\n\treg_string_list.extend([reg_string2])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, directory_path, files_md)\ndef perform_regex_replacement_on_zhi_book_mds_name(path=None):\n\tif path is None:\n path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(path) if f.endswith(\'.md\')]\n\treg_string_dir = [r"(.+) - .+ - 知乎书店", r"\\1"]\n\treg_string_md = [r"(.+) - .+ - 知乎书店(\\.md)", r"\\1\\2"]\n\treg_string_md2 = [r"{ (.+) }", r"{\\1}"]\n\treg_string_list = []\n\treg_string_list.append(reg_string_md)\n\tfile_operations_utils.perform_regex_rename_on_files(\n reg_string_list, path, files_md)\n\tdirs = [directory for directory in os.listdir(\n path) if os.path.isdir(directory)]\n\treg_string_list = []\n\treg_string_list.append(reg_string_dir)\n\tfile_operations_utils.perform_regex_rename_on_files(\n reg_string_list, path, dirs)\ndef num2str_title(num):\n\treturn str(num).zfill(3)\ndef rename_files_base_on_index_markdown(path=None):\n\tcounter = 0\n\tif path is None:\n path = os.getcwd()\n\twith open(os.path.join(path, "000_index.md"), \'r\', encoding=\'UTF-8\') as f:\n lines = f.readlines()\n\tfiles = os.listdir(path)\n\tfor i, line in enumerate(lines):\n line = line.strip().replace("%", "_")\n note_name = line + \'.md\'\n if note_name in files:\n counter += 1\n os.replace(os.path.join(path, note_name),\n os.path.join(path, num2str_title(counter) + "_" + note_name))\n else:\n print(files)\n raise FileNotFoundError(f"{note_name} not in the files list")\ndef get_md_files(directory=\'.\'):\n\t"""Return a sorted list of markdown filenames in a given directory."""\n\tfiles = [f for f in os.listdir(directory) if f.endswith(\'.md\')]\n\t# Extract numeric prefix and sort based on it\n\tfiles.sort(key=lambda x: int(re.match(r\'(\\d{3})_\', x).group(\n 1)) if re.match(r\'(\\d{3})_\', x) else float(\'inf\'))\n\treturn files\ndef check_md_files(files):\n\t# Check if files are in expected order\n\tfor i, filename in enumerate(files):\n expected_prefix = f"{i:03d}_"\n if not filename.startswith(expected_prefix):\n print(\n f"Warning: {filename} does not match expected prefix {expected_prefix}")\ndef merge_files(filenames, output_filename):\n\t"""Merge the content of a list of files and write to a new file."""\n\twith open(output_filename, \'w\', encoding=\'utf-8\') as outfile:\n for fname in filenames:\n try:\n with open(fname, \'r\', encoding=\'utf-8\') as infile:\n content = infile.read()\n outfile.write(content)\n outfile.write(\'\\n\') # add blank lines between files\n except IOError:\n print(f\'Error opening file {fname}, skipping.\')\ndef merge_all_md_files_into_one():\n\t"""Merge all markdown files in the current directory into one file."""\n\troot_path, root_dir = file_operations_utils.get_assets_root_path()\n\toutput_file = os.path.join(root_path, root_dir+".md")\n\tmd_files = get_md_files()\n\tcheck_md_files(md_files)\n\tmerge_files(md_files, output_file)\ndef Merge_all_md_files_into_one_file_base_on_num_index():\n\tfiles = [f for f in os.listdir() if f.endswith(\'.md\')]\n\tfiles.sort()\n\tprint(files)\n\troot_path, root_dir = file_operations_utils.get_assets_root_path()\n\twith open(os.path.join(root_path, root_dir+".md"), \'w\', encoding=\'utf-8\') as f:\n for file in files:\n with open(file, \'r\', encoding=\'utf-8\') as f2:\n content = f2.read()\n f.write(content)\n f.write(\'\\n\\n\')\n'",
"file_operations_utils.py": "'import os\nimport re\nimport time\nimport pyperclip\nimport glob\nimport subprocess\ndef back_up_dir_tree(path):\n\ttime_str = datetime.datetime.now().strftime(\'%Y-%m-%d-%H-%M-%S\')\n\t# get the father path\n\tfather_path = os.path.abspath(os.path.dirname(path) + os.path.sep + ".")\n\t# get current dir name\n\tdir_name = os.path.basename(path)\n\tback_path = os.path.join(father_path, dir_name+"_"+time_str)\n\t# os.mkdir(back_path)\n\t# copy all files in the current path to the back_path\n\tshutil.copytree(path, back_path)\ndef back_up_dir(src_dir):\n\ttime_str = datetime.datetime.now().strftime(\'%Y-%m-%d-%H-%M-%S\')\n\t# get the father path\n\tfather_path = os.path.abspath(os.path.dirname(src_dir) + os.path.sep + ".")\n\t# get current dir name\n\tdir_name = os.path.basename(src_dir)\n\tback_path = os.path.join(src_dir, dir_name+"_"+time_str)\n\t# os.mkdir(back_path)\n\tif not os.path.exists(back_path):\n os.makedirs(back_path)\n\t# copy all files in the current path to the back_path\n\tfor filename in os.listdir(src_dir):\n src_path = os.path.join(src_dir, filename)\n dst_path = os.path.join(back_path, filename)\n if os.path.isfile(src_path):\n shutil.copy2(src_path, dst_path)\ndef get_father_path(path):\n\treturn os.path.dirname(path)\n# 0\ndef create_directory_assets_imgs():\n\tdirs = [\n "assets/imgs",\n "assets/vids"\n\t]\n\tfor directory in dirs:\n if not os.path.exists(directory):\n os.makedirs(directory)\n print(f"Created directory: {directory}")\n else:\n print(f"Directory already exists: {directory}")\ndef create_directory_assets_concept_structure():\n\tdirs = [\n "assets",\n "assets/imgs",\n "assets/lectures",\n "assets/papers",\n "lectures",\n "papers",\n\t]\n\tfor directory in dirs:\n if not os.path.exists(directory):\n os.makedirs(directory)\n print(f"Created directory: {directory}")\n else:\n print(f"Directory already exists: {directory}")\ndef open_folder_in_windows(folder_path):\n\t"""Open a folder in Windows File Explorer based on the folder path.\n\tArgs:\n\tfolder_path (str): The folder path to open.\n\tReturns:\n\tNone\n\t"""\n\tif os.path.exists(folder_path):\n os.startfile(folder_path)\n\telse:\n print(f"Folder path {folder_path} does not exist.")\ndef open_b_assets_folder(cwd=None):\n\tif cwd is None:\n cwd = os.getcwd()\n\tprint(cwd)\n\tif cwd.find("OneDrive") == -1:\n raise Exception("This script is only for use with OneDrive.")\n\tassets_path_front = "C:/BaiduSyncdisk/assets"\n\t# Split the path after \'KG\' and replace backslashes with forward slashes\n\tkg_path_back = cwd.split("\\\\KG")[1].replace("\\\\", "/")\n\t# Remove the leading forward slash from kg_path_back\n\tkg_path_back = kg_path_back.lstrip("/")\n\tassets_path = os.path.join(assets_path_front, kg_path_back)\n\tif assets_path.find("BaiduSyncdisk") == -1:\n raise Exception("The assets path is not in BaiduSyncdisk.")\n\topen_folder_in_windows(assets_path)\ndef perform_regex_rename_on_files(reg_string_list, path=None, files=None):\n\tif path is None:\n path = os.getcwd()\n\tif files is None:\n files = os.listdir(path)\n\tfor file in files:\n for reg_string in reg_string_list:\n match = re.search(reg_string[0], file)\n if match is not None:\n new_file = re.sub(reg_string[0], reg_string[1], file)\n try:\n os.rename(file, new_file)\n print(f"Renamed \'{file}\' to \'{new_file}\'")\n except OSError as e:\n print(f"Error renaming \'{file}\' to \'{new_file}\': {e}")\ndef rename_files_in_directories(base_path=None):\n\trename_files_in_directories_2()\ndef rename_files_in_directories_2(base_path=None):\n\t"""\n\t/index/*.mp4\n\tto\n\t/index_*.mp4\n\tRename all files in numbered directories within the base path.\n\tEach file is prefixed with the directory number, zero-padded to three digits.\n\t"""\n\t# Use the current working directory if no path is provided\n\tbase_path = base_path or os.getcwd()\n\tfiles = os.listdir(base_path)\n\tfiles_mp4 = []\n\tfor f in files:\n if f.endswith(".mp4"):\n files_mp4.append(f)\n\t# Validate the base path\n\tif not os.path.isdir(base_path):\n print(f"The provided path \'{base_path}\' is not a valid directory.")\n return\n\tfor index in range(16):\n start_str = f"{16 - index:03d}_"\n for file_mp4 in files_mp4:\n if file_mp4.startswith(start_str):\n new_file = f"{1+index:03d}{file_mp4[3:]}"\n os.rename(os.path.join(base_path, file_mp4),\n os.path.join(base_path, new_file))\ndef rename_files_in_directories_1(base_path=None):\n\t"""\n\t/index/*.mp4\n\tto\n\t/index_*.mp4\n\tRename all files in numbered directories within the base path.\n\tEach file is prefixed with the directory number, zero-padded to three digits.\n\t"""\n\t# Use the current working directory if no path is provided\n\tbase_path = base_path or os.getcwd()\n\t# Validate the base path\n\tif not os.path.isdir(base_path):\n print(f"The provided path \'{base_path}\' is not a valid directory.")\n return\n\tfor index in range(16):\n dir_path = os.path.join(base_path, f"{16 - index}")\n # Check if the directory exists\n if not os.path.isdir(dir_path):\n print(f"Directory \'{dir_path}\' does not exist. Skipping.")\n continue\n try:\n for file in os.listdir(dir_path):\n old_file_path = os.path.join(dir_path, file)\n # Zero-padded prefix\n new_file_name = f"{16 - index:03d}_{file}"\n new_file_path = os.path.join(base_path, new_file_name)\n os.rename(old_file_path, new_file_path)\n print(f"Renamed \'{old_file_path}\' to \'{new_file_path}\'")\n except OSError as e:\n print(f"Error renaming files in \'{dir_path}\': {e}")\ndef get_current_timestamp():\n\ttimestamp = int(time.time())\n\tprint(timestamp)\n\treturn timestamp\ndef add_timestamp_to_filenames():\n\tcurrent_dir = os.getcwd()\n\ttimestamp = int(time.time())\n\tprint("add_timestamp is : ", timestamp)\n\tfor filename in os.listdir(current_dir):\n if os.path.isfile(os.path.join(current_dir, filename)) and not filename.endswith(".py"):\n filename_without_ext, ext = os.path.splitext(filename)\n new_filename = f"{filename_without_ext}_{timestamp}{ext}"\n os.replace(os.path.join(current_dir, filename),\n os.path.join(current_dir, new_filename))\ndef get_Topic_in_kg(TR_MODE=0):\n\tassets_sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tif TR_MODE:\n print("assets_sub_topic1_to_sub_topicn_folder_list:",\n assets_sub_topic1_to_sub_topicn_folder_list)\n print("OneDrive KG root directory_path:",\n OneDrive_KG_note_root_directory_path)\n\tTopic = os.path.basename(OneDrive_KG_note_root_directory_path)\n\tif TR_MODE:\n print("Topic:", Topic)\n\tnum_topic = len(assets_sub_topic1_to_sub_topicn_folder_list)\n\treg_sub1 = [r\'\\d{3}_(.+)\', r\'\\1\']\n\tif num_topic < 1:\n sub_topic1 = None\n\telif num_topic >= 1:\n sub_topic1 = assets_sub_topic1_to_sub_topicn_folder_list[0]\n match = re.search(reg_sub1[0], sub_topic1)\n if match:\n sub_topic1 = re.sub(reg_sub1[0], reg_sub1[1], sub_topic1)\n if TR_MODE:\n print("sub_topic1:", sub_topic1)\n\treturn Topic, sub_topic1\ndef perform_regex_replacement_on_files(reg_string_list, path=None, files=None):\n\tif path is None:\n path = os.getcwd()\n\tif files is None:\n files = os.listdir(path)\n\tfor file in files:\n with open(os.path.join(path, file), "r", encoding="utf-8") as f1:\n content = f1.read()\n for regex in reg_string_list:\n content = re.sub(regex[0], regex[1], content)\n with open(os.path.join(path, file), "w", encoding="utf-8") as f:\n f.write(content)\ndef perform_regex_replacement_on_files_tree(reg_string_list, path=None):\n\tif path is None:\n path = os.getcwd()\n\tfor root, dirs, files in os.walk(path):\n for file in files:\n file_path = os.path.join(root, file)\n with open(file_path, "r", encoding="utf-8") as f1:\n content = f1.read()\n new_content = content\n for regex in reg_string_list:\n new_content = re.sub(regex[0], regex[1], new_content)\n if new_content != content:\n with open(file_path, "w", encoding="utf-8") as f:\n f.write(new_content)\ndef get_bvids_origin_topic_path(Topic, TR_MODE=0):\n\t# bvids_origin_topic_path = get_bvids_origin_topic_path(BaiduSyncdisk_assets_root)\n\t# bvids_origin_topic_path = r"C:\\BaiduSyncdisk\\Multivariable_calculus_Khan_Academy_youtube"\n\t# bvids_origin_topic_path=r\'C:\\BaiduSyncdisk\\First Principles of Computer Vision Specialization\\Features and Boundaries\'\n\tbvids_origin_topic_path = r\'C:\\BaiduSyncdisk\\00_MOOC_b\'\n\t# bvids_origin_topic_path=r\'C:\\BaiduSyncdisk\\deep\'\n\t# bvids_origin_topic_path=r\'C:\\BaiduSyncdisk\\Introduction\'\n\tif Topic is None:\n raise Exception("Topic is None")\n\tbvids_origin_topic_path = os.path.join(\n bvids_origin_topic_path, Topic)\n\tif TR_MODE:\n print("bvids_origin_topic_path:", bvids_origin_topic_path)\n\t# if os.path.basename(bvids_origin_topic_path) != Topic:\n\t#\t print("bvids_origin_topic_path:", bvids_origin_topic_path)\n\t#\t print("Topic:", Topic)\n\t#\t raise Exception("Topic name not match")\n\treturn bvids_origin_topic_path\ndef get_kg_assets_root(current_dir=None):\n\t\'\'\'\n\t\'\'\'\n\tTR_MODE = 1\n\tif current_dir is None:\n current_dir = os.getcwd()\n\tsub_topic1_to_sub_topicn_folder_list = []\n\twhile True:\n if \'assets\' in os.listdir(current_dir):\n sub_topic1_to_sub_topicn_folder_list.reverse()\n return sub_topic1_to_sub_topicn_folder_list, current_dir\n else:\n sub_topic1_to_sub_topicn_folder_list.append(\n os.path.basename(current_dir))\n current_dir = os.path.dirname(current_dir)\ndef create_file_subtitle_summary_gpt_md(path=None):\n\t# Create a file named subtitle.md and summary_gpt.md\n\tprint("create_file_subtitle_summary_gpt_md")\n\tif path is None:\n path = os.getcwd()\n\ttime_stamp = int(time.time())\n\twith open(os.path.join(path, "subtitle_"+str(time_stamp)+".md"), "w") as f:\n pass\n\twith open(os.path.join(path, "summary_gpt_"+str(time_stamp)+".md"), "w") as f:\n pass\n\twith open(os.path.join(path, "timestamps_"+str(time_stamp)+".md"), "w") as f:\n pass\ndef get_note_assets_dir_path(sub_topic1_to_sub_topicn_folder_list, current_dir):\n\t# sub_topic1_to_sub_topicn_folder_list.append(os.path.basename(current_dir))\n\t# current_dir = os.path.dirname(current_dir)\n\twhile True:\n if \'assets\' in os.listdir(current_dir):\n sub_topic1_to_sub_topicn_folder_list.reverse()\n if sub_topic1_to_sub_topicn_folder_list != []:\n note_assets_dir_path = os.path.join(current_dir, \'assets\')\n for folder_name in sub_topic1_to_sub_topicn_folder_list:\n note_assets_dir_path = os.path.join(\n note_assets_dir_path, folder_name)\n # print(note_assets_dir_path)\n # if os.path.isdir(note_assets_dir_path):\n if not os.path.exists(note_assets_dir_path):\n os.makedirs(note_assets_dir_path)\n return note_assets_dir_path\n # else:\n #\t raise Exception(\'not a directory \',note_assets_dir_path)\n else:\n raise Exception("No folder name found")\n break\n else:\n sub_topic1_to_sub_topicn_folder_list.append(\n os.path.basename(current_dir))\n current_dir = os.path.dirname(current_dir)\ndef initialize_notes_files_structure():\n\tTR_mode = 1\n\ttimestamp = int(time.time())\n\t# Get the current directory\n\tcurrent_directory = os.getcwd()\n\tif TR_mode:\n print(f"Current directory: {current_directory}")\n\t# Get the parent directory\n\tparent_directory = os.path.dirname(current_directory)\n\tif TR_mode:\n print(f"Parent directory: {parent_directory}")\n # Get the name of the current directory\n\tcurrent_directory_name = os.path.basename(current_directory)\n\tif TR_mode:\n print(f"Current directory name: {current_directory_name}")\n\t# Get the name of the parent directory\n\tparent_directory_name = os.path.basename(parent_directory)\n\tif TR_mode:\n print(f"Parent directory name: {parent_directory_name}")\n\tstart_file = "000_"+current_directory_name+"_"+parent_directory_name+".md"\n\tif TR_mode:\n print(f"start_file: {start_file}")\n\t# Check if file exists, if not create it\n\tstart_file__directory = os.path.join(current_directory, start_file)\n\tif not os.path.exists(start_file__directory):\n with open(start_file__directory, \'w\') as f:\n f.write(\'\') # creating an empty markdown file\n\tstring_list = current_directory_name.split("_")\n\tlen_string_list = len(string_list)\n\tif len_string_list < 1:\n raise ValueError("len error")\n\telif len_string_list == 1:\n if len(string_list[0]) < 2:\n raise ValueError("len error")\n folder_b_assets = string_list[0][0] + \\\n string_list[-1][-1]+"_"+str(timestamp)\n\telif len_string_list > 1:\n folder_b_assets = string_list[0][0] + \\\n string_list[-1][0]+"_"+str(timestamp)\n\tif TR_mode:\n print("folder_b_assets: ", folder_b_assets)\n\tassets_directory = os.path.join(current_directory, "assets")\n\t# Check if \'assets\' directory exists, if not create it\n\tif not os.path.exists(assets_directory):\n os.mkdir(assets_directory)\n if TR_mode:\n print(f"\'assets\' directory created in {current_directory}")\n\tb_assets_directory = os.path.join(assets_directory, folder_b_assets)\n\tif not os.path.exists(b_assets_directory):\n os.mkdir(b_assets_directory)\n if TR_mode:\n print(\n f"b_assets_directory directory created in {b_assets_directory}")\n\tfile_git_ignore = os.path.join(b_assets_directory, ".gitignore")\n\tif not os.path.exists(file_git_ignore):\n with open(file_git_ignore, \'w\') as f:\n f.write(\'*.flv\\n*.mp4\\n*.srt\\n*.vtt\\n*.pdf\\n*.epub\\n*.pptx\\n\')\n\tfile_readme = os.path.join(b_assets_directory, "readme.md")\n\tif not os.path.exists(file_readme):\n with open(file_readme, \'w\') as f:\n f.write(current_directory_name+"\\n")\ndef rename_folders_4_mooc_b(path=None, zfill_num=3):\n\tif path is None:\n path = os.getcwd()\n\timport flags_utils\n\tFlags = flags_utils.GlobalFlags()\n\tFlags.set_flag(\'TR_MODE\', 1)\n\tTR_MODE = Flags.get_flag(\'TR_MODE\')\n\t# files_mp4 = [f for f in os.listdir(\n\t#\t path) if f.endswith(".mp4")]\n\t# files_vtt = [f for f in os.listdir(\n\t#\t path) if f.endswith(".vtt")]\n\t# files_srt = [f for f in os.listdir(\n\t#\t path) if f.endswith(".srt")]\n\tfiles = os.listdir(path)\n\t# for file_mp4 in files_mp4:\n\t# r"How Ultrasonic Energy is Created _ Science of Energy Ep. 1 _ Ethicon-Bd2xISKVyFc.mp4"\n\tr"Monopolar Electrosurgery Technology and Principles - Science of Energy Ep. 5 - E.en.srt"\n\treg_string_vid1 = [\n r\'(.+) ｜ Fuzzy Logic.+Part (\\d{1,2})\\.mp4\', \'\']\n\treg_string_sub1 = [\n r"(.+) ｜ Fuzzy Logic.+Part (\\d{1,2})(\\.en|\\.eng|\\.zh|\\.cn|\\.zho|\\.chi|\\.zh-Hans|\\.zh-Hant|)-eEY6OEpapPo(\\.vtt|\\.srt)", r\'\\1\']\n\treg_string_vid2 = [\n r\'(.+) - Science of Energy Ep. (\\d{1,2}) -.+\\.mp4\', \'\']\n\treg_string_sub2 = [\n r"(.+) - Science of Energy Ep. (\\d{1,2}) -.+\\.en\\.srt", r\'\\1\']\n\treg_sring_vid = reg_string_vid1\n\treg_sring_sub = reg_string_sub1\n\tfor file in files:\n match = re.search(reg_sring_vid[0], file)\n if match:\n series_num = match.group(2)\n series_num = series_num.zfill(zfill_num)\n reg_string_vid_replace = series_num+"_"+r"\\1"+".mp4"\n if TR_MODE:\n print("reg_string_vid_replace is:", reg_string_vid_replace)\n file_name = re.sub(reg_sring_vid[0], reg_string_vid_replace, file)\n if TR_MODE:\n print(file_name)\n os.rename(os.path.join(path, file), os.path.join(\n path, file_name))\n match = re.search(reg_sring_sub[0], file)\n if match:\n series_num = match.group(2)\n series_num = series_num.zfill(zfill_num)\n reg_string_sub_replace = series_num+"_"+r"\\1"+r"\\3"+r"\\4"\n if TR_MODE:\n print("reg_string_sub_replace is:\\n", reg_string_sub_replace)\n file_name = re.sub(reg_sring_sub[0], reg_string_sub_replace, file)\n if TR_MODE:\n print("file_name is :\\n", file_name)\n os.rename(os.path.join(path, file), os.path.join(\n path, file_name))\ndef zfill_folder_files(path=None, zfill_num=3):\n\tif path is None:\n path = os.getcwd()\n\tfiles = [f for f in os.listdir(\n path) if os.path.isfile(os.path.join(path, f))]\n\tfor file in files:\n file_name, file_ext = os.path.splitext(file)\n file_name_zfilled = file_name.zfill(zfill_num)\n os.rename(os.path.join(path, file), os.path.join(\n path, file_name_zfilled + file_ext))\n\tdirs = [f for f in os.listdir(\n path) if os.path.isdir(os.path.join(path, f))]\n\tfor dir in dirs:\n dir_name, dir_ext = os.path.splitext(dir)\n dir_name_zfilled = dir_name.zfill(zfill_num)\n os.rename(os.path.join(path, dir), os.path.join(\n path, dir_name_zfilled + dir_ext))\ndef get_kg_bassets_folder_keyword():\n\tTR_MODE = 1\n\tsub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tif TR_MODE:\n print("Folder list:", sub_topic1_to_sub_topicn_folder_list)\n print("OneDrive KG root directory_path:",\n OneDrive_KG_note_root_directory_path)\n\tOneDrive_KG_assets_directory_path = os.path.join(\n OneDrive_KG_note_root_directory_path, "assets")\n\tif TR_MODE:\n print("OneDrive KG assets directory_path:",\n OneDrive_KG_assets_directory_path)\n\tdirs = [directory for directory in os.listdir(OneDrive_KG_assets_directory_path) if os.path.isdir(\n os.path.join(OneDrive_KG_assets_directory_path, directory))]\n\tif TR_MODE:\n print("dirs:", dirs)\n\treg_string = [r".+_\\d{10}", r"\\1"]\n\tfor dir in dirs:\n match = re.search(reg_string[0], dir)\n if match:\n if TR_MODE:\n print("match.group(0):", match.group(0))\n keyword_path = os.path.join(OneDrive_KG_assets_directory_path, dir)\n if TR_MODE:\n print("keyword_path:", keyword_path)\n return match.group(0), keyword_path\ndef get_bassets_keyword_path(current_dir=None, key_word="mc_1683793602"):\n\t\'\'\'\n\tkg and bkg 中的 bassets path\n\t\'\'\'\n\tTR_MODE = 1\n\tif current_dir is None:\n current_dir = os.getcwd()\n\tkeyword_sub_topic1_to_sub_topicn_folder_list = []\n\tkeyword_sub_topic1_to_sub_topicn_folder_list.append(\n os.path.basename(current_dir))\n\tcurrent_dir = os.path.dirname(current_dir)\n\twhile True:\n if \'assets\' in os.listdir(current_dir):\n keyword_sub_topic1_to_sub_topicn_folder_list.reverse()\n keyword_sub_topic1_to_sub_topicn_folder_list.insert(1, key_word)\n return keyword_sub_topic1_to_sub_topicn_folder_list, current_dir\n else:\n keyword_sub_topic1_to_sub_topicn_folder_list.append(\n os.path.basename(current_dir))\n current_dir = os.path.dirname(current_dir)\ndef get_Topic_in_kg_assets(TR_MODE=0):\n\tassets_sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tif TR_MODE:\n print("assets_sub_topic1_to_sub_topicn_folder_list:",\n assets_sub_topic1_to_sub_topicn_folder_list)\n print("OneDrive KG root directory_path:",\n OneDrive_KG_note_root_directory_path)\n\tTopic = os.path.basename(OneDrive_KG_note_root_directory_path)\n\tif TR_MODE:\n print("Topic:", Topic)\n\tnum_topic = len(assets_sub_topic1_to_sub_topicn_folder_list)\n\treg_sub1 = [r\'\\d{3}_(.+)\', r\'\\1\']\n\tif num_topic <= 1:\n raise Exception("num_topic<=1")\n\telif num_topic == 2:\n sub_topic1 = None\n\telif num_topic >= 3:\n match = re.search(\n reg_sub1[0], assets_sub_topic1_to_sub_topicn_folder_list[1])\n if match:\n sub_topic1 = re.sub(reg_sub1[0], reg_sub1[1],\n assets_sub_topic1_to_sub_topicn_folder_list[1])\n if TR_MODE:\n print("sub_topic1:", sub_topic1)\n else:\n raise Exception("sub_topic1 not found")\n\tcurrent_topic = assets_sub_topic1_to_sub_topicn_folder_list[-1]\n\tcurrent_topic = re.sub(reg_sub1[0], reg_sub1[1], current_topic)\n\treturn Topic, sub_topic1, current_topic\ndef get_b_KG_directory_path(path=None):\n\tif path is None:\n path = os.getcwd()\n\tif path.find("OneDrive") == -1 or path.find("KG") == -1:\n raise Exception("This script is only for use with OneDrive/KG.")\n\t# if path.find("assets") ==-1:\n\t#\t raise Exception("current path is not an assets path.")\n\t# reg_search=[r\'(.+\\\\OneDrive\\\\KG\\\\)(.+)\']\n\treg_search = [\n [r\'.+\\\\OneDrive\\\\KG\\\\(.+)\', r\'C:\\\\BaiduSyncdisk\\\\assets\\\\\\1\']]\n\ttest2 = r\'C:\\BaiduSyncdisk\\assets\\O\\O1\\O17\\O172\\Multivaribale_calculus_Khan_Academy\\assets\\bvids\\mc_1683793602\\001_\\005_\'\n\ttest = r\'C:\\Users\\shade\\OneDrive\\KG\\O\\O1\\O17\\O172\\Multivaribale_calculus_Khan_Academy\\assets\\001_Thinking about multivariable functions\\005_Transformations\\003_Transformations, part 3\'\n\t# print(path)\n\tmatch1 = re.search(reg_search[0][0], path)\n\tif match1:\n path_b_assets = re.sub(reg_search[0][0], reg_search[0][1], path)\n # print(path_b_assets)\n return path_b_assets\ndef get_OneDrive_KG_note_path(OneDrive_KG_root, sub_topic1_to_sub_topicn_folder_list):\n\tOneDrive_KG_note_path = OneDrive_KG_root\n\tfor i in range(2, len(sub_topic1_to_sub_topicn_folder_list)-1):\n OneDrive_KG_note_path = os.path.join(\n OneDrive_KG_note_path, sub_topic1_to_sub_topicn_folder_list[i])\n\tprint(OneDrive_KG_note_path)\n\treturn OneDrive_KG_note_path\ndef get_current_bvid_name(path=None):\n\tif path is None:\n path = os.getcwd()\n\tfile = os.path.basename(path)\n\treturn file+".mp4"\ndef get_bvids_destination_long(sub_topic1_to_sub_topicn_folder_list, BaiduSyncdisk_assets_root):\n\tpath_temp = BaiduSyncdisk_assets_root\n\tfor i in range(len(sub_topic1_to_sub_topicn_folder_list)-1):\n path_temp = os.path.join(\n path_temp, sub_topic1_to_sub_topicn_folder_list[i])\n if not os.path.exists(path_temp):\n os.makedirs(path_temp)\n\treturn path_temp\ndef get_assets_root_path(current_dir=None):\n\tif current_dir is None:\n current_dir = os.getcwd()\n\twhile True:\n if \'assets\' in os.listdir(current_dir):\n return current_dir, os.path.basename(current_dir)\n else:\n current_dir = os.path.dirname(current_dir)\n if current_dir == \'\':\n raise Exception(\'assets folder not found\')\ndef create_output_directory(root=None):\n\tif root is None:\n root = os.getcwd()\n\toutput_dir = os.path.join(root, \'output\')\n\tif not os.path.exists(output_dir):\n os.mkdir(output_dir)\n\t# print("Created output directory %s" % output_dir)\n\treturn output_dir\ndef create_new_file_name(file):\n\tif not file.endswith(\'.md\'):\n filename_without_ext = os.path.splitext(file)[0]\n new_file_name = filename_without_ext+\'.md\'\n\telse:\n new_file_name = file\n\tprint(new_file_name)\n\treturn new_file_name\ndef create_excalidraw_file_based_on_content(content=None, path=None):\n\twrite_string = """\n---\nexcalidraw-plugin: parsed\ntags: [excalidraw]\n---\n==⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠==\n%%\n# Drawing\n```json\n{"type":"excalidraw","version":2,"source":"https://github.com/zsviczian/obsidian-excalidraw-plugin/releases/tag/1.9.19","elements":[],"appState":{"gridSize":null,"viewBackgroundColor":"#ffffff"}}\n```\n%%\n"""\n\text = ".excalidraw" + ".md"\n\tcreate_file_based_on_content(\n write_string, ext, content, path)\ndef create_drawio_file_based_on_content(content=None, path=None):\n\twrite_string = """\n<svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="0px" width="0px" viewBox="-10 -10 20 20" content="&lt;mxGraphModel dx=&quot;801&quot; dy=&quot;859&quot; grid=&quot;1&quot; gridSize=&quot;10&quot; guides=&quot;1&quot; tooltips=&quot;1&quot; connect=&quot;1&quot; arrows=&quot;1&quot; fold=&quot;1&quot; page=&quot;1&quot; pageScale=&quot;1&quot; pageWidth=&quot;827&quot; pageHeight=&quot;1169&quot; math=&quot;0&quot; shadow=&quot;0&quot;&gt;&lt;root&gt;&lt;mxCell id=&quot;0&quot;/&gt;&lt;mxCell id=&quot;1&quot; parent=&quot;0&quot;/&gt;&lt;/root&gt;&lt;/mxGraphModel&gt;"><style type="text/css"></style></svg>\n"""\n\text = ".drawio.svg"\n\tcreate_file_based_on_content(\n write_string, ext, content, path)\ndef create_file_based_on_content(write_string="", ext="", content=None, path=None):\n\tif content is None:\n content = pyperclip.paste()\n\tif path is None:\n path = os.getcwd()\n\tif len(content) > 100:\n raise ValueError("Content length exceeds 100 characters")\n\tif len(content) < 1:\n raise ValueError("Content length is less than 1 character")\n\tif content.count("\\n") > 2:\n raise TypeError("Content contains more than 2 newline characters")\n\tcontent = content.replace(\'\\n\', \' \')\n\tcontent = content.replace(\'\\r\', \' \')\n\treg = [r"\\s{2,}", r\' \']\n\tcontent = re.sub(reg[0], reg[1], content)\n\ttimestamp = str(int(time.time()))\n\tnew_name = content.strip() + "_" + timestamp+ext\n\twith open(os.path.join(path, new_name), "w", encoding="utf-8") as file:\n file.write(write_string)\ndef rename_index_folder_files(base_dir=None):\n\tif base_dir is None:\n base_dir = os.getcwd()\n\t# Ensure the path is absolute\n\tbase_dir = os.path.abspath(base_dir)\n\t# Iterate through the subdirectories under the base directory\n\tfor subdir in os.listdir(base_dir):\n subdir_path = os.path.join(base_dir, subdir)\n if os.path.isdir(subdir_path):\n # Ensure the subdirectory name is numeric before proceeding\n if subdir.isnumeric():\n # Format the subdirectory name with leading zeros\n formatted_subdir = f"{int(subdir):04d}"\n # Use glob to find all .mp4 files in the subdirectory\n mp4_files = glob.glob(os.path.join(subdir_path, "*.mp4"))\n # Rename each .mp4 file\n for mp4_file in mp4_files:\n basename = os.path.basename(mp4_file)\n new_name = f"{formatted_subdir}_{basename}"\n new_path = os.path.join(base_dir, new_name)\n os.rename(mp4_file, new_path)\ndef rename_bilibili_subs(path=None):\n\t\'\'\' 重命名下载的字幕，改成视频名\'\'\'\n\tif path is None:\n path = os.getcwd()\n\tfiles_mp4 = glob.glob(os.path.join(path, "*.mp4"))\n\tfiles_srt = glob.glob(os.path.join(path, "*.srt"))\n\tfor file_mp4 in files_mp4:\n basename = os.path.basename(file_mp4)\n new_name = f"{basename.split(\'.\')[0]}.srt"\n new_path = os.path.join(path, new_name)\n for file_srt in files_srt:\n mp4 = (basename.split(\'.\')[0]).split(\'_\')[1]\n if mp4 in file_srt:\n os.rename(file_srt, new_path)\n'",
"flags_utils.py": "'class GlobalFlags:\n\tdef __init__(self):\n self.flags = {\n \'flag_one_by_one\': False,\n \'verbose\': False,\n \'debug\': True,\n \'TR_MODE\': True,\n \'TR_MODE_debug\': True,\n }\n\tdef set_flag(self, name, value):\n if name in self.flags:\n self.flags[name] = value\n else:\n raise KeyError(f"Flag \'{name}\' not found.")\n\tdef get_flag(self, name):\n print(f"Getting flag \'{name}\'")\n print(f"Flags: {self.flags}")\n return self.flags.get(name, None)\n\tdef toggle_flag(self, name):\n if name in self.flags:\n self.flags[name] = not self.flags[name]\n else:\n raise KeyError(f"Flag \'{name}\' not found.")\ndef get_flag_one_by_one(TR_MODE=0):\n\tflag_one_by_one = True\n\treturn flag_one_by_one\ndef get_flag_search_sub_topic1_in_bvids_origin_topic_path(TR_MODE=0):\n\tflag_search_sub_topic1 = False\n\treturn flag_search_sub_topic1\nif __name__ == \'__main__\':\n\t# Usage\n\tflags = GlobalFlags()\n\tflags.set_flag(\'debug\', True)\n\tprint(flags.get_flag(\'debug\')) # Output: True\n\tflags.toggle_flag(\'debug\')\n\tprint(flags.get_flag(\'debug\')) # Output: False\n'",
"html_processor.py": "'import os\nimport re\nimport time\nimport urllib.parse\n# import aspose.words as aw\nimport subprocess\nfrom typing import Optional\nimport glob\ndef convert_html_to_md(input_directory=None, output_directory=None):\n\tif input_directory is None:\n input_directory = os.getcwd()\n\tif output_directory is None:\n output_directory = os.path.join(input_directory, "md")\n\ttry:\n # Create the output directory if it does not exist\n os.makedirs(output_directory, exist_ok=True)\n # List all files in the input directory\n files = [f for f in os.listdir(input_directory) if f.endswith(\'.html\')]\n for file in files:\n input_file = os.path.join(input_directory, file)\n output_file = os.path.join(\n output_directory, file.replace(\'.html\', \'.md\'))\n # Convert HTML to Markdown and extract images\n subprocess.run([\'pandoc\', \'--extract-media=\' + output_directory,\n input_file, \'-o\', output_file], check=True)\n print(\n f\'Successfully converted HTML files to Markdown in {output_directory}\')\n\texcept subprocess.CalledProcessError as e:\n print(f\'Failed to convert HTML to Markdown: {e}\')\n\texcept Exception as e:\n print(f\'An error occurred: {e}\')\ndef change_html_title(path: Optional[str] = None) -> None:\n\t"""\n\tChange the title of all HTML files in the specified directory to match their filenames.\n\tParameters:\n\tpath (str): The directory to search for HTML files. Defaults to the current working directory.\n\tReturns:\n\tNone\n\t"""\n\tif path is None:\n path = os.getcwd()\n\tfiles = glob.glob(os.path.join(path, \'*.html\'))\n\tfor file in files:\n input_file = os.path.join(path, file)\n input_file = input_file.replace(\'\\\\\', \'/\')\n if os.path.exists(input_file) and os.path.isfile(input_file):\n try:\n with open(input_file, \'r\', encoding="utf-8") as f:\n content = f.read()\n reg_string = r\'<title>.*?</title>\'\n content = re.sub(\n reg_string, f\'<title>{os.path.splitext(os.path.basename(file))[0]}</title>\', content)\n with open(input_file, \'w\', encoding="utf-8") as f:\n f.write(content)\n except Exception as e:\n print(f"An error occurred while processing {input_file}: {e}")\n else:\n print(f"File {input_file} does not exist or is not accessible.")\ndef html2md(path=None, output_root="C://Output//", output_folder_name=None):\n\tif path is None:\n path = os.getcwd()\n\ttimestamp = int(time.time())\n\tintput_path = path\n\tinput_floder_name = os.path.basename(intput_path)\n\t# replace_list_regex2=[[r\'Part \\d{2}-Module \\d{2}-Lesson (\\d{2})_(.+)\',r\'0\\1_\\2\'],]\n\tinput_floder_name = re.sub(\n r\'Part \\d{2}-Module \\d{2}-Lesson (\\d{2})_(.+)\', r\'0\\1_\\2\', input_floder_name)\n\t# Part 01-Module 01-Lesson 01_Welcome to the C++ Developer Nanodegree Program\n\tinput_floder_name = input_floder_name.replace(" ", "_")\n\toutput_path = os.path.join(\n output_root, output_folder_name, input_floder_name)\n\tos.makedirs(output_path, exist_ok=True)\n\tlistfiles = os.listdir(intput_path)\n\tmp4_list = [\n filename for filename in listfiles if filename.endswith(".mp4")]\n\t# print(listfiles)\n\tfor i in range(len(listfiles)):\n filename = listfiles[i] # get all file list\n if filename.endswith(".html"):\n input_file = os.path.join(intput_path, filename)\n doc = aw.Document(input_file)\n output_file = os.path.join(\n output_path, filename.replace(".html", ".md"))\n # print(output_path)\n doc.save(output_file)\n\toutput_files_list = os.listdir(output_path)\n\treplace_list_regex = [[r\'!\\[\\]\\(.+\\.001\\.png\\)\', r\'\'],\n [r\'(!\\[\\]|!\\[.+\\])(\\(.+)(\\.png|\\.jpg|\\.gif|\\.jpeg|\\.svg|\\.wbem)\\)\',\n r\'\\1\\2\'+f\'_{timestamp}\'+r\'\\3)\'],\n [r\'\\*\\*Evaluation Only\\. Created with Aspose\\.Words\\. Copyright 2003-2023 Aspose Pty Ltd\\.\\*\\*\', r\'\'],\n [r\'\\*\\*Created with an evaluation copy of Aspose.Words. To discover the full versions of our APIs please visit: https://products.aspose.com/words/\\*\\*\', r\'\'],\n [r\'\\[udacimak v1.4.1\\]\\(https://github.com/udacimak/udacimak#readme\\)\', r\'\'],\n [r\'\\[.+\\]\\(.+\\.html\\)\', r\'\'],\n [r\'\\n{3,}\', r\'\\n\\n\'],\n [r\'`[ ]+`\', r\'\t\'],\n ]\n\tfor i in range(len(output_files_list)):\n filename = output_files_list[i]\n if filename.endswith(".001.png"):\n os.remove(os.path.join(output_path, filename))\n continue\n if filename.endswith(".md"):\n if filename == "index.md":\n os.remove(os.path.join(output_path, filename))\n continue\n with open(os.path.join(output_path, filename), \'r\', encoding=\'UTF-8\') as f:\n content = f.read()\n with open(os.path.join(output_path, filename), \'w\', encoding=\'UTF-8\') as f:\n for replace_list in replace_list_regex:\n content = re.sub(replace_list[0], replace_list[1], content)\n # f.write(content)\n lines = content.splitlines()\n for line in lines:\n if len(line) > 4:\n for file_mp4 in mp4_list:\n word_list = line.split(" ")\n flag = 0\n flag_out = 0\n for word in word_list:\n if file_mp4.find(word) > -1:\n flag = flag+1\n elif file_mp4.find(word) == -1:\n flag_out = flag_out+1\n if flag:\n if flag_out:\n # print(line)\n pass\n else:\n path_mp4 = os.path.join(\n intput_path, file_mp4)\n url_path = urllib.parse.quote(\n os.path.abspath(path_mp4))\n url = "file:///" + \\\n url_path.replace("\\\\", "/")\n line = line+"\\n\\n" + \\\n f"[{file_mp4}]({url})\\n" + \\\n f"![{file_mp4}]({url})"\n f.write(line+"\\n")\n\tmd_note_process(output_path)\n\toutput_files_list = os.listdir(output_path)\n\toutput_path_md = output_path\n\toutput_path_img = os.path.join(\n output_root, "imgs", output_folder_name, input_floder_name)\n\t# Create the output directory and its subdirectory if they don\'t exist\n\ttry:\n os.makedirs(output_path_img, exist_ok=True)\n\texcept FileNotFoundError as e:\n if e.winerror == 206:\n # Shorten the filename and try again\n output_path_img = output_path_img = os.path.join(\n output_path_md, "imgs")\n os.makedirs(output_path_img, exist_ok=True)\n else:\n # If it\'s not WinError 206, raise the original error\n raise e\n\tfor i in range(len(output_files_list)):\n filename = output_files_list[i]\n if filename.endswith(".md"):\n try:\n os.replace(os.path.join(output_path, filename),\n os.path.join(output_path_md, filename))\n except FileExistsError:\n os.remove(os.path.join(output_path_md, filename))\n os.replace(os.path.join(output_path, filename),\n os.path.join(output_path_md, filename))\n if filename.endswith(".png") or filename.endswith(".jpg") or filename.endswith(".jpeg") or filename.endswith(".gif"):\n filename_ext = os.path.splitext(filename)[1]\n filename_without_ext = os.path.splitext(filename)[0]\n filename_img = filename_without_ext+f\'_{timestamp}\'+filename_ext\n try:\n os.replace(os.path.join(output_path, filename),\n os.path.join(output_path_img, filename_img))\n except FileExistsError:\n os.remove(os.path.join(output_path_img, filename_img))\n os.replace(os.path.join(output_path, filename),\n os.path.join(output_path_img, filename_img))\n except FileNotFoundError as e:\n if e.winerror == 3:\n output_path_img = output_path_img = os.path.join(\n output_path_md, "imgs")\n os.makedirs(output_path_img, exist_ok=True)\n os.replace(os.path.join(output_path, filename),\n os.path.join(output_path_img, filename_img))\n else:\n # If it\'s not WinError 206, raise the original error\n raise e\ndef html2md2():\n\timport html2markdown\n\tfiles = [f for f in os.listdir() if os.path.isfile(f)]\n\tfor file in files:\n if file.endswith(".html"):\n with open(file, \'r\', encoding=\'utf-8\') as f:\n html_string = f.read()\n markdown_text = html2markdown.convert(html_string)\n with open(file[:-4] + \'.md\', \'w\', encoding=\'utf-8\') as f:\n f.write(markdown_text)\ndef html2md_tree():\n\tfiles = [f for f in os.listdir() if os.path.isfile(f)]\n\tdirectories = [f for f in os.listdir() if os.path.isdir(f)]\n\toutput_folder_dict = dict()\n\tfor directory in directories:\n search_str = r\'Part (\\d{2})_(.+)\'\n match = re.search(search_str, directory)\n if match:\n output_folder_dict[match.group(\n 1)] = \'0\'+match.group(1)+"_"+match.group(2)\n\tfor directory in directories:\n search_str = r\'Part (\\d{2})-Module \\d{2}-Lesson (\\d{2})_(.+)\'\n match = re.search(search_str, directory)\n if match:\n output_folder1 = "C:\\\\Output\\\\"\n output_folder2 = output_folder_dict[match.group(1)]\n # output_folder=os.path.join(output_folder1,output_folder2)\n input_path = os.path.join(os.getcwd(), directory)\n html2md(input_path, output_folder1, output_folder2)\n'",
"main.py": "'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport argparse\ndef test():\n\tpass\ndef md_note_process(num=0, head_num=1):\n\timport md_helper\n\timport html_processor\n\toperations = {\n 1: md_helper.remove_back_matter_and_copy_code,\n 2: md_helper.process_md_head_to_hn,\n 3: md_helper.retrieve_document_summary_info,\n 4: md_helper.format_ocr_text,\n 5: md_helper.create_file_based_on_content,\n 6: md_helper.format_2_gpt_input,\n 7: md_helper.mermaid_format,\n 8: html_processor.convert_html_to_md,\n 9: html_processor.change_html_title,\n 10: md_helper.create_node_for_mermaid,\n\t}\n\tif num in operations:\n if (num == 2):\n operations[num](head_num)\n else:\n operations[num]()\n\telif num == 0:\n print("Available operations:")\n for num, func in operations.items():\n print(f"{num}: {func.__name__}")\n\telse:\n raise ValueError("Invalid operation number.")\ndef wiki_note_process(num=0):\n\timport wiki_processor\n\toperations = {\n 1: wiki_processor.remove_wiki_edit_link,\n 2: wiki_processor.remove_wiki_equation_svg,\n\t}\n\tif num in operations:\n operations[num]()\n\telif num == 0:\n print("Available operations:")\n for num, func in operations.items():\n print(f"{num}: {func.__name__}")\n\telse:\n raise ValueError("Invalid operation number.")\ndef book_processor(num=0):\n\timport book_processor\n\toperations = {\n 1: book_processor.perform_regex_replacement_on_index_file,\n 2: book_processor.perform_regex_replacement_on_zhi_book_mds_name,\n 3: book_processor.rename_files_base_on_index_markdown,\n 4: book_processor.prepend_filename_as_header_if_chapter_present,\n 5: book_processor.lower_header_level_in_md_files,\n 6: book_processor.remove_md_copy_code,\n 7: book_processor.perform_regex_replacement_on_zhi_mds,\n 8: book_processor.convert_zhi_footnote_to_obsidian,\n 10: book_processor.merge_all_md_files_into_one,\n\t}\n\tif num in operations:\n operations[num]()\n\telif num == 0:\n print("Available operations:")\n for num, func in operations.items():\n print(f"{num}: {func.__name__}")\n\telse:\n raise ValueError(\n "Invalid operation number. Please choose a number between 0 and 4.")\ndef vid_note_process(num=0):\n\timport vid_note_processor\n\toperations = {\n 1: vid_note_processor.initialize_vid_note_file_structure,\n 2: vid_note_processor.generate_vid_note_with_timeline_from_text_summary,\n 3: vid_note_processor.generate_vid_note_with_timeline_from_timestamps,\n 4: vid_note_processor.convert_md_vid_link_to_html,\n 5: vid_note_processor.convert_md_vid_link_to_html_tree,\n 6: vid_note_processor.vtt_format_4_gpt,\n 7: vid_note_processor.mul_initialize_vid_note_file_structure,\n\t}\n\tif num in operations:\n operations[num]()\n\telif num == 0:\n print("Available operations:")\n for num, func in operations.items():\n print(f"{num}: {func.__name__}")\n\telse:\n raise ValueError("Invalid operation number.")\ndef os_file_processor(num=0):\n\timport file_operations_utils\n\timport markmind\n\toperations = {\n 1: file_operations_utils.initialize_notes_files_structure,\n 2: file_operations_utils.add_timestamp_to_filenames,\n 3: file_operations_utils.get_current_timestamp,\n 4: file_operations_utils.open_b_assets_folder,\n 5: file_operations_utils.rename_folders_4_mooc_b,\n 6: file_operations_utils.create_drawio_file_based_on_content,\n 7: file_operations_utils.create_excalidraw_file_based_on_content,\n 8: file_operations_utils.rename_index_folder_files,\n 9: file_operations_utils.rename_bilibili_subs,\n 10: markmind.create_annotator,\n 11: file_operations_utils.rename_files_in_directories,\n\t}\n\tif num in operations:\n operations[num]()\n\telif num == 0:\n print("Available operations:")\n for num, func in operations.items():\n print(f"{num}: {func.__name__}")\n\telse:\n raise ValueError("Invalid operation number.")\ndef get_prompts(num=0):\n\timport prompt_generator\n\toperations = {\n 1: prompts.video_summarization_expert_one,\n 2: prompts.get_prompt_explain_c_cpp,\n 3: prompts.chatbot_prompt_expert,\n 4: prompts.Translate_Chinese_sentence_into_function_name,\n 5: prompts.Expert_Prompt_Creator,\n 6: prompts.dot2mermaid,\n 7: prompts.code_improve,\n 8: prompts.format_code_current_dir,\n\t}\n\tif num in operations:\n operations[num]()\n\telif num == 0:\n print("Available operations:")\n for num, func in operations.items():\n print(f"{num}: {func.__name__}")\n\telse:\n raise ValueError("Invalid operation number.")\ndef main():\n\t# create a parser object\n\tparser = argparse.ArgumentParser()\n\t# add arguments for each function\n\tparser.add_argument(\'-t\', \'--timestamp\', type=str, default=r\'1676880280\',\n help=\'input timestamp to pass to the function\')\n\tparser.add_argument(\'-u\', \'--str_url\', type=str, default=r\'test\',\n help=\'input str_url to pass to the function\')\n\tparser.add_argument(\'-i\', \'--input_int\', type=int, default=r\'0\',\n help=\'input input_int to pass to the function\')\n\tparser.add_argument(\'-hn\', \'--head_num\', type=int, default=r\'1\',\n help=\'input head_num to pass to the function\')\n\tparser.add_argument(\'-mdx\', \'--mdx2md\',\n action=\'store_true\', help=\'call mdx2md\')\n\tparser.add_argument(\'-oaf\', \'--open_b_assets_folder\',\n action=\'store_true\', help=\'call open_b_assets_folder\')\n\tparser.add_argument(\'-md\', \'--md_note_process\',\n action=\'store_true\', help=\'call md_note_process\')\n\tparser.add_argument(\'-wiki\', \'--wiki_note_process\',\n action=\'store_true\', help=\'call wiki_note_process\')\n\tparser.add_argument(\'-vid\', \'--vid_note_process\',\n action=\'store_true\', help=\'call vid_note_process\')\n\tparser.add_argument(\'-test\', \'--test\',\n action=\'store_true\', help=\'call test\')\n\tparser.add_argument(\'-bp\', \'--book_processor\',\n action=\'store_true\', help=\'call book_processor\')\n\tparser.add_argument(\'-ofp\', \'--os_file_processor\',\n action=\'store_true\', help=\'call os_file_processor\')\n\tparser.add_argument(\'-gp\', \'--get_prompts\',\n action=\'store_true\', help=\'call get_prompts\')\n\t# parse the command-line arguments\n\targs = parser.parse_args()\n\t# call the appropriate function based on the arguments\n\tif args.md_note_process:\n md_note_process(args.input_int, args.head_num)\n\telif args.wiki_note_process:\n wiki_note_process(args.input_int)\n\telif args.vid_note_process:\n vid_note_process(args.input_int)\n\telif args.test:\n test(args.input_int)\n\telif args.book_processor:\n book_processor(args.input_int)\n\telif args.os_file_processor:\n os_file_processor(args.input_int)\n\telif args.get_prompts:\n get_prompts(args.input_int)\n\telse:\n print("Invalid argument")\nif __name__ == "__main__":\n\tmain()\n'",
"markmind.py": "'import os\nimport logging\nimport file_operations_utils\nimport time\nimport urllib.parse\nimport re\n# Set up logging\nlogging.basicConfig(level=logging.DEBUG)\n# Constants\nTR_MODE = True\nASSETS_FOLDER_NAME = "assets"\ndef get_annotator_id(file_name):\n\tfile_name_temp = file_name.replace(" ", "_")\n\treturn file_name_temp + "_" + str(int(time.time())), file_name_temp\ndef get_annotate_image_target_path(path):\n\ttry:\n return path.split("KG\\\\")[1]\n\texcept IndexError:\n logging.error("Invalid path format")\n return None\ndef create_annotator(path=None):\n\tif path is None:\n path = os.getcwd()\n\tfiles_annotator = [f for f in os.listdir(\n path) if f.endswith(\'_annotator.md\')]\n\t# get bassets folder path\n\tbig_assets_path = file_operations_utils.get_b_KG_directory_path(path)\n\tif big_assets_path is None:\n raise FileNotFoundError(\n "Could not find assets folder in current folder path")\n\tif TR_MODE:\n logging.debug("big_assets_path: %s", big_assets_path)\n\tfor root, dirs, files in os.walk(big_assets_path):\n for file in files:\n if file.endswith(".pdf"):\n file_name = os.path.splitext(file)[0]\n annotator_id, file_name_temp = get_annotator_id(file_name)\n if TR_MODE:\n logging.debug("annotator_id: %s", annotator_id)\n annotate_target_path = os.path.join(root, file)\n # annotate_target_path = urllib.parse.quote(\n #\t os.path.abspath(annotate_target_path))\n annotate_image_target_full_path = os.path.join(path, "imgs")\n annotate_image_target_path = get_annotate_image_target_path(\n annotate_image_target_full_path)\n content_annotator = f"""\n---\nid: {annotator_id}\nannotate-type: pdf\nannotate-target: file://{annotate_target_path}\nannotate-image-target: {annotate_image_target_path}\n---\n"""\n annotator_file_name = f"{annotator_id}_annotator.md"\n annotator_path = os.path.join(path, annotator_file_name)\n reg_anno = file_name_temp+"_"+r"\\d{10}"+"_annotator.md"\n flag = False\n for file_annotator in files_annotator:\n match = re.search(reg_anno, file_annotator)\n if match:\n flag = True\n if not flag:\n with open(annotator_path, "w", encoding="utf-8") as f:\n f.write(content_annotator)\n# def create_annotator(path=None):\n#\t if path is None:\n# path = os.getcwd()\n#\t TR_MODE = 1\n#\t # IS "\\OneDrive\\KG\\" contained by current folder path? if not, raise error\n#\t # get bassets folder path\n#\t big_assets_path = file_operations_utils.get_b_KG_directory_path(path)\n#\t if TR_MODE:\n# print("big_assets_path:", big_assets_path)\n#\t if big_assets_path is None:\n# raise Exception("Could not find assets folder in current folder path")\n#\t for root, dirs, files in os.walk(big_assets_path):\n# for file in files:\n# if file.endswith(".pdf"):\n# file_name = file.split(".")[0]\n# file_name_temp = file_name.replace(" ", "_")\n# annotator_id = file_name_temp+"_"+str(int(time.time()))\n# if TR_MODE:\n# print("annotator_id:", annotator_id)\n# annotate_target_path = os.path.join(root, file)\n# if TR_MODE:\n# print("annotate_target_path:", annotate_target_path)\n# annotate_image_target_full_path = os.path.join(path, "imgs")\n# if TR_MODE:\n# print("annotate_image_target_full_path:",\n# annotate_image_target_full_path)\n# # annotate_image_target_path= annotate_image_target_full_path after \\OneDrive\\KG\\\n# annotate_image_target_path = annotate_image_target_full_path.split(\n# "KG\\\\")[1]\n# if TR_MODE:\n# print("annotate_image_target_path:",\n# annotate_image_target_path)\n# content_annotator = f"""\n# ---\n# id: {annotator_id}\n# annotate-type: pdf\n# annotate-target: file://{annotate_target_path}\n# annotate-image-target: {annotate_image_target_path}\n# ---\n# """\n# annotator_file_name = annotator_id + "_annotator"+".md"\n# annotator_path = os.path.join(path, annotator_file_name)\n# with open(annotator_path, "w", encoding="utf-8") as f:\n# f.write(content_annotator)\n'",
"md_helper.py": "'from typing import Optional\nimport glob\nimport pyperclip\nimport os\nimport re\nimport subprocess\nimport time\nimport file_operations_utils\ndef text_replace(root_dir: str, replace_list: list):\n\tassets_root_path, assets_root_dir = get_assets_root_path()\n\toutput_dir = create_output_directory(assets_root_path)\n\tfor filename_with_ext in os.listdir(root_dir):\n if filename_with_ext.endswith(\'.md\'):\n src_path = os.path.join(root_dir, filename_with_ext)\n dest_path = os.path.join(output_dir, filename_with_ext)\n with open(src_path, \'r\', encoding=\'UTF-8\') as f_src, open(dest_path, \'w\', encoding=\'UTF-8\') as f_dest:\n for line in f_src:\n for replace_item in replace_list:\n line = line.replace(replace_item[0], replace_item[1])\n f_dest.write(line)\ndef mdx2md(timestamp: int = 1676880280):\n\tassets_root_path, assets_root_dir = get_assets_root_path()\n\toutput_dir = create_output_directory(assets_root_path)\n\tcwd = os.getcwd()\n\t# text_replace_list_mdx2md3 = [\n\t# ]\n\t# replace_list = text_replace_list_mdx2md3\n\t# <Figure\n\tfor filename_with_ext in os.listdir(cwd):\n if filename_with_ext.endswith(\'.md\'):\n src_path = os.path.join(cwd, filename_with_ext)\n dest_path = os.path.join(output_dir, filename_with_ext)\n # with open(src_path, \'r\', encoding=\'UTF-8\') as f_src, open(dest_path, \'w\', encoding=\'UTF-8\') as f_dest:\n #\t for line in f_src:\n # for replace_item in replace_list:\n # line = line.replace(replace_item[0], replace_item[1])\n # f_dest.write(line)\n with open(src_path, \'r\', encoding=\'UTF-8\') as f_src:\n content = f_src.read()\n # Define the regex pattern and replacement string\n replace_list_regex = [\n [r"<PiCreature\\n{0,}\\s{0,}(.+)\\n{0,}\\s{0,}(.+)\\n{0,}\\s{0,}/>", r"\\1\\n\\2\\n"],\n # [r"show=\\"video\\"\\n", r""],\n # [r"<!--", r""],\n # [r"-->", r""],\n [r"<Question", r"---"],\n [r"<FreeResponse>", r"---"],\n [r"</FreeResponse>", r"---"],\n [r"</Question>", r"---"],\n [r\'\'\'<Figure[\\n ]{1,}image="(.+)(\\.svg|\\.png|\\.jpg)"[\\w ._="\'\\n_%]{0,}/>\'\'\',\n r\'![](\\1_\'+str(timestamp)+r\'\\2)\'],\n [r\'<Accordion\\stitle=".+">\\n\', r\'\'],\n [r\'</Accordion>\\n\', r\'\'],\n # [r\'emotion="\\w+"[ \\t]+\\n\', r\'\'],\n # [r\'flip=\\{(true|false)\\}\\n\', r\'\'],\n # [r\'(?s)<Question .+?</Question>\', r\'tttttttttttttttttttt\'],\n [r\'answer=\\{(\\d)\\}[ \\n\\t]{0,}>\',\n r\'\\n<details><summary>answer</summary><p>Choice= \\1</p></details>\\n\\n- **Explanation**\'],\n # [r\'\'\'<Question[\\n \\t]{0,}question="(.+)"[\\n \\t]{0,}choice1="(.+)"[\\n \\t]{0,}choice2="(.+)"[\\n \\t]{0,}choice3="(.+)"[\\n \\t]{0,}choice4="(.+)"[\\n \\t]answer=\\{(\\d)\\}[\\n \\t]{0,}>\'\'\',r\'- **Question**\\n\\t\\1\']\n [r\'[ \\t]{0,}question="(.+)"\',\n r\'- **Question**\\n\\t\\1\'],\n [r\'[ \\t]{0,}choice1="(.+)"\',\n r\'\t- **Choice 1=** \\1\'],\n [r\'[ \\t]{0,}choice2="(.+)"\',\n r\'\t- **Choice 2=** \\1\'],\n [r\'[ \\t]{0,}choice3="(.+)"\', r\'\t- **Choice 3=** \\1\'],\n [r\'[ \\t]{0,}choice4="(.+)"\', r\'\t- **Choice 4=** \\1\'],\n # [r\'video=".+\\.mp4"\', r\'\'],\n # [r\'show="video"\', r\'\'],\n [r\'([ \\t]{0,}\\n){3,}\', r\'\\1\\1\'],\n # [\'/>\', r\'\'],\n ]\n for i in range(len(replace_list_regex)):\n pattern = replace_list_regex[i][0]\n replacement = replace_list_regex[i][1]\n # Perform the regex replacement\n content = re.sub(pattern, replacement, content)\n # Write the modified content to the output Markdown file with UTF-8 encoding\n with open(dest_path, \'w\', encoding=\'utf-8\') as file:\n file.write(content)\ndef remove_back_matter_and_copy_code(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_Back_matter_template = [r"---\\n\\n- created:.+\\n- source: .+", r""]\n\treg_string_list.extend([reg_Back_matter_template])\n\treg_string_copy_code = [r"```\\n(.+)Copy code", r"```\\1\\n"]\n\treg_string_list.extend([reg_string_copy_code])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, directory_path, files_md)\ndef Is_head_line(line):\n\tpattern = r"^(#{1,}) (.+|)"\n\tmatch = re.search(pattern, line)\n\tif match:\n return True\n\telse:\n return False\ndef get_highest_head_level(content):\n\tlines = content.split(\'\\n\')\n\tlowest_level = float(\'inf\')\n\tpattern = re.compile(r"^(#{1,}) ")\n\tfor line in lines:\n match = pattern.match(line)\n if match:\n level = len(match.group(1))\n if level < lowest_level:\n lowest_level = level\n\treturn lowest_level if lowest_level != float(\'inf\') else None\ndef downgrade_heads(content, downgrade_level):\n\tlines = content.split(\'\\n\')\n\tnew_lines = []\n\tfor line in lines:\n if Is_head_line(line):\n head_level = 0\n for char in line:\n if char == \'#\':\n head_level += 1\n else:\n break\n if head_level > 0:\n new_head_level = head_level + downgrade_level\n if new_head_level > 6:\n new_head_level = 6\n new_line = \'#\' * new_head_level + line[head_level:]\n new_lines.append(new_line)\n else:\n new_lines.append(line)\n\treturn \'\\n\'.join(new_lines)\ndef upgrade_heads(content, upgrade_level):\n\tlines = content.split(\'\\n\')\n\tnew_lines = []\n\tfor line in lines:\n head_level = 0\n for char in line:\n if char == \'#\':\n head_level += 1\n else:\n break\n if head_level > 0:\n new_head_level = head_level - upgrade_level\n if new_head_level < 1:\n new_head_level = 1\n new_line = \'#\' * new_head_level + line[head_level:]\n new_lines.append(new_line)\n else:\n new_lines.append(line)\n\treturn \'\\n\'.join(new_lines)\ndef degrade_markdown_by_head_number(head_number):\n\tcontent = pyperclip.paste()\n\tTR_MODE = 1\n\thighest_head_level = get_highest_head_level(content)\n\t# highest_head_level=3\n\tif TR_MODE:\n print("highest_head_level: ", highest_head_level)\n print("head_number: ", head_number)\n\tif highest_head_level < head_number:\n content = downgrade_heads(\n content, head_number-highest_head_level)\n pyperclip.copy(content)\ndef upgrade_markdown_by_head_number(head_number):\n\tcontent = pyperclip.paste()\n\tTR_MODE = 1\n\thighest_head_level = get_highest_head_level(content)\n\tif TR_MODE:\n print("highest_head_level: ", highest_head_level)\n print("head_number: ", head_number)\n\tif highest_head_level > head_number:\n content = upgrade_heads(\n content, highest_head_level-head_number)\n pyperclip.copy(content)\ndef process_md_head_to_hn(head_number, content=None):\n\tif content is None:\n content = pyperclip.paste()\n\tTR_MODE = 1\n\thighest_head_level = get_highest_head_level(content)\n\tif TR_MODE:\n print("highest_head_level: ", highest_head_level)\n print("head_number: ", head_number)\n\tif highest_head_level > head_number:\n content = upgrade_heads(\n content, highest_head_level-head_number)\n pyperclip.copy(content)\n\telif highest_head_level < head_number:\n content = downgrade_heads(\n content, head_number-highest_head_level)\n pyperclip.copy(content)\ndef format_2_gpt_input(content=None):\n\t"""\n\tThis function formats the input content by replacing one or more newline characters with a single newline character.\n\tIf no content is provided, it fetches the content from the clipboard, formats it, and then copies the formatted content back to the clipboard.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t"""\n\tif content is None:\n content = pyperclip.paste()\n\t# content = repr(content)\n\tprint(repr(content))\n\tcontent = content.replace("\\r\\n", "\\n")\n\tcontent = content.replace("\n", "\\n")\n\treg_repalce_list = []\n\treg_repalce_list.append([r"\\n{2,}", r"\\n"])\n\treg_repalce_list.append([r"[ ]{2,}", " "])\n\tfor reg_replace in reg_repalce_list:\n content = re.sub(reg_replace[0], reg_replace[1], content)\n\t# Printing the formatted content\n\tprint(repr(content))\n\t# Copying the formatted content back to the clipboard\n\tpyperclip.copy(repr(content))\ndef mermaid_format(content=None):\n\tif content is None:\n content = pyperclip.paste()\n\t# content = repr(content)\n\tprint(repr(content))\n\t# content = content.replace(" \\w{1,3}", "\\n")\n\tnum_str = r"22"\n\treg_repalce_list = []\n\treg_repalce_list.append(\n [r" (\\w{1,3})( |\\n|\\(|\\{|\\[)", r" \\1_"+num_str+r"\\2"])\n\t# reg_repalce_list.append([r" \\w{1,3}\\n", r" \\1\\n"+num_str])\n\tfor reg_replace in reg_repalce_list:\n content = re.sub(reg_replace[0], reg_replace[1], content)\n\tprint(repr(content))\n\t# Copying the formatted content back to the clipboard\n\tpyperclip.copy(content)\ndef retrieve_document_summary_info(content=None):\n\tif content is None:\n content = pyperclip.paste()\n\treg_string1 = [\n r\'(#{1,6}) (.+)\\n\\n<video src="file://.+" controls></video>\\n\\n- .+\', r"\\1# \\2"]\n\tmatch = re.search(reg_string1[0], content)\n\tif match:\n content = re.sub(reg_string1[0], reg_string1[1], content)\n\treg_string2 = [r\'\\n{3,}\', r\'\\n\\n\']\n\tcontent = re.sub(reg_string2[0], reg_string2[1], content)\n\tpyperclip.copy(content)\ndef format_ocr_text(content=None):\n\tTR_mode = False\n\tif content is None:\n content = pyperclip.paste()\n\tif TR_mode:\n print(":", repr(content))\n\tcontent = content.replace(\'\\n\', \' \')\n\tcontent = content.replace(\'\\r\', \' \')\n\tif TR_mode:\n print(repr(content))\n\twhile \' \' in content:\n content = content.replace(\' \', \' \')\n\tif TR_mode:\n print(repr(content))\n\tpyperclip.copy(content)\ndef create_file_based_on_content(content=None, path=None):\n\t"""\n\tThis function creates a file based on the content provided.\n\tParameters:\n\tcontent (str): The content to be written to the file. If not provided, it will use the content from the clipboard.\n\tpath (str): The path where the file will be created. If not provided, it will use the current working directory.\n\tRaises:\n\tValueError: If the length of the content is less than 1 or greater than 100.\n\tTypeError: If the content contains more than 2 newline characters.\n\t"""\n\tif content is None:\n content = pyperclip.paste()\n\tif path is None:\n path = os.getcwd()\n\tif len(content) > 100:\n raise ValueError("Content length exceeds 100 characters")\n\tif len(content) < 1:\n raise ValueError("Content length is less than 1 character")\n\tif content.count("\\n") > 2:\n raise TypeError("Content contains more than 2 newline characters")\n\tcontent = content.replace(\'\\n\', \' \')\n\tcontent = content.replace(\'\\r\', \' \')\n\treg = [r"\\s{2,}", r\' \']\n\tcontent = re.sub(reg[0], reg[1], content)\n\ttimestamp = str(int(time.time()))\n\tnew_name = content.strip() + "_" + timestamp + ".md"\n\twith open(os.path.join(path, new_name), "w", encoding="utf-8") as file:\n file.write("")\ndef create_node_for_mermaid(num=30):\n\tcontent = ""\n\tfor i in range(num):\n content += f"Node{i+1}[\\"\\"]\\n"\n\tpyperclip.copy(content)\ndef main():\n\tcontent = pyperclip.paste()\n\thighest_level = get_highest_head_level(content)\n\tprint(f"The highest head level is {highest_level}")\n\tdowngrade_level = int(\n input("Enter the number by which you want to downgrade the headers: "))\n\tnew_content = downgrade_heads(content, downgrade_level)\n\tpyperclip.copy(new_content)\n\tprint("Content updated in clipboard.")\nif __name__ == "__main__":\n\tmain()\n'",
"prompts.py": "'\nimport pyperclip\nimport re\nimport os\ndef get_prompt_explain_c_cpp(content=None):\n\tprompt_string1 = \'\'\'## Exploring Key C/C++ Concepts: A Guide to Understanding and Resources\nPlease provide a detailed explanation for the following C/C++ concepts that I\'ll specify. Can you also recommend some comprehensive books or resources to aid my understanding of these concepts\nconcepts is :\n```\n\'\'\'\n\tprompt_string2 = \'\'\'```\n\t\'\'\'\n\tcombine_strings_with_clipboard(\n prompt_string1, prompt_string2, content)\ndef chatbot_prompt_expert(content=None):\n\tprompt_string1 = \'\'\'## chatbot prompt expert\nAs an AI chatbot prompt expert, could you analyze and provide suggestions to improve the following prompt:\n\'[\n\'\'\'\n\tprompt_string2 = \'\'\'\n]\'\nPlease provide a final revised version.\n\'\'\'\n\tcombine_strings_with_clipboard(\n prompt_string1, prompt_string2, content)\ndef Translate_Chinese_sentence_into_function_name(content=None):\n\tprompt_string1 = \'\'\'\n\t## Translate Chinese sentence into function name\nTranslate the following Chinese sentence into English and create a snake_case function name based on the translated sentence:\n[\n\'\'\'\n\tprompt_string2 = \'\'\'\n]. Your function name should reflect the primary task described in the sentence. Please also provide a brief description of what the function will do\n\'\'\'\n\tcombine_strings_with_clipboard(\n prompt_string1, prompt_string2, content)\ndef combine_strings_with_clipboard(prompt_string1, prompt_string2, content=None):\n\tif content is None:\n content = pyperclip.paste()\n\tfinal_string = prompt_string1 + content + "\\n" + prompt_string2\n\tpyperclip.copy(final_string)\n\t# print(final_string)\n\treturn final_string\ndef Expert_Prompt_Creator():\n\tfinal_string = """\nI want you to become my Expert Prompt Creator. Your goal is to help me craft the best possible prompt for my needs. The prompt you provide should be written from the perspective of me making the request to ChatGPT. Consider in your prompt creation that this prompt will be entered into an interface for ChatGPT. The process is as follows:\n1. You will generate the following sections:\nPrompt:\n{provide the best possible prompt according to my request}\nCritique:\n{provide a concise paragraph on how to improve the prompt. Be very critical in your response}\nQuestions:\n{ask any questions pertaining to what additional information is needed from me to improve the prompt (max of 3). If the prompt needs more clarification or details in certain areas, ask questions to get more information to include in the prompt}\n2. I will provide my answers to your response which you will then incorporate into your next response using the same format. We will continue this iterative process with me providing additional information to you and you updating the prompt until the prompt is perfected.\nRemember, the prompt we are creating should be written from the perspective of me making a request to ChatGPT. Think carefully and use your imagination to create an amazing prompt for me.\nYou\'re first response should only be a greeting to the user and to ask what the prompt should be about.\n"""\n\tpyperclip.copy(final_string)\n\treturn final_string\ndef draw_flowchart():\n\t"""{\n "instruction": "ChatGPT, could you assist me in designing two flowcharts based on the provided code?",\n "codePlaceholder": "[YOUR CODE HERE]",\n "description": "[YOUR CODE DESCRIPTION HERE]",\n "syntax": "Mermaid",\n "flowchartTypes": [\n\t"high-level overview",\n\t"detailed, including minor processes"\n ],\n "tone": "formal documentation"\n}\n"""\ndef dot2mermaid():\n\tprompt_string1 = """{ "instruction": "Dear ChatGPT, I need your assistance in converting the following Graphviz code into Mermaid syntax. I\'m trying to create a more visually appealing diagram while retaining the structure and relationships depicted in the original Graphviz diagram. Your expertise in this transformation would be highly valued. Here\'s the Graphviz code:",\n "graphviz_code": "["""\n\tprompt_string2 = """ ]",\n}"""\n\tcontent = format_code_2_gpt_input(copy_to_clipboard=False)\n\tfinal_string = prompt_string1 + content + prompt_string2\n\tpyperclip.copy(final_string)\ndef format_code_2_gpt_input(content=None, copy_to_clipboard=True):\n\t"""\n\tFormats the input content by replacing multiple newline characters with a single newline character and\n\tmultiple spaces with a single space. If no content is provided, it fetches the content from the clipboard,\n\tformats it, and then copies the formatted content back to the clipboard if copy_to_clipboard is True.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t:param copy_to_clipboard: A flag indicating whether to copy the formatted content back to the clipboard.\n\t:return: The formatted content as a string.\n\t"""\n\tif content is None:\n try:\n content = pyperclip.paste()\n except pyperclip.PyperclipException:\n print("Unable to access the clipboard.")\n return None\n\tcontent = content.replace("\\r\\n", "\\n").replace("\\\\\n", "\\n")\n\treplacements = [\n (r"\\n{2,}", "\\n"),\n (r"[ ]{2,}", " ")\n\t]\n\tfor pattern, replacement in replacements:\n content = re.sub(pattern, replacement, content)\n\tif copy_to_clipboard:\n try:\n pyperclip.copy(repr(content))\n except pyperclip.PyperclipException:\n print("Unable to copy content to the clipboard.")\n\treturn repr(content)\ndef format_python_2_gpt_input(content=None, copy_to_clipboard=True):\n\t"""\n\tFormats the input content by replacing multiple newline characters with a single newline character and\n\tmultiple spaces with a single space. If no content is provided, it fetches the content from the clipboard,\n\tformats it, and then copies the formatted content back to the clipboard if copy_to_clipboard is True.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t:param copy_to_clipboard: A flag indicating whether to copy the formatted content back to the clipboard.\n\t:return: The formatted content as a string.\n\t"""\n\tif content is None:\n try:\n content = pyperclip.paste()\n except pyperclip.PyperclipException:\n print("Unable to access the clipboard.")\n return None\n\tcontent = content.replace("\\r\\n", "\\n").replace("\\\\\n", "\\n")\n\treplacements = [\n (r"\\n{2,}", "\\n"),\n (r"[ ]{4}", "\\t")\n\t]\n\tfor pattern, replacement in replacements:\n content = re.sub(pattern, replacement, content)\n\tif copy_to_clipboard:\n try:\n pyperclip.copy(repr(content))\n except pyperclip.PyperclipException:\n print("Unable to copy content to the clipboard.")\n\treturn repr(content)\ndef format_c_cpp_2_gpt_input(content=None, copy_to_clipboard=True):\n\t"""\n\tFormats the input content by replacing multiple newline characters with a single newline character and\n\tmultiple spaces with a single space. If no content is provided, it fetches the content from the clipboard,\n\tformats it, and then copies the formatted content back to the clipboard if copy_to_clipboard is True.\n\t:param content: The input content to format. If None, the content will be taken from the clipboard.\n\t:param copy_to_clipboard: A flag indicating whether to copy the formatted content back to the clipboard.\n\t:return: The formatted content as a string.\n\t"""\n\tif content is None:\n try:\n content = pyperclip.paste()\n except pyperclip.PyperclipException:\n print("Unable to access the clipboard.")\n return None\n\tcontent = content.replace("\\r\\n", "\\n").replace("\\\\\n", "\\n")\n\treplacements = [\n (r"\\n{2,}", "\\n"),\n (r"[ ]{2,}", " ")\n\t]\n\tfor pattern, replacement in replacements:\n content = re.sub(pattern, replacement, content)\n\tif copy_to_clipboard:\n try:\n pyperclip.copy(repr(content))\n except pyperclip.PyperclipException:\n print("Unable to copy content to the clipboard.")\n\treturn repr(content)\ndef code_improve():\n\tprompt_string1 = """{\n"language": "Python",\n"application_type": "desktop",\n"code_snippet": "[ """\n\tprompt_string2 = """ ]",\n"request": "I am developing a desktop application in Python and I need insights on how to improve my code. Here\'s a snippet of my code. Can you provide feedback on its efficiency, readability, and suggestions for enhancement?"\n}"""\n\tcontent = format_code_2_gpt_input(copy_to_clipboard=False)\n\tfinal_string = prompt_string1 + content + prompt_string2\n\tpyperclip.copy(final_string)\ndef video_summarization_expert_one(content=None):\n\tprompt_string1 = \'\'\'## video summarization expert one\nHello ChatGPT,\nI have an extensive video subtitle data that needs your expertise. My aim is to break down this data into as many thematic segments as possible, where each segment represents a unique topic or theme discussed in the video.\nFor each segment, I expect you to craft a detailed summary that includes:\n- Title: A descriptive title that encapsulates the main point of the segment.\n- Start Timestamp: The starting time of the segment within the video.\n- Summary: A brief and short summary text showing the main points or topics discussed in that segment.\nHere is the format I expect for each segment:\nTitle:\nStart Timestamp:\nSummary:\nKindly start analyzing the following subtitle data:\n[\n\'\'\'\n\tprompt_string2 = \'\'\'\n]\nI appreciate your assistance. Thank you!\n\'\'\'\n\tcontent = format_code_2_gpt_input(copy_to_clipboard=False)\n\tfinal_string = prompt_string1 + content + prompt_string2\n\tpyperclip.copy(final_string)\ndef read_file_skip_non_utf8_parts(file_path):\n\timport logging\n\t"""\n\tReads a file in binary mode and decodes it to UTF-8.\n\tSkips the parts of the file that are not UTF-8 encoded.\n\t:param file_path: Path to the file.\n\t:return: Decoded file content with non-UTF-8 parts skipped.\n\t"""\n\ttry:\n with open(file_path, \'rb\') as f:\n byte_content = f.read()\n return byte_content.decode(\'utf-8\', errors=\'ignore\')\n\texcept Exception as e:\n logging.error(f"Error reading file {file_path}: {e}")\n\treturn None\ndef format_code_current_dir(current_dir=None):\n\tif current_dir is None:\n current_dir = os.getcwd()\n\toutput_dir = os.path.join(current_dir, \'gpt_ready_code\')\n\tos.makedirs(output_dir, exist_ok=True)\n\t# with open(os.path.join(output_dir, \'.gitignore\'), \'w\', encoding="utf-8") as f:\n\t#\t f.write("*.md\\n")\n\tfor root, dirs, files in os.walk(current_dir):\n for file in files:\n if file.endswith(\'.c\') or file.endswith(\'.cpp\') or file.endswith(\'.h\') or file.endswith(\'.hpp\') or file.endswith(\'.py\'):\n # Get file name\n file_name = os.path.basename(file)\n # Get directory name\n dir_name = os.path.basename(root)\n # print(dir_name)\n if dir_name.startswith(\'.\'):\n continue\n origin_dir = os.path.join(root, file)\n # read file skip none utf-8\n content = read_file_skip_non_utf8_parts(origin_dir)\n content = format_python_2_gpt_input(\n content=content, copy_to_clipboard=False) if file.endswith(\'.py\') else format_c_cpp_2_gpt_input(content, copy_to_clipboard=False)\n floder_sep = os.path.join(output_dir, dir_name)\n os.makedirs(floder_sep, exist_ok=True)\n file_dir = os.path.join(floder_sep, f\'{file_name}.md\')\n total_dir = os.path.join(\n output_dir, f\'{dir_name}.md\')\n with open(file_dir, \'w\', encoding="utf-8") as f1:\n f1.write(f"\\"{file_name}\\": \\"{content}\\",\\n")\n if os.path.exists(total_dir):\n with open(total_dir, \'r\', encoding="utf-8") as f1:\n content1 = f1.read()\n else:\n content1 = \'\'\n with open(total_dir, \'w\', encoding="utf-8") as f1:\n content = f1.write(\n content1+f"\\"{file_name}\\": \\"{content}\\",\\n")\n\treturn current_dir\n'",
"UI.py": "'import sys\nfrom PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QTabWidget, QPushButton, QTextEdit\nimport prompt_generator\nimport pyperclip\n# Your functions here (e.g., get_prompt_explain_c_cpp, video_summarization_expert_one, Translate_Chinese_sentence_into_function_name)\nclass MyApp(QWidget):\n\tdef __init__(self):\n super().__init__()\n self.initUI()\n\tdef initUI(self):\n layout = QVBoxLayout()\n tab_widget = QTabWidget()\n prompts_tab = QWidget()\n prompts_layout = QVBoxLayout()\n self.prompts_text_edit = QTextEdit()\n prompts_layout.addWidget(self.prompts_text_edit)\n btn1 = QPushButton(\'video_summarization_expert_one\')\n btn1.clicked.connect(lambda: prompts.video_summarization_expert_one(\n self.prompts_text_edit.toPlainText()))\n prompts_layout.addWidget(btn1)\n btn2 = QPushButton(\'Get Prompt Explain C/C++\')\n btn2.clicked.connect(lambda: prompts.get_prompt_explain_c_cpp(\n self.prompts_text_edit.toPlainText()))\n prompts_layout.addWidget(btn2)\n btn3 = QPushButton(\'chatbot_prompt_expert\')\n btn3.clicked.connect(lambda: prompts.chatbot_prompt_expert(\n self.prompts_text_edit.toPlainText()))\n prompts_layout.addWidget(btn3)\n btn4 = QPushButton(\'Translate Chinese Sentence into Function Name\')\n btn4.clicked.connect(lambda: prompts.Translate_Chinese_sentence_into_function_name(\n self.prompts_text_edit.toPlainText()))\n prompts_layout.addWidget(btn4)\n btn5 = QPushButton(\'Expert_Prompt_Creator\')\n btn5.clicked.connect(lambda: prompts.Expert_Prompt_Creator(\n self.prompts_text_edit.toPlainText()))\n prompts_layout.addWidget(btn5)\n prompts_tab.setLayout(prompts_layout)\n tab_widget.addTab(prompts_tab, "Prompts")\n layout.addWidget(tab_widget)\n self.setLayout(layout)\n self.setWindowTitle(\'Expert Prompt Creator\')\n self.show()\nif __name__ == \'__main__\':\n\tapp = QApplication(sys.argv)\n\tex = MyApp()\n\tsys.exit(app.exec_())\n'",
"vid_note_processor.py": "'import os\nimport re\nimport file_operations_utils\nimport pyperclip\nimport flags_utils\nimport shutil\nimport prompt_generator\nimport urllib.parse\ndef srt_format_4_gpt(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_srt = [f for f in os.listdir(directory_path) if f.endswith(\'.srt\')]\n\tfor file in files_srt:\n with open(os.path.join(directory_path, file), "r", encoding="utf-8") as f1:\n lines = f1.readlines()\n content = \'\'\n for line in lines:\n line_temp = line.strip()\n content += line_temp\n reg_srt_2_gpt1 = [\n r\'\\d{1,3}(\\d{2}:\\d{2}:\\d{2}),\\d{3} --> \\d{1,2}:\\d{2}:\\d{2},\\d{3}\', r\'\\n(\\1) \']\n reg_srt_2_gpt = reg_srt_2_gpt1\n content = re.sub(reg_srt_2_gpt[0], reg_srt_2_gpt[1], content)\n with open(os.path.join(directory_path, file), "w", encoding="utf-8") as f1:\n f1.write(content)\n\tif files_srt != []:\n print(files_srt)\n prompts.video_summarization_expert_one(content)\ndef vtt_format_4_gpt(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_srt = [f for f in os.listdir(directory_path) if f.endswith(\'.vtt\')]\n\tfor file in files_srt:\n with open(os.path.join(directory_path, file), "r", encoding="utf-8") as f1:\n lines = f1.readlines()\n content = \'\'\n for line in lines:\n content += line.strip()+" "\n reg_vtt_2_gpt_list = []\n reg_vtt_2_gpt_list.append([\n r\'(\\d{2}:\\d{2}:\\d{2}).\\d{3} --> \\d{1,2}:\\d{2}:\\d{2}.\\d{3}\', r\'\\n(\\1)\'])\n reg_vtt_2_gpt_list.append([\n r\'WEBVTT Kind:.+ Language:.+\\n\', r\'\'])\n reg_vtt_2_gpt_list.append([r\'&nbsp;\', r\' \'])\n reg_vtt_2_gpt_list.append([r\' line:\\d{1,3}%\', r\' \'])\n reg_vtt_2_gpt_list.append([r\'[ ]{1,}\', r\' \'])\n for reg_vtt_2_gpt in reg_vtt_2_gpt_list:\n content = re.sub(reg_vtt_2_gpt[0], reg_vtt_2_gpt[1], content)\n with open(os.path.join(directory_path, file), "w", encoding="utf-8") as f1:\n f1.write(content)\n\tif files_srt != []:\n print(files_srt)\n prompts.video_summarization_expert_one(content)\ndef subtitles_format_for_gpt_input(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tvtt_format_4_gpt(directory_path)\n\tsrt_format_4_gpt(directory_path)\ndef get_list_key_word_vid(current_dir=None):\n\tif current_dir is None:\n current_dir = os.getcwd()\n\tlist_key_word_vid = []\n\tfiles_mp4 = [file for file in os.listdir(\n current_dir) if file.endswith(".mp4")]\n\tfiles_mp4.sort()\n\tfor file in files_mp4:\n reg = r".*? - Lecture \\d{1,2} - (.*?)-.*?\\.mp4"\n match = re.search(reg, file)\n if match:\n list_key_word_vid.append(match[1])\n else:\n print("not matching")\n\treturn list_key_word_vid\ndef mul_initialize_vid_note_file_structure(current_dir=None, list_content=None):\n\tflags = flags_utils.GlobalFlags()\n\tflags.set_flag(\'TR_MODE\', True)\n\tTR_MODE = flags.get_flag(\'TR_MODE\')\n\tif current_dir is None:\n current_dir = os.getcwd()\n\tTopic, sub_topic1 = file_operations_utils.get_Topic_in_kg(TR_MODE)\n\tif Topic is None:\n raise ValueError("Topic is None")\n\tbvids_origin_topic_path = file_operations_utils.get_bvids_origin_topic_path(\n Topic, TR_MODE)\n\tif list_content is None:\n list_content = get_list_key_word_vid(\n current_dir=bvids_origin_topic_path)\n\tfor content in list_content:\n initialize_vid_note_file_structure(current_dir, content)\ndef initialize_vid_note_file_structure(current_dir=None, content=None):\n\tflags = flags_utils.GlobalFlags()\n\tflags.set_flag(\'TR_MODE\', True)\n\tTR_MODE = flags.get_flag(\'TR_MODE\')\n\t# Get content from clipboard\n\tif content is None:\n content = pyperclip.paste()\n\tcontent = content.strip()\n\treg_content_to_current_topic = [r"\\d{1,3}_(.+)\\.mp4", r"\\1"]\n\tmatch = re.search(reg_content_to_current_topic[0], content)\n\tif match:\n current_topic = re.sub(\n reg_content_to_current_topic[0], reg_content_to_current_topic[1], content)\n\telse:\n reg_content_to_current_topic = [r"(.+)\\.mp4", r"\\1"]\n match = re.search(reg_content_to_current_topic[0], content)\n if match:\n current_topic = re.sub(\n reg_content_to_current_topic[0], reg_content_to_current_topic[1], content)\n else:\n current_topic = content\n\tif TR_MODE == 1:\n print("current_topic: ", current_topic)\n\tif current_dir is None:\n current_dir = os.getcwd()\n\t# Check for existing serial numbers (first three digits of filenames)\n\tserial_numbers = [f[:3] for f in os.listdir(current_dir) if os.path.isfile(\n os.path.join(current_dir, f)) and f[:3].isdigit()]\n\t# # Generate filename\n\t# if serial_numbers:\n\t#\t max_serial_number = max(serial_numbers)\n\t#\t note_file = str(int(max_serial_number) + 1).zfill(3) + \\\n\t# "_"+current_topic+".md"\n\t# else:\n\t#\t note_file = "001"+"_"+current_topic+".md"\n\tmax_serial_number = max(serial_numbers) if serial_numbers else "000"\n\tnote_file = f"{int(max_serial_number) + 1:03d}_{current_topic}.md"\n\tif TR_MODE == 1:\n print("note_file: ", note_file)\n\t# Add the filename to the current_dir\n\tnote_file_path = os.path.join(current_dir, note_file)\n\tif not os.path.exists(note_file_path):\n with open(note_file_path, \'w\') as f:\n f.write("")\n\tsub_topic1_to_sub_topicn_folder_list = [note_file[:-3]]\n\t# sub_topic1_to_sub_topicn_folder_list.append(os.path.basename(current_dir))\n\tnote_assets_dir_path = file_operations_utils.get_note_assets_dir_path(\n sub_topic1_to_sub_topicn_folder_list, current_dir)\n\tif TR_MODE == 1:\n print("note_assets_dir_path: ", note_assets_dir_path)\n\tfile_operations_utils.create_file_subtitle_summary_gpt_md(\n note_assets_dir_path)\n\tTopic, sub_topic1 = file_operations_utils.get_Topic_in_kg(TR_MODE)\n\tif Topic is None:\n raise ValueError("Topic is None")\n\tbvids_origin_topic_path = file_operations_utils.get_bvids_origin_topic_path(\n Topic, TR_MODE)\n\tflag_search_sub_topic1 = flags_utils.get_flag_search_sub_topic1_in_bvids_origin_topic_path()\n\tif flag_search_sub_topic1:\n dirs = [d for d in os.listdir(bvids_origin_topic_path) if os.path.isdir(\n os.path.join(bvids_origin_topic_path, d))]\n if TR_MODE:\n print("dirs:", dirs)\n reg_string = r"\\d{1,3}_"+sub_topic1\n flag_find_sub_topic = False\n for dir in dirs:\n if re.match(reg_string, dir):\n bvids_origin_topic_path = os.path.join(\n bvids_origin_topic_path, dir)\n flag_find_sub_topic = True\n break\n if not flag_find_sub_topic:\n raise Exception("sub topic not found")\n\t# if match copy to des\n\tfiles_subtitle = [f for f in os.listdir(\n bvids_origin_topic_path) if f.endswith(\'.srt\') or f.endswith(\'.vtt\')]\n\tif TR_MODE:\n print("files_subtitle:", files_subtitle)\n\treg_sub_string_current_topic = [\n r\'(\\d{1,3}_|)\'+current_topic+r\'(\\.en|\\.eng|\\.zh|\\.cn|\\.zho|\\.chi|\\.zh-Hans|\\.zh-Hant|)(\\.srt|\\.vtt)\', r\'\']\n\tflag_one_by_one = flags_utils.get_flag_one_by_one()\n\tfor file_srt in files_subtitle:\n match = re.match(reg_sub_string_current_topic[0], file_srt)\n flag_find_match = False\n if match:\n flag_find_match = True\n if ((match.group(2) == ".en") or (match.group(2) == "")):\n # copy srt to note_assets_dir_path\n new_srt_name = note_file[:-3]+match.group(2)+match.group(3)\n src_srt_file_path = os.path.join(\n bvids_origin_topic_path, file_srt)\n des_srt_file_path = os.path.join(\n note_assets_dir_path, new_srt_name)\n shutil.copy(src_srt_file_path, des_srt_file_path)\n\tif not flag_find_match:\n if flag_one_by_one:\n file_srt = files_subtitle[0]\n src_srt_file_path = os.path.join(\n bvids_origin_topic_path, file_srt)\n des_srt_file_path = os.path.join(\n note_assets_dir_path, file_srt)\n shutil.copy(src_srt_file_path, des_srt_file_path)\n\tsubtitles_format_for_gpt_input(note_assets_dir_path)\n\t# todo generate prompt\ndef move_origin_vid_to_destination(TR_MODE=0):\n\tflag_one_by_one = flags_utils.get_flag_one_by_one()\n\tif TR_MODE:\n print("flag_one_by_one:", flag_one_by_one)\n\tflag_search_sub_topic1 = flags_utils.get_flag_search_sub_topic1_in_bvids_origin_topic_path()\n\tkey_word, key_word_path = file_operations_utils.get_kg_bassets_folder_keyword()\n\tsub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = file_operations_utils.get_bassets_keyword_path(\n key_word=key_word)\n\t# sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_bassets_keyword_path(key_word="NN_1687967434")\n\torigin_current_vid_file_name = ""\n\t# sub_topic1_to_sub_topicn_folder_list, OneDrive_KG_note_root_directory_path = get_kg_assets_root()\n\tTopic, sub_topic1, current_topic = file_operations_utils.get_Topic_in_kg_assets(\n TR_MODE)\n\tif TR_MODE:\n print("Folder list:", sub_topic1_to_sub_topicn_folder_list)\n print("OneDrive KG root directory_path:",\n OneDrive_KG_note_root_directory_path)\n\tBaiduSyncdisk_KG_note_root_directory_path = file_operations_utils.get_b_KG_directory_path(\n OneDrive_KG_note_root_directory_path)\n\tif TR_MODE:\n print("BaiduSyncdisk assets root _directory_path:",\n BaiduSyncdisk_KG_note_root_directory_path)\n\tbvids_origin_topic_path = file_operations_utils.get_bvids_origin_topic_path(\n Topic, TR_MODE=TR_MODE)\n\tif flag_search_sub_topic1:\n dirs = [d for d in os.listdir(bvids_origin_topic_path) if os.path.isdir(\n os.path.join(bvids_origin_topic_path, d))]\n if TR_MODE:\n print("dirs:", dirs)\n reg_string = r"\\d{1,3}_"+sub_topic1\n flag_find_sub_topic = False\n for dir in dirs:\n if re.match(reg_string, dir):\n bvids_origin_topic_path = os.path.join(\n bvids_origin_topic_path, dir)\n flag_find_sub_topic = True\n break\n if not flag_find_sub_topic:\n raise Exception("sub topic not found")\n\tfiles = [f for f in os.listdir(bvids_origin_topic_path) if os.path.isfile(\n os.path.join(bvids_origin_topic_path, f)) and f.endswith(".mp4")]\n\tfiles.sort()\n\tif TR_MODE:\n print("Files:", files)\n\tOneDrive_KG_current_note_directory_path = file_operations_utils.get_OneDrive_KG_note_path(\n OneDrive_KG_note_root_directory_path, sub_topic1_to_sub_topicn_folder_list)\n\tif TR_MODE:\n print("OneDrive KG note directory_path:",\n OneDrive_KG_current_note_directory_path)\n\tcurrent_bvid_name = file_operations_utils.get_current_bvid_name()\n\tif TR_MODE:\n print("current_bvid_name:", current_bvid_name)\n\tserial_number = current_bvid_name[:3]\n\tif TR_MODE:\n print("serial_number:", serial_number)\n\tbvids_destination_directory_path = file_operations_utils.get_bvids_destination_long(\n sub_topic1_to_sub_topicn_folder_list, BaiduSyncdisk_KG_note_root_directory_path)\n\tif TR_MODE:\n print("bvids_destination_directory_path:",\n bvids_destination_directory_path)\n\t# bvid_reg_string = r\'.+\\(P\\d{1,3}\\. \\d{1,3}\\.\\d{1,3}\\.\\d{1,3}(.+)\\)\\.mp4\'\n\tcurrent_bvid_destination_file_path = os.path.join(\n bvids_destination_directory_path, current_bvid_name)\n\tif flag_one_by_one:\n if not os.path.exists(current_bvid_destination_file_path):\n vid_name_origin = files[0]\n # origin_current_vid_file_name = "\\n"+re.sub(bvid_reg_string, r\'\\1\', vid_name_origin)\n origin_current_vid_file_name = vid_name_origin\n os.rename(os.path.join(bvids_origin_topic_path,\n vid_name_origin), current_bvid_destination_file_path)\n reg_vid_name_origin_serial = r"(\\d{2,6})_.+(\\.mp4|\\.flv|\\.whem)"\n match = re.search(reg_vid_name_origin_serial,\n origin_current_vid_file_name)\n serial_number_origin = match.group(1)\n if match:\n reg_string_sub = r"^" + \\\n serial_number_origin+"_"+".+?" + \\\n r"(\\.ch\\.cn|\\.en)(\\.srt|\\.vtt)$"\n reg_string_sub2 = r"^" + \\\n serial_number_origin+"_"+".+?" + \\\n r"(\\.srt|\\.vtt)$"\n else:\n raise Exception("Error: regex not match")\n files_sub = [f for f in os.listdir(bvids_origin_topic_path) if os.path.isfile(\n os.path.join(bvids_origin_topic_path, f)) and (f.endswith(".srt") or f.endswith(".vtt"))]\n for file_sub in files_sub:\n match = re.search(reg_string_sub, file_sub)\n if match:\n # print(match)\n current_bsrt_name = current_bvid_name[:-4] + \\\n match.group(1)+match.group(2)\n os.rename(os.path.join(\n bvids_origin_topic_path, file_sub), os.path.join(bvids_destination_directory_path, current_bsrt_name))\n else:\n match = re.search(reg_string_sub2, file_sub)\n if match:\n current_bsrt_name = current_bvid_name[:-4] + \\\n match.group(1)\n os.rename(os.path.join(\n bvids_origin_topic_path, file_sub), os.path.join(bvids_destination_directory_path, current_bsrt_name))\n\treturn origin_current_vid_file_name, current_bvid_destination_file_path, OneDrive_KG_current_note_directory_path\ndef vid_path_2_md_vid_link(vid_path, current_bvid_name):\n\timport urllib\n\turl_path = urllib.parse.quote(os.path.abspath(vid_path))\n\turl = "file:///" + url_path.replace("\\\\", "/")\n\tmd_show_url = f"![{current_bvid_name}]({url})"\n\tmd_url = f"[{current_bvid_name}]({url})"\n\treturn md_show_url, md_url\ndef convert_chatgpt_summary_text_to_one_line_summary(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_string1 = [\n r\'(Section \\d{1,2}: |Title: |Title:\\n)(.+)\\n{1,2}(Start: |Start Timestamp: |Start Timestamp:\\n)(|\\()(\\d{1,2}:\\d{1,2})(|\\))\\n{1,2}Summary(: |:\\n)(.+)\', r"- \\2 (\\5) \\8"]\n\treg_string_list.append(reg_string1)\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, directory_path, files_md)\ndef check_video_file_path_conforms_to_pattern(str_url):\n\tr"![001_Derivatives of multivariable functions.mp4](file:///C%3A%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CMultivaribale_calculus_Khan_Academy%5Cassets%5Cbvids%5Cmc_1683793602%5C002%5C001%5C001_Derivatives%20of%20multivariable%20functions.mp4)"\n\turl_pattern_4_file_vid = r\'(!\\[.+\\..+\\]\\(file:///C:%5CBaiduSyncdisk%5Cassets(%5C.+){1,}\\.\\w+)(\\))\'\n\turl_pattern_4_file_vid2 = r\'(!\\[.+\\..+\\]\\(file:///C%3A%5CBaiduSyncdisk%5Cassets(%5C.+){1,}\\.\\w+)(\\))\'\n\tmatch1 = re.search(url_pattern_4_file_vid, str_url)\n\tif not match1:\n match1 = re.search(url_pattern_4_file_vid2, str_url)\n if not match1:\n print("str_url: ", str_url)\n raise Exception(\'No match found\')\n\treturn match1\ndef convert_min_sec_to_seconds(time_str):\n\ttime_line_pattern_str = r\'\\((\\d{1,2}:\\d{1,2})-(\\d{1,2}:\\d{1,2})\\)[ ]{1,}\'\n\ttime_stamp_pattern_str = r\'((\\d{1,2}):|)(\\d{1,2}):(\\d{1,2})\'\n\tmatch = re.search(time_line_pattern_str, time_str)\n\tif match:\n time_line_start = match.group(1)\n time_line_end = match.group(2)\n time_line_start_seconds = int(time_line_start.split(\n \':\')[0])*60+int(time_line_start.split(\':\')[1])\n return time_line_start_seconds\n\telse:\n match = re.search(time_stamp_pattern_str, time_str)\n if match:\n if match.group(2) != None:\n # print(match.group(1))\n hour = int(match.group(2))\n else:\n hour = 0\n time_seconds = hour * 60*60 + \\\n int(match.group(3))*60 + int(match.group(4))\n return time_seconds\n else:\n return None\ndef get_list_time_head_textshort_text_4_file(file, key_word):\n\t# print("start to generate time line for video and head text:")\n\tnumber_list_head_time_text_pattern_str = r\'((\\d{1,2}\\.)|-)[ ]{1,}(.+) \\((\\d{1,2}):(\\d{1,2})\\) (.+)\'\n\tnumber_list_head_time_pattern_str = r\'(\\d{1,2}):(\\d{1,2}) - (.+)\'\n\tnumber_list_head_time_pattern_str2 = r\'(\\d{1,2}):(\\d{1,2}) (.+)\'\n\ttime_text_pattern_str = r\'\\((\\d{1,2}):(\\d{1,2})\\)[ ]{0,}([^\\n]+)[\\n]{0,}\'\n\tpattern_dict = dict()\n\tpattern_dict["timestamps"] = number_list_head_time_pattern_str\n\tpattern_dict["summary_gpt"] = number_list_head_time_text_pattern_str\n\tpattern_dict["subtitle"] = time_text_pattern_str\n\tlist_time_head_textshort_text = []\n\twith open(os.path.join(os.getcwd(), file), \'r\', encoding=\'UTF-8\') as f:\n lines = f.readlines()\n\tfor line in lines:\n time_line_start_seconds = convert_min_sec_to_seconds(line)\n if time_line_start_seconds != None:\n if key_word in pattern_dict:\n pattern_str = pattern_dict[key_word]\n match = re.search(pattern_str, line)\n if match:\n if key_word == "timestamps":\n list_time_head_textshort_text.append(\n [time_line_start_seconds, match.group(3), None, None])\n elif key_word == "summary_gpt":\n # for i in range(len(match.groups())):\n #\t print(i,match.group(i))\n list_time_head_textshort_text.append(\n [time_line_start_seconds, match.group(3), match.group(6), None])\n elif key_word == "subtitle":\n list_time_head_textshort_text.append(\n [time_line_start_seconds, None, None, match.group(3)])\n else:\n if key_word == "timestamps":\n match2 = re.search(\n number_list_head_time_pattern_str2, line)\n if match2:\n list_time_head_textshort_text.append(\n [time_line_start_seconds, match2.group(3), None, None])\n else:\n print("no match for line:", line)\n print(key_word)\n else:\n print("no match for line:", line)\n print(key_word)\n else:\n raise Exception("key_word not in pattern_dict")\n\t# print("List of time, heading, short text, text:")\n\t# print(list_time_head_textshort_text)\n\treturn list_time_head_textshort_text\ndef list_time_head_textshort_text_to_vid_timeline_md(timeline_data, file, match):\n\t# print(timeline_data)\n\tassets_root_path, assets_root_dir = file_operations_utils.get_assets_root_path()\n\toutput_dir = file_operations_utils.create_output_directory(\n assets_root_path)\n\tnew_file_name = file_operations_utils.create_new_file_name(file)\n\tflag_write_line_by_line = True\n\tif not flag_write_line_by_line:\n content = ""\n\twith open(os.path.join(output_dir, new_file_name), \'w\', encoding=\'UTF-8\') as f:\n for i, (start_time, heading, short_text, text) in enumerate(timeline_data):\n start_time_sec = int(start_time)\n if i == len(timeline_data) - 1:\n end_time_sec = start_time_sec + 999\n else:\n end_time_sec = int(timeline_data[i + 1][0])\n if heading:\n if flag_write_line_by_line:\n f.write(f"## {heading}\\n\\n")\n else:\n content += f"## {heading}\\n\\n"\n i_temp = i\n flag_find_next_head = False\n while i_temp < len(timeline_data) - 1:\n i_temp += 1\n if timeline_data[i_temp][1]:\n end_time_sec2 = int(timeline_data[i_temp][0])\n vid_line = f"{match.group(1)}#t={start_time_sec},{end_time_sec2}{match.group(3)}"\n if flag_write_line_by_line:\n f.write(f"{vid_line}\\n\\n")\n else:\n content += f"{vid_line}\\n\\n"\n flag_find_next_head = True\n break\n if not flag_find_next_head:\n vid_line = f"{match.group(1)}#t={start_time_sec}{match.group(3)}"\n if flag_write_line_by_line:\n f.write(f"{vid_line}\\n\\n")\n else:\n content += f"{vid_line}\\n\\n"\n if short_text:\n if flag_write_line_by_line:\n f.write(f"- {short_text}\\n\\n")\n else:\n content += f"- {short_text}\\n\\n"\n if heading:\n if flag_write_line_by_line:\n f.write(f"---\\n\\n\\n\\n")\n else:\n content += f"---\\n\\n\\n\\n"\n if text:\n vid_line = f"{match.group(1)}#t={start_time_sec},{end_time_sec}{match.group(3)}"\n if flag_write_line_by_line:\n f.write(f"{vid_line}\\n\\n")\n f.write(f"{text}\\n\\n")\n else:\n content += f"{vid_line}\\n\\n"\n content += f"{text}\\n\\n"\n if flag_write_line_by_line:\n pass\n else:\n f.write(content)\n content = ""\n\treturn output_dir, new_file_name\ndef convert_md_vid_link_to_html(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_string2 = [r\'(!\\[\\]|!\\[.+\\])\\((file:///.+(\\.mp4|\\.mp4#t=.+))\\)\',\n r\'<video src="\\2" controls></video>\']\n\treg_string_list.extend([reg_string2])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, directory_path, files_md)\ndef convert_md_vid_link_to_html_tree(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\treg_string_list = []\n\treg_string2 = [r\'(!\\[\\]|!\\[.+\\])\\((file:///.+(\\.mp4|\\.mp4#t=.+))\\)\',\n r\'<video src="\\2" controls></video>\']\n\treg_string_list.extend([reg_string2])\n\tfile_operations_utils.perform_regex_replacement_on_files_tree(\n reg_string_list, directory_path)\ndef convert_gpt_summary_to_markdown_vid_timeline(str_url, TR_MODE, path=None):\n\t# str_url=r\'![009_area-and-slope.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C009_area-and-slope.mp4)\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\tif path is None:\n path = os.getcwd()\n\tfile_list = os.listdir(path)\n\tassets_root_path, assets_root_dir = file_operations_utils.get_assets_root_path()\n\tif TR_MODE:\n print("assets_root_path is : ", assets_root_path)\n\toutput_dir = file_operations_utils.create_output_directory(\n assets_root_path)\n\tif TR_MODE:\n print("output_dir is : ", output_dir)\n\tfor file in file_list:\n if file.endswith(".md"):\n if file.find("summary_gpt") != -1:\n cwd_floder_name = os.path.basename(path)\n file_summary = file\n key_word = "summary_gpt"\n list_time_head_textshort = get_list_time_head_textshort_text_4_file(\n file, key_word)\n # list_time_head_textshort_text_to_vid_timeline_md(list_time_head_textshort_text,file,match1)\n\tif TR_MODE:\n print("list_time_head_textshort is :", list_time_head_textshort)\n\tlist_time_head_textshort_text_to_vid_timeline_md(\n list_time_head_textshort, file_summary, match1)\n\tconvert_md_vid_link_to_html(output_dir)\n\treturn output_dir, file_summary\ndef get_note_vid_name():\n\tfile = os.path.basename(os.getcwd())\n\treturn file+r\'_vid\'+".md"\ndef merge_all_content_into_md_note_file(note_name, file_summary_path, origin_current_vid_file_name, current_vid_md_link_content, OneDrive_KG_current_note_directory_path):\n\twith open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "r", encoding="utf-8") as f:\n current_note_origin_content = f.read()\n\twith open(file_summary_path, "r", encoding="utf-8") as f:\n current_vid_summary = f.read()\n\twith open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "w", encoding="utf-8") as f:\n f.write(current_note_origin_content+origin_current_vid_file_name +\n current_vid_md_link_content+current_vid_summary)\ndef generate_vid_note_with_timeline_from_text_summary():\n\tTR_MODE = 1\n\torigin_current_vid_file_name, current_bvid_destination_file_path, OneDrive_KG_current_note_directory_path = move_origin_vid_to_destination(\n TR_MODE)\n\tcurrent_bvid_name = file_operations_utils.get_current_bvid_name()\n\tif TR_MODE:\n print("current_bvid_name:", current_bvid_name)\n\tmd_show_url, md_url = vid_path_2_md_vid_link(\n current_bvid_destination_file_path, current_bvid_name)\n\tcurrent_vid_md_link_content = \'\\n\\n\'+md_url+\'\\n\'+md_show_url+\'\\n\\n\'\n\tif TR_MODE:\n print("md_show_url:", md_show_url)\n print("md_url:", md_url)\n\tconvert_chatgpt_summary_text_to_one_line_summary()\n\t# output_dir, file_summary = convert_subtitle_and_summary_to_markdown_vid_timeline(\n\t#\t md_show_url)\n\toutput_dir, file_summary = convert_gpt_summary_to_markdown_vid_timeline(\n md_show_url, TR_MODE)\n\tfile_summary_path = os.path.join(output_dir, file_summary)\n\tnote_name = get_note_vid_name()\n\tif TR_MODE:\n print("note_name:", note_name)\n\tif not os.path.exists(os.path.join(OneDrive_KG_current_note_directory_path, note_name)):\n # print(os.path.join(OneDrive_KG_current_note_directory_path, note_name),"is note exists")\n # raise Exception("note not found")\n with open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "w", encoding="utf-8") as f:\n pass\n\tmerge_all_content_into_md_note_file(note_name, file_summary_path, origin_current_vid_file_name,\n current_vid_md_link_content, OneDrive_KG_current_note_directory_path)\n\tconvert_md_vid_link_to_html(OneDrive_KG_current_note_directory_path)\ndef timestamps_3blue1brown_2_timeline(str_url):\n\t# process url\n\t# str_url=r\'![007_limits.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C007_limits.mp4)\'\n\t# \'(!\\[.+\\..+\\]\\(file:///C:%5CBaiduSyncdisk%5Cassets(%5C.+){1,}\\.\\w+)(\\))\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\t# timestamps file\n\tfile_list = os.listdir(os.getcwd())\n\tfor file in file_list:\n if file.endswith(".md") or file.endswith(".txt"):\n if file.find("timestamps") != -1:\n key_word = "timestamps"\n list_time_head_textshort_text = get_list_time_head_textshort_text_4_file(\n file, key_word)\n output_dir, file_name = list_time_head_textshort_text_to_vid_timeline_md(\n list_time_head_textshort_text, file, match1)\n return output_dir, file_name\ndef generate_vid_note_with_timeline_from_timestamps():\n\tTR_MODE = 1\n\torigin_current_vid_file_name, current_bvid_destination_file_path, OneDrive_KG_current_note_directory_path = move_origin_vid_to_destination(\n TR_MODE)\n\tcurrent_bvid_name = file_operations_utils.get_current_bvid_name(\n current_bvid_destination_file_path)\n\tmd_show_url, md_url = vid_path_2_md_vid_link(\n current_bvid_destination_file_path, current_bvid_name)\n\tcurrent_vid_md_link_content = \'\\n\\n\'+md_url+\'\\n\'+md_show_url+\'\\n\\n\'\n\tif TR_MODE:\n print("md_show_url:", md_show_url)\n print("md_url:", md_url)\n\toutput_dir, file_summary = timestamps_3blue1brown_2_timeline(md_show_url)\n\tfile_summary_path = os.path.join(output_dir, file_summary)\n\tnote_name = get_note_vid_name()\n\tif TR_MODE:\n print("note_name:", note_name)\n\tif not os.path.exists(os.path.join(OneDrive_KG_current_note_directory_path, note_name)):\n # print(os.path.join(OneDrive_KG_current_note_directory_path, note_name),"is note exists")\n # raise Exception("note not found")\n with open(os.path.join(OneDrive_KG_current_note_directory_path, note_name), "w", encoding="utf-8") as f:\n pass\n\tmerge_all_content_into_md_note_file(note_name, file_summary_path, origin_current_vid_file_name,\n current_vid_md_link_content, OneDrive_KG_current_note_directory_path)\n\tconvert_md_vid_link_to_html(OneDrive_KG_current_note_directory_path)\ndef merge_list_time_head_textshort_text(list_time_text, list_time_head_textshort):\n\t# print("list_time_head_textshort is :")\n\t# print(list_time_head_textshort)\n\t# print("list_time_text is :")\n\t# print(list_time_text)\n\tfor i in range(len(list_time_head_textshort)):\n # print(list_time_head_textshort[i][0])\n for j in range(len(list_time_text)):\n if list_time_head_textshort[i][0] == list_time_text[j][0]:\n time_text = list_time_text.pop(j)\n print(time_text)\n list_time_head_textshort[i][3] = time_text[3]\n # list_time_head_textshort.append([list_time_head_textshort[i][0],list_time_head_textshort[i][1],list_time_head_textshort[i][2],time_text[3]])\n break\n\t# print("first merge list_time_head_textshort_text is :")\n\t# print(list_time_head_textshort)\n\tlist_time_head_textshort_text = list_time_head_textshort\n\tif len(list_time_text) > 0:\n # print("remain:",list_time_text)\n list_pop = []\n for i in range(len(list_time_text)):\n for j in range(len(list_time_head_textshort_text)):\n time_text = int(list_time_text[i][0])\n time_shorttext = int(list_time_head_textshort_text[j][0])\n if j != len(list_time_head_textshort_text)-1:\n time_shorttext_next = int(\n list_time_head_textshort_text[j+1][0])\n if time_text > time_shorttext and time_text < time_shorttext_next:\n list_time_head_textshort_text.insert(\n j+1, [list_time_text[i][0], None, None, list_time_text[i][3]])\n list_pop.append(list_time_text[i])\n break\n else:\n if time_text > time_shorttext:\n list_time_head_textshort_text.append(\n [list_time_text[i][0], None, None, list_time_text[i][3]])\n list_pop.append(list_time_text[i])\n break\n for elment in list_pop:\n index = list_time_text.index(elment)\n list_time_text.pop(index)\n\tif len(list_time_text) > 0:\n print("remain:", list_time_text)\n\treturn list_time_head_textshort_text\ndef get_bvid_reg_string(sub_topic1_to_sub_topicn_folder_list, TR_MODE=0):\n\t# sub_topic=sub_topic1_to_sub_topicn_folder_list[-2].split("_")[-2]+" "+sub_topic1_to_sub_topicn_folder_list[-2].split("_")[-1]\n\t# sub_topic=sub_topic1_to_sub_topicn_folder_list[-2].split("_")[-1]\n\treg_sub = [r\'\\d{3}_(.+)\', r\'\\1\']\n\tmatch = re.search(reg_sub[0], sub_topic1_to_sub_topicn_folder_list[-2])\n\tif match:\n sub_topic1 = re.sub(reg_sub[0], reg_sub[1],\n sub_topic1_to_sub_topicn_folder_list[-2])\n sub_topic1.replace("_", " ")\n\telse:\n raise Exception("sub_topic1 not found")\n\tif TR_MODE:\n print("Sub topic1:", sub_topic1)\n\tcurrent_topic = sub_topic1_to_sub_topicn_folder_list[-1].split("_")[-1]\n\tif TR_MODE:\n print("Current topic:", current_topic)\n\tbvid_reg_string = current_topic+r\'(( - )|(- - ))\'+sub_topic1+r\'\\.mp4\'\n\tif TR_MODE:\n print("bvid_reg_string:", bvid_reg_string)\n\tbvid_srt_reg_string = current_topic + \\\n r\'(( - )|(- - ))\'+sub_topic1+r\'(\\.en|\\.en.+)\'+r\'\\.srt\'\n\treturn bvid_reg_string, bvid_srt_reg_string\ndef get_bvids_destination_short(sub_topic1_to_sub_topicn_folder_list, BaiduSyncdisk_assets_root):\n\tpath_temp = BaiduSyncdisk_assets_root\n\tfor i in range(len(sub_topic1_to_sub_topicn_folder_list)-1):\n folder_temp = sub_topic1_to_sub_topicn_folder_list[i].split(\'_\')[0]\n if folder_temp != "FPCV":\n path_temp = os.path.join(path_temp, folder_temp)\n else:\n path_temp = os.path.join(\n path_temp, sub_topic1_to_sub_topicn_folder_list[i])\n if not os.path.exists(path_temp):\n os.makedirs(path_temp)\n\treturn path_temp\ndef get_bvids_origin_topic_path(BaiduSyncdisk_assets_root):\n\treturn os.path.join(BaiduSyncdisk_assets_root, "assets", "bvids", "mc_1683793602")\ndef get_note_name():\n\tfile = os.path.basename(os.getcwd())\n\treturn file+".md"\ndef get_note_vid_tra_name():\n\tfile = os.path.basename(os.getcwd())\n\treturn file+r\'_vid_tra\'+".md"\ndef copy_timestamps_and_index_2_root(directory=None):\n\t"""\n\tCopies files with \'timestamps\' in their name and \'.mdx\' extension to the root directory\n\twith an updated name. Also copies files with \'index\' in their name and \'.mdx\' extension\n\tto the root directory with an updated name.\n\t"""\n\tif directory is None:\n directory = os.getcwd()\n\tcurrent_folder_name = os.path.basename(directory)\n\tfilelist = os.listdir(directory)\n\tfor file in filelist:\n file_name, file_extension = os.path.splitext(file)\n if "timestamps" in file_name and file_extension == \'.md\':\n new_file_name1 = f"timestamps_{current_folder_name}.md"\n dest_path1 = os.path.join(directory, \'../..\', new_file_name1)\n if not os.path.exists(dest_path1):\n shutil.copy(file, dest_path1)\n if file_extension == \'.mdx\':\n if "index" in file_name:\n new_file_name = f"{current_folder_name}.md"\n dest_path = os.path.join(directory, \'../..\', new_file_name)\n if not os.path.exists(dest_path):\n shutil.copy(file, dest_path)\ndef convert_subtitle_and_summary_to_markdown_vid_timeline(str_url):\n\t# str_url=r\'![009_area-and-slope.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C009_area-and-slope.mp4)\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\tcwd = os.getcwd()\n\tfile_list = os.listdir(cwd)\n\tassets_root_path, assets_root_dir = get_assets_root_path()\n\toutput_dir = create_output_directory(assets_root_path)\n\tfor file in file_list:\n if file.endswith(".md"):\n if file.find("subtitle") != -1:\n key_word = "subtitle"\n list_time_text = get_list_time_head_textshort_text_4_file(\n file, key_word)\n # list_time_head_textshort_text_to_vid_timeline_md(list_time_head_textshort_text,file,match1)\n if file.find("summary_gpt") != -1:\n cwd_floder_name = os.path.basename(cwd)\n file_summary = file\n key_word = "summary_gpt"\n list_time_head_textshort = get_list_time_head_textshort_text_4_file(\n file, key_word)\n # list_time_head_textshort_text_to_vid_timeline_md(list_time_head_textshort_text,file,match1)\n\tlist_time_head_textshort_text = merge_list_time_head_textshort_text(\n list_time_text, list_time_head_textshort)\n\tprint("final is:")\n\tprint(list_time_head_textshort_text)\n\tlist_time_head_textshort_text_to_vid_timeline_md(\n list_time_head_textshort_text, file_summary, match1)\n\tconvert_md_vid_link_to_html(output_dir)\n\treturn output_dir, file_summary\ndef convert_subtitle_chatgpt_summary_to_markdown_vid_timeline(str_url):\n\t# str_url=r\'![009_area-and-slope.mp4](file:///C:%5CBaiduSyncdisk%5Cassets%5CO%5CO1%5CO17%5CO172%5CCalculus%203Blue1Brown%5Cassets%5Cbvids%5C009_area-and-slope.mp4)\'\n\tmatch1 = check_video_file_path_conforms_to_pattern(str_url)\n\tcwd = os.getcwd()\n\tfile_list = os.listdir(cwd)\n\tassets_root_path, assets_root_dir = get_assets_root_path()\n\tcreate_output_directory(assets_root_path)\n\tfor file in file_list:\n if file.endswith(".md"):\n if file.find("summary_gpt") != -1:\n key_word = "summary_gpt"\n list_time_head_textshort_text = get_list_time_head_textshort_text_4_file(\n file, key_word)\n list_time_head_textshort_text_to_vid_timeline_md(\n list_time_head_textshort_text, file, match1)\n'",
"wiki_processor.py": "'import os\nimport file_operations_utils\ndef remove_wiki_edit_link(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_wiki_edit_link = [\n r\'\\\\\\[\\[edit\\]\\(https://en\\.wikipedia\\.org/w/index\\.php\\?title=.+ "Edit section: (.+)"\\)\\\\\\]\', r""]\n\treg_string_list.extend([reg_wiki_edit_link])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, directory_path, files_md)\ndef remove_wiki_equation_svg(directory_path=None):\n\tif directory_path is None:\n directory_path = os.getcwd()\n\tfiles_md = [f for f in os.listdir(directory_path) if f.endswith(\'.md\')]\n\treg_string_list = []\n\treg_wiki_equation_svg = [r\'!\\[([^\\]]+)\\]\\([A-Za-z0-9]+\\.svg\\)\', r"$\\1$"]\n\treg_string_list.extend([reg_wiki_equation_svg])\n\tfile_operations_utils.perform_regex_replacement_on_files(\n reg_string_list, directory_path, files_md)\n'",
